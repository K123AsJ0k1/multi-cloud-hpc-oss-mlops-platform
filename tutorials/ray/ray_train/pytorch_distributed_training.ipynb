{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pytorch Distributed Training\n",
    "\n",
    "See the \"Pytorch distributed training\" section of the [README](README.md) for setting up the Ray cluster before running this example.\n",
    "\n",
    "For more information about Ray Train and the pytorch distributed training example, please check the original [getting-started-pytorch](https://docs.ray.io/en/latest/train/getting-started-pytorch.html) documentation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dd59779405ab6a9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Install requirements"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1dc95efb2549ae8e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%bash\n",
    "# pip install \"ray[data,train,tune,serve]\"==2.9.0\n",
    "# pip install torch torchvision\n",
    "# pip install IPython"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5d4022fdcb1679c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run a port forwarding to the Ray head service:\n",
    "```bash\n",
    "kubectl port-forward svc/raycluster-kuberay-head-svc 10001:10001 -n default\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90fd320efb90e4eb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "\n",
    "import ray\n",
    "from ray.train.torch import TorchTrainer\n",
    "import ray.train.torch\n",
    "\n",
    "print(ray.__version__)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "481ead5b0e5fa772",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Connect to the Ray cluster"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87448451f3b3af8d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "runtime_env = {\n",
    "    \"pip\": [\"torch\", \"torchvision\", \"IPython\"],\n",
    "}\n",
    "ray.init(address=\"ray://localhost:10001\", runtime_env=runtime_env)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d4371125bae14aea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(ray.cluster_resources())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f77dba013557371d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Define training\n",
    "\n",
    "- `train_func` is the Python code that executes on each distributed training worker.\n",
    "\n",
    "- `ScalingConfig` defines the number of distributed training workers and whether to use GPUs.\n",
    "\n",
    "- `TorchTrainer` launches the distributed training job."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcbd1be9aef9ee8b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_func(config):\n",
    "    # Model, Loss, Optimizer\n",
    "    model = resnet18(num_classes=10)\n",
    "    model.conv1 = torch.nn.Conv2d(\n",
    "        1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
    "    )\n",
    "    # model.to(\"cuda\")  # This is done by `prepare_model`\n",
    "    # [1] Prepare model.\n",
    "    model = ray.train.torch.prepare_model(model)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Data\n",
    "    transform = Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "    data_dir = os.path.join(tempfile.gettempdir(), \"data\")\n",
    "    train_data = FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "    # [2] Prepare dataloader.\n",
    "    train_loader = ray.train.torch.prepare_data_loader(train_loader)\n",
    "\n",
    "    # Training\n",
    "    n_epochs = 4\n",
    "    for epoch in range(n_epochs):\n",
    "        for images, labels in train_loader:\n",
    "            # This is done by `prepare_data_loader`!\n",
    "            # images, labels = images.to(\"cuda\"), labels.to(\"cuda\")\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # [3] Report metrics and checkpoint.\n",
    "        metrics = {\"loss\": loss.item(), \"epoch\": epoch}\n",
    "        with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "            torch.save(\n",
    "                model.module.state_dict(),\n",
    "                os.path.join(temp_checkpoint_dir, \"model.pt\")\n",
    "            )\n",
    "            ray.train.report(\n",
    "                metrics,\n",
    "                checkpoint=ray.train.Checkpoint.from_directory(temp_checkpoint_dir),\n",
    "            )\n",
    "        if ray.train.get_context().get_world_rank() == 0:\n",
    "            print(metrics)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f63f34bcc9a165a9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Configure scaling and resource requirements.\n",
    "scaling_config = ray.train.ScalingConfig(num_workers=2, use_gpu=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0abf33da5091a67",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Distributed training job.\n",
    "trainer = ray.train.torch.TorchTrainer(\n",
    "    train_func,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config=ray.train.RunConfig(\n",
    "        storage_path=\"/home/ray/nfs\",\n",
    "        name=\"nfs\",\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9062a2bed5e71d5",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Launch training job"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a49b206c6f18468"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "result = trainer.fit()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9dfb1e27d2990c6",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
