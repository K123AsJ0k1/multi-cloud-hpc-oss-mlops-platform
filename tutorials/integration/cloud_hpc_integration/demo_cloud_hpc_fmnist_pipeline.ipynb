{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c41a24-7b3e-4f8e-b6fc-637b3784c5d7",
   "metadata": {},
   "source": [
    "# Cloud-HPC FMNIST Experiment\n",
    "\n",
    "In this notebook we construct the necessery code for data analysis, preprocessing, model training and model analysis steps using OSS run in CPouta for orhestration, Allas for storage and Ray in Mahti for compute. You need to have the following:\n",
    "\n",
    "- MyCSC account\n",
    "- Project with billing units\n",
    "- Access to CPouta\n",
    "- Suitable network rules\n",
    "- SSH key for CPouta for local and bridge\n",
    "- Setup Cloud-HPC OSS\n",
    "- Access to Allas\n",
    "- Access to Mahti\n",
    "- SSH setup to Mahti\n",
    "\n",
    "This notebook uses the following packages:\n",
    "- pip install jupyterlab\n",
    "- pip install matplotlib\n",
    "- pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu\n",
    "- pip install python-decouple\n",
    "- pip install keystoneauth1 python-keystoneclient python-swiftclient\n",
    "- pip install kfp~=1.8.14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c262784b-1196-4351-8676-ca5a0b84c2e1",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aac4bf2f-3c04-435e-999c-dd24cfbfcda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "\n",
    "image_labels = {\n",
    "    0: 'Top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle Boot',\n",
    "}\n",
    "\n",
    "regular_transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "source_train_data = datasets.FashionMNIST(\n",
    "    root = './data', \n",
    "    train = True, \n",
    "    download = True, \n",
    "    transform = regular_transform\n",
    ")\n",
    "\n",
    "source_test_data = datasets.FashionMNIST(\n",
    "    root = './data', \n",
    "    train = False, \n",
    "    download = True, \n",
    "    transform = regular_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319d9f41-acfb-4098-8e12-35be874e22a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def first_columnsXrows_images(\n",
    "    dataset: any,\n",
    "    labels: any,\n",
    "    columns: int,\n",
    "    rows: int\n",
    "):\n",
    "    figure = plt.figure(figsize = (10,10))\n",
    "    for i in range (1, columns * rows + 1):\n",
    "        image, label = dataset[i]\n",
    "        figure.add_subplot(\n",
    "            rows, \n",
    "            columns, \n",
    "            i\n",
    "        )\n",
    "        plt.title(labels[label])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(\n",
    "            image.squeeze(), \n",
    "            cmap = 'gray'\n",
    "        )\n",
    "    plt.show()\n",
    "\n",
    "def class_amounts(\n",
    "    dataset: any,\n",
    "    labels: any\n",
    "):\n",
    "    class_amounts = torch.bincount(dataset.targets)\n",
    "    print('Class, amount:')\n",
    "    for i in range(len(labels)):\n",
    "        print(labels[i], class_amounts[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb050f63-d078-488c-a903-edfb290953a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set has 60000 instances\n",
      "Class, amount:\n",
      "Top 6000\n",
      "Trouser 6000\n",
      "Pullover 6000\n",
      "Dress 6000\n",
      "Coat 6000\n",
      "Sandal 6000\n",
      "Shirt 6000\n",
      "Sneaker 6000\n",
      "Bag 6000\n",
      "Ankle Boot 6000\n"
     ]
    }
   ],
   "source": [
    "first_columnsXrows_images(\n",
    "    dataset = source_train_data,\n",
    "    labels = image_labels,\n",
    "    columns = 3,\n",
    "    rows = 3\n",
    ")\n",
    "print('Train set has {} instances'.format(len(source_train_data)))\n",
    "class_amounts(\n",
    "    dataset = source_train_data,\n",
    "    labels = image_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1759ce49-3d37-4241-80ab-4f25dadd15f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set has 10000 instances\n",
      "Class, amount:\n",
      "Top 1000\n",
      "Trouser 1000\n",
      "Pullover 1000\n",
      "Dress 1000\n",
      "Coat 1000\n",
      "Sandal 1000\n",
      "Shirt 1000\n",
      "Sneaker 1000\n",
      "Bag 1000\n",
      "Ankle Boot 1000\n"
     ]
    }
   ],
   "source": [
    "first_columnsXrows_images(\n",
    "    dataset = source_test_data,\n",
    "    labels = image_labels,\n",
    "    columns = 3,\n",
    "    rows = 3\n",
    ")\n",
    "print('Test set has {} instances'.format(len(source_test_data)))\n",
    "class_amounts(\n",
    "    dataset = source_test_data,\n",
    "    labels = image_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ade23d1-6719-4d4b-99a4-f552bec83abb",
   "metadata": {},
   "source": [
    "## Preprocessing and training in Cloud-HPC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3781bdc-effa-4317-a4d8-234458db77c8",
   "metadata": {},
   "source": [
    "## Boilerplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ef073c-2418-4d28-874e-03f63abfa181",
   "metadata": {},
   "source": [
    "## Istio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d76f6fb0-db6b-4094-8229-beb8eeed20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "from urllib.parse import urlsplit\n",
    "\n",
    "def get_istio_auth_session(url: str, username: str, password: str) -> dict:\n",
    "    \"\"\"\n",
    "    Determine if the specified URL is secured by Dex and try to obtain a session cookie.\n",
    "    WARNING: only Dex `staticPasswords` and `LDAP` authentication are currently supported\n",
    "             (we default default to using `staticPasswords` if both are enabled)\n",
    "\n",
    "    :param url: Kubeflow server URL, including protocol\n",
    "    :param username: Dex `staticPasswords` or `LDAP` username\n",
    "    :param password: Dex `staticPasswords` or `LDAP` password\n",
    "    :return: auth session information\n",
    "    \"\"\"\n",
    "    # define the default return object\n",
    "    auth_session = {\n",
    "        \"endpoint_url\": url,    # KF endpoint URL\n",
    "        \"redirect_url\": None,   # KF redirect URL, if applicable\n",
    "        \"dex_login_url\": None,  # Dex login URL (for POST of credentials)\n",
    "        \"is_secured\": None,     # True if KF endpoint is secured\n",
    "        \"session_cookie\": None  # Resulting session cookies in the form \"key1=value1; key2=value2\"\n",
    "    }\n",
    "\n",
    "    # use a persistent session (for cookies)\n",
    "    with requests.Session() as s:\n",
    "\n",
    "        ################\n",
    "        # Determine if Endpoint is Secured\n",
    "        ################\n",
    "        resp = s.get(url, allow_redirects=True)\n",
    "        if resp.status_code != 200:\n",
    "            raise RuntimeError(\n",
    "                f\"HTTP status code '{resp.status_code}' for GET against: {url}\"\n",
    "            )\n",
    "\n",
    "        auth_session[\"redirect_url\"] = resp.url\n",
    "\n",
    "        # if we were NOT redirected, then the endpoint is UNSECURED\n",
    "        if len(resp.history) == 0:\n",
    "            auth_session[\"is_secured\"] = False\n",
    "            return auth_session\n",
    "        else:\n",
    "            auth_session[\"is_secured\"] = True\n",
    "\n",
    "        ################\n",
    "        # Get Dex Login URL\n",
    "        ################\n",
    "        redirect_url_obj = urlsplit(auth_session[\"redirect_url\"])\n",
    "\n",
    "        # if we are at `/auth?=xxxx` path, we need to select an auth type\n",
    "        if re.search(r\"/auth$\", redirect_url_obj.path):\n",
    "\n",
    "            #######\n",
    "            # TIP: choose the default auth type by including ONE of the following\n",
    "            #######\n",
    "\n",
    "            # OPTION 1: set \"staticPasswords\" as default auth type\n",
    "            redirect_url_obj = redirect_url_obj._replace(\n",
    "                path=re.sub(r\"/auth$\", \"/auth/local\", redirect_url_obj.path)\n",
    "            )\n",
    "            # OPTION 2: set \"ldap\" as default auth type\n",
    "            # redirect_url_obj = redirect_url_obj._replace(\n",
    "            #     path=re.sub(r\"/auth$\", \"/auth/ldap\", redirect_url_obj.path)\n",
    "            # )\n",
    "\n",
    "        # if we are at `/auth/xxxx/login` path, then no further action is needed (we can use it for login POST)\n",
    "        if re.search(r\"/auth/.*/login$\", redirect_url_obj.path):\n",
    "            auth_session[\"dex_login_url\"] = redirect_url_obj.geturl()\n",
    "\n",
    "        # else, we need to be redirected to the actual login page\n",
    "        else:\n",
    "            # this GET should redirect us to the `/auth/xxxx/login` path\n",
    "            resp = s.get(redirect_url_obj.geturl(), allow_redirects=True)\n",
    "            if resp.status_code != 200:\n",
    "                raise RuntimeError(\n",
    "                    f\"HTTP status code '{resp.status_code}' for GET against: {redirect_url_obj.geturl()}\"\n",
    "                )\n",
    "\n",
    "            # set the login url\n",
    "            auth_session[\"dex_login_url\"] = resp.url\n",
    "\n",
    "        ################\n",
    "        # Attempt Dex Login\n",
    "        ################\n",
    "        resp = s.post(\n",
    "            auth_session[\"dex_login_url\"],\n",
    "            data={\"login\": username, \"password\": password},\n",
    "            allow_redirects=True\n",
    "        )\n",
    "        if len(resp.history) == 0:\n",
    "            raise RuntimeError(\n",
    "                f\"Login credentials were probably invalid - \"\n",
    "                f\"No redirect after POST to: {auth_session['dex_login_url']}\"\n",
    "            )\n",
    "\n",
    "        # store the session cookies in a \"key1=value1; key2=value2\" string\n",
    "        auth_session[\"session_cookie\"] = \"; \".join([f\"{c.name}={c.value}\" for c in s.cookies])\n",
    "\n",
    "    return auth_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f988378f-a5ef-434a-bc9b-66ae3437f33f",
   "metadata": {},
   "source": [
    "### General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7317c8e0-6add-40ec-af8f-825bc4acd600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_formatted_user(\n",
    "    user: str   \n",
    ") -> any:\n",
    "    return re.sub(r'[^a-z0-9]+', '-', user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3cdc3c-9f20-4653-85d8-75e0f94c07cb",
   "metadata": {},
   "source": [
    "## SWIFT Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7976507-730f-43c0-8c14-11148be387e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import Config,RepositoryEnv\n",
    "from keystoneauth1 import loading, session\n",
    "from keystoneauth1.identity import v3\n",
    "from keystoneclient.v3 import client as keystone_client\n",
    "import swiftclient as sc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa640c73-b251-4534-a712-0c6aaf1bc4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_swift_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    return isinstance(storage_client, sc.Connection)\n",
    "\n",
    "def swift_setup_client(\n",
    "    pre_auth_url: str,\n",
    "    pre_auth_token: str,\n",
    "    user_domain_name: str,\n",
    "    project_domain_name: str,\n",
    "    project_name: str,\n",
    "    auth_version: str\n",
    ") -> any:\n",
    "    swift_client = sc.Connection(\n",
    "        preauthurl = pre_auth_url,\n",
    "        preauthtoken = pre_auth_token,\n",
    "        os_options = {\n",
    "            'user_domain_name': user_domain_name,\n",
    "            'project_domain_name': project_domain_name,\n",
    "            'project_name': project_name\n",
    "        },\n",
    "        auth_version = auth_version\n",
    "    )\n",
    "    return swift_client\n",
    "\n",
    "def swift_create_bucket(\n",
    "    swift_client: any,\n",
    "    bucket_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        swift_client.put_container(\n",
    "            container = bucket_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def swift_check_bucket(\n",
    "    swift_client: any,\n",
    "    bucket_name:str\n",
    ") -> any:\n",
    "    try:\n",
    "        bucket_info = swift_client.get_container(\n",
    "            container = bucket_name\n",
    "        )\n",
    "        bucket_metadata = bucket_info[0]\n",
    "        list_of_objects = bucket_info[1]\n",
    "        return {'metadata': bucket_metadata, 'objects': list_of_objects}\n",
    "    except Exception as e:\n",
    "        return {} \n",
    "\n",
    "def swift_delete_bucket(\n",
    "    swift_client: any,\n",
    "    bucket_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        swift_client.delete_container(\n",
    "            container = bucket_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def swift_list_buckets(\n",
    "    swift_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        account_buckets = swift_client.get_account()[1]\n",
    "        buckets = {}\n",
    "        for bucket in account_buckets:\n",
    "            bucket_name = bucket['name']\n",
    "            bucket_count = bucket['count']\n",
    "            bucket_size = bucket['bytes']\n",
    "            buckets[bucket_name] = {\n",
    "                'amount': bucket_count,\n",
    "                'size': bucket_size\n",
    "            }\n",
    "        return buckets\n",
    "    except Exception as e:\n",
    "        return {}\n",
    "\n",
    "def swift_create_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    ") -> bool: \n",
    "    try:\n",
    "        swift_client.put_object(\n",
    "            container = bucket_name,\n",
    "            obj = object_path,\n",
    "            contents = object_data,\n",
    "            headers = object_metadata\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def swift_check_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> any: \n",
    "    try:\n",
    "        object_metadata = swift_client.head_object(\n",
    "            container = bucket_name,\n",
    "            obj = object_path\n",
    "        )       \n",
    "        return object_metadata\n",
    "    except Exception as e:\n",
    "        return {} \n",
    "\n",
    "def swift_get_object(\n",
    "    swift_client:any,\n",
    "    bucket_name: str,\n",
    "    object_path: str\n",
    ") -> any:\n",
    "    try:\n",
    "        response = swift_client.get_object(\n",
    "            container = bucket_name,\n",
    "            obj = object_path \n",
    "        )\n",
    "        object_info = response[0]\n",
    "        object_data = response[1]\n",
    "        return {'data': object_data, 'info': object_info}\n",
    "    except Exception as e:\n",
    "        return {}     \n",
    "   \n",
    "def swift_remove_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> bool: \n",
    "    try:\n",
    "        swift_client.delete_object(\n",
    "            container = bucket_name, \n",
    "            obj = object_path\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def swift_update_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    ") -> bool:  \n",
    "    remove = swift_remove_object(\n",
    "        swift_client = swift_client, \n",
    "        bucket_name = bucket_name, \n",
    "        object_path = object_path\n",
    "    )\n",
    "    if not remove:\n",
    "        return False\n",
    "    create = swift_create_object(\n",
    "        swift_client = swift_client, \n",
    "        bucket_name = bucket_name, \n",
    "        object_path = object_path, \n",
    "        object_data = object_data,\n",
    "        object_metadata = object_metadata\n",
    "    )\n",
    "    return create\n",
    "\n",
    "def swift_create_or_update_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    ") -> any:\n",
    "    bucket_info = swift_check_bucket(\n",
    "        swift_client = swift_client, \n",
    "        bucket_name = bucket_name\n",
    "    )\n",
    "    \n",
    "    if len(bucket_info) == 0:\n",
    "        creation_status = swift_create_bucket(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        if not creation_status:\n",
    "            return False\n",
    "    \n",
    "    object_info = swift_check_object(\n",
    "        swift_client = swift_client, \n",
    "        bucket_name = bucket_name, \n",
    "        object_path = object_path\n",
    "    )\n",
    "    \n",
    "    if len(object_info) == 0:\n",
    "        return swift_create_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            object_data = object_data,\n",
    "            object_metadata = object_metadata\n",
    "        )\n",
    "    else:\n",
    "        return swift_update_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            object_data = object_data,\n",
    "            object_metadata = object_metadata\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b91063-d28b-451a-9778-435d71714844",
   "metadata": {},
   "source": [
    "## Storage Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21f9438b-30f3-48c9-a97a-6af84d85821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_encoded_metadata(\n",
    "    used_client: str,\n",
    "    object_metadata: any\n",
    ") -> any:\n",
    "    encoded_metadata = {}\n",
    "    if used_client == 'swift':\n",
    "        key_initial = 'x-object-meta'\n",
    "        for key, value in object_metadata.items():\n",
    "            encoded_key = key_initial + '-' + key\n",
    "            if isinstance(value, list):\n",
    "                encoded_metadata[encoded_key] = 'list=' + ','.join(map(str, value))\n",
    "                continue\n",
    "            encoded_metadata[encoded_key] = str(value)\n",
    "    return encoded_metadata\n",
    "\n",
    "def get_general_metadata(\n",
    "    used_client: str,\n",
    "    object_metadata: any\n",
    ") -> any:\n",
    "    general_metadata = {}\n",
    "    if used_client == 'swift':\n",
    "        key_initial = 'x-object-meta'\n",
    "        for key, value in object_metadata.items():\n",
    "            if not key_initial == key[:len(key_initial)]:\n",
    "                general_metadata[key] = value\n",
    "    return general_metadata\n",
    "\n",
    "def get_decoded_metadata(\n",
    "    used_client: str,\n",
    "    object_metadata: any\n",
    ") -> any: \n",
    "    decoded_metadata = {}\n",
    "    if used_client == 'swift':\n",
    "        key_initial = 'x-object-meta'\n",
    "        for key, value in object_metadata.items():\n",
    "            if key_initial == key[:len(key_initial)]:\n",
    "                decoded_key = key[len(key_initial) + 1:]\n",
    "                if 'list=' in value:\n",
    "                    string_integers = value.split('=')[1]\n",
    "                    values = string_integers.split(',')\n",
    "                    if len(values) == 1 and values[0] == '':\n",
    "                        decoded_metadata[decoded_key] = []\n",
    "                    else:\n",
    "                        try:\n",
    "                            decoded_metadata[decoded_key] = list(map(int, values))\n",
    "                        except:\n",
    "                            decoded_metadata[decoded_key] = list(map(str, values))\n",
    "                    continue\n",
    "                if value.isnumeric():\n",
    "                    decoded_metadata[decoded_key] = int(value)\n",
    "                    continue\n",
    "                decoded_metadata[decoded_key] = value\n",
    "    return decoded_metadata\n",
    "\n",
    "def set_bucket_names(\n",
    "    storage_parameters: any\n",
    ") -> any:\n",
    "    storage_names = []\n",
    "    bucket_prefix = storage_parameters['bucket-prefix']\n",
    "    ice_id = storage_parameters['ice-id']\n",
    "    user = storage_parameters['user']\n",
    "    storage_names.append(bucket_prefix + '-forwarder-' + ice_id)\n",
    "    storage_names.append(bucket_prefix + '-submitter-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "    storage_names.append(bucket_prefix + '-pipeline-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "    storage_names.append(bucket_prefix + '-experiment-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "    return storage_names\n",
    "\n",
    "def setup_storage_client(\n",
    "    storage_parameters: any\n",
    ") -> any:\n",
    "    storage_client = None\n",
    "    if storage_parameters['used-client'] == 'swift':\n",
    "        storage_client = swift_setup_client(\n",
    "            pre_auth_url = storage_parameters['pre-auth-url'],\n",
    "            pre_auth_token = storage_parameters['pre-auth-token'],\n",
    "            user_domain_name = storage_parameters['user-domain-name'],\n",
    "            project_domain_name = storage_parameters['project-domain-name'],\n",
    "            project_name = storage_parameters['project-name'],\n",
    "            auth_version = storage_parameters['auth-version']\n",
    "        )\n",
    "    return storage_client\n",
    "\n",
    "def check_object_metadata(\n",
    "    storage_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> any: \n",
    "    object_metadata = {\n",
    "        'general-meta': {},\n",
    "        'custom-meta': {}\n",
    "    }\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        all_metadata = swift_check_object(\n",
    "           swift_client = storage_client,\n",
    "           bucket_name = bucket_name,\n",
    "           object_path = object_path\n",
    "        ) \n",
    "\n",
    "        general_metadata = {}\n",
    "        custom_metadata = {}\n",
    "        if not len(all_metadata) == 0:\n",
    "            general_metadata = get_general_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = all_metadata\n",
    "            )\n",
    "            custom_metadata = get_decoded_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = all_metadata\n",
    "            )\n",
    "\n",
    "        object_metadata['general-meta'] = general_metadata\n",
    "        object_metadata['custom-meta'] = custom_metadata\n",
    "\n",
    "    return object_metadata\n",
    "\n",
    "def get_object_content(\n",
    "    storage_client: any,\n",
    "    bucket_name: str,\n",
    "    object_path: str\n",
    ") -> any:\n",
    "    object_content = {}\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        fetched_object = swift_get_object(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path\n",
    "        )\n",
    "        object_content['data'] = pickle.loads(fetched_object['data'])\n",
    "        object_content['general-meta'] = get_general_metadata(\n",
    "            used_client = 'swift',\n",
    "            object_metadata = fetched_object['info']\n",
    "        )\n",
    "        object_content['custom-meta'] = get_decoded_metadata(\n",
    "            used_client = 'swift',\n",
    "            object_metadata = fetched_object['info']\n",
    "        )\n",
    "    return object_content\n",
    "   \n",
    "def remove_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> bool: \n",
    "    removed = False\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        removed = swift_remove_object(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path\n",
    "        )\n",
    "    return removed\n",
    "\n",
    "def create_or_update_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    ") -> any:\n",
    "    success = False\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        formatted_data = pickle.dumps(object_data)\n",
    "        formatted_metadata = set_encoded_metadata(\n",
    "            used_client = 'swift',\n",
    "            object_metadata = object_metadata\n",
    "        )\n",
    "\n",
    "        success = swift_create_or_update_object(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path,\n",
    "            object_data = formatted_data,\n",
    "            object_metadata = formatted_metadata\n",
    "        )\n",
    "    return success\n",
    "\n",
    "def format_bucket_metadata(\n",
    "    used_client: str,\n",
    "    bucket_metadata: any\n",
    ") -> any:\n",
    "    formatted_metadata = {}\n",
    "    if used_client == 'swift':\n",
    "        relevant_values = {\n",
    "            'x-container-object-count': 'object-count',\n",
    "            'x-container-bytes-used-actual': 'used-bytes',\n",
    "            'last-modified': 'date',\n",
    "            'content-type': 'type'\n",
    "        }\n",
    "        formatted_metadata = {}\n",
    "        for key,value in bucket_metadata.items():\n",
    "            if key in relevant_values:\n",
    "                formatted_key = relevant_values[key]\n",
    "                formatted_metadata[formatted_key] = value\n",
    "    return formatted_metadata\n",
    "\n",
    "def format_bucket_objects(\n",
    "    used_client: str,\n",
    "    bucket_objects: any\n",
    ") -> any:\n",
    "    formatted_objects = {}\n",
    "    if used_client == 'swift':\n",
    "        for bucket_object in bucket_objects:\n",
    "            formatted_object_metadata = {\n",
    "                'hash': 'id',\n",
    "                'bytes': 'used-bytes',\n",
    "                'last_modified': 'date'\n",
    "            }\n",
    "            object_key = None\n",
    "            object_metadata = {}\n",
    "            for key, value in bucket_object.items():\n",
    "                if key == 'name':\n",
    "                    object_key = value\n",
    "                if key in formatted_object_metadata:\n",
    "                    formatted_key = formatted_object_metadata[key]\n",
    "                    object_metadata[formatted_key] = value\n",
    "            formatted_objects[object_key] = object_metadata\n",
    "    return formatted_objects\n",
    "\n",
    "def format_bucket_info(\n",
    "    used_client: str,\n",
    "    bucket_info: any\n",
    ") -> any:\n",
    "    bucket_metadata = {}\n",
    "    bucket_objects = {}\n",
    "    if used_client == 'swift':\n",
    "        bucket_metadata = format_bucket_metadata(\n",
    "            used_client = used_client,\n",
    "            bucket_metadata = bucket_info['metadata']\n",
    "        )\n",
    "        bucket_objects = format_bucket_objects(\n",
    "            used_client = used_client,\n",
    "            bucket_objects = bucket_info['objects']\n",
    "        )\n",
    "    return {'metadata': bucket_metadata, 'objects': bucket_objects} \n",
    "\n",
    "def get_bucket_info(\n",
    "    storage_client: any,\n",
    "    bucket_name: str\n",
    ") -> any:\n",
    "    bucket_info = {}\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        unformatted_bucket_info = swift_check_bucket(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        bucket_info = format_bucket_info(\n",
    "            used_client = 'swift',\n",
    "            bucket_info = unformatted_bucket_info\n",
    "        )\n",
    "    return bucket_info\n",
    "\n",
    "def format_container_info(\n",
    "    used_client: str,\n",
    "    container_info: any\n",
    ") -> any:\n",
    "    formatted_container_info = {}\n",
    "    if used_client == 'swift':\n",
    "        for bucket in container_info:\n",
    "            bucket_name = bucket['name']\n",
    "            bucket_count = bucket['count']\n",
    "            bucket_size = bucket['bytes']\n",
    "            formatted_container_info[bucket_name] = {\n",
    "                'amount': bucket_count,\n",
    "                'size': bucket_size\n",
    "            }\n",
    "    return formatted_container_info\n",
    "\n",
    "def get_container_info( \n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    container_info = {}\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        unformatted_container_info = swift_list_buckets(\n",
    "            swift_client = storage_client \n",
    "        )\n",
    "        container_info = format_container_info(\n",
    "            used_client = 'swift',\n",
    "            container_info = unformatted_container_info\n",
    "        )\n",
    "    return container_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074429bd-e23c-424a-be87-b45af537204a",
   "metadata": {},
   "source": [
    "## Object Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "774ff4f5-7974-443d-a131-f993ada41650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_object_path(\n",
    "    object_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any\n",
    "):\n",
    "    object_paths = {\n",
    "        'root': 'name',\n",
    "        'code': 'CODE/name',\n",
    "        'slurm': 'CODE/SLURM/name',\n",
    "        'ray': 'CODE/RAY/name',\n",
    "        'data': 'DATA/name',\n",
    "        'artifacts': 'ARTIFACTS/name',\n",
    "        'time': 'TIMES/name'\n",
    "    }\n",
    "\n",
    "    i = 0\n",
    "    path_split = object_paths[object_name].split('/')\n",
    "    for name in path_split:\n",
    "        if name in path_replacers:\n",
    "            replacer = path_replacers[name]\n",
    "            if 0 < len(replacer):\n",
    "                path_split[i] = replacer\n",
    "        i = i + 1\n",
    "    \n",
    "    if not len(path_names) == 0:\n",
    "        path_split.extend(path_names)\n",
    "\n",
    "    object_path = '/'.join(path_split)\n",
    "    print('Used object path:' + str(object_path))\n",
    "    return object_path\n",
    "\n",
    "def setup_storage(\n",
    "    storage_parameters: any\n",
    ") -> any:\n",
    "    storage_client = setup_storage_client(\n",
    "        storage_parameters = storage_parameters\n",
    "    ) \n",
    "    \n",
    "    storage_name = set_bucket_names(\n",
    "       storage_parameters = storage_parameters\n",
    "    )\n",
    "    \n",
    "    return storage_client, storage_name\n",
    "\n",
    "def check_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str,\n",
    "    object_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any\n",
    ") -> bool:\n",
    "    object_path = set_object_path(\n",
    "        object_name = object_name,\n",
    "        path_replacers = path_replacers,\n",
    "        path_names = path_names\n",
    "    )\n",
    "    object_metadata = check_object_metadata(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = bucket_name,\n",
    "        object_path = object_path\n",
    "    )\n",
    "    object_metadata['path'] = object_path\n",
    "    return object_metadata\n",
    "\n",
    "def get_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str,\n",
    "    object_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any\n",
    ") -> any:\n",
    "    checked_object = check_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = bucket_name,\n",
    "        object_name = object_name,\n",
    "        path_replacers = path_replacers,\n",
    "        path_names = path_names\n",
    "    )\n",
    "\n",
    "    object_data = None\n",
    "    if not len(checked_object['general-meta']) == 0:\n",
    "        object_data = get_object_content(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = checked_object['path']\n",
    "        )\n",
    "\n",
    "    return object_data\n",
    "\n",
    "def set_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str,\n",
    "    object_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any,\n",
    "    overwrite: bool,\n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    "):\n",
    "    checked_object = check_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = bucket_name,\n",
    "        object_name = object_name,\n",
    "        path_replacers = path_replacers,\n",
    "        path_names = path_names\n",
    "    )\n",
    "    \n",
    "    perform = True\n",
    "    if not len(checked_object['general-meta']) == 0 and not overwrite:\n",
    "        perform = False\n",
    "    \n",
    "    if perform:\n",
    "        create_or_update_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = checked_object['path'],\n",
    "            object_data = object_data,\n",
    "            object_metadata = object_metadata\n",
    "        )\n",
    "\n",
    "def check_bucket(\n",
    "    storage_client: any,\n",
    "    bucket_name: str\n",
    ") -> any:\n",
    "    return get_bucket_info(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = bucket_name\n",
    "    )\n",
    "\n",
    "def check_buckets(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    return get_container_info( \n",
    "        storage_client = storage_client\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc30abac-9534-4953-b1df-ce7f8f017002",
   "metadata": {},
   "source": [
    "## Metadata Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4cde924-d044-4129-9095-070ef5198a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_object_metadata():\n",
    "    general_object_metadata = {\n",
    "        'version': 1\n",
    "    }\n",
    "    return general_object_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73f4e7-384b-4ade-ab3c-30fd5172fe55",
   "metadata": {},
   "source": [
    "## Time Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cc748a1-94e4-4693-88da-72f79a221020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_time(\n",
    "    storage_client: any,\n",
    "    storage_name: any,\n",
    "    time_group: any,\n",
    "    time_name: any,\n",
    "    start_time: int,\n",
    "    end_time: int\n",
    "):\n",
    "    time_object = get_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = storage_name,\n",
    "        object_name = 'time',\n",
    "        path_replacers = {\n",
    "            'name': time_group\n",
    "        },\n",
    "        path_names = []\n",
    "    )\n",
    "\n",
    "    time_data = {}\n",
    "    time_metadata = {} \n",
    "    if time_object is None:\n",
    "        time_data = {}\n",
    "        time_metadata = general_object_metadata()\n",
    "    else:\n",
    "        time_data = time_object['data']\n",
    "        time_metadata = time_object['custom-meta']\n",
    "    \n",
    "    current_key_amount = len(time_data)\n",
    "    current_key_full = False\n",
    "    current_key = str(current_key_amount)\n",
    "    if 0 < current_key_amount:\n",
    "        time_object = time_data[current_key]\n",
    "        if 0 < time_object['total-seconds']:\n",
    "            current_key_full = True\n",
    "    \n",
    "    changed = False\n",
    "    if 0 < end_time and 0 < current_key_amount and not current_key_full:\n",
    "        stored_start_time = time_data[current_key]['start-time']\n",
    "        time_diff = (end_time-stored_start_time)\n",
    "        time_data[current_key]['end-time'] = end_time\n",
    "        time_data[current_key]['total-seconds'] = round(time_diff,5)\n",
    "        changed = True\n",
    "    else:\n",
    "        next_key_amount = len(time_data) + 1\n",
    "        new_key = str(next_key_amount)\n",
    "    \n",
    "        if 0 < start_time and 0 == end_time:\n",
    "            time_data[new_key] = {\n",
    "                'name': time_name,\n",
    "                'start-time': start_time,\n",
    "                'end-time': 0,\n",
    "                'total-seconds': 0\n",
    "            }\n",
    "            changed = True\n",
    "\n",
    "        if 0 < start_time and 0 < end_time:\n",
    "            time_diff = (end_time-start_time)\n",
    "            time_data[new_key] = {\n",
    "                'name': time_name,\n",
    "                'start-time': start_time,\n",
    "                'end-time': end_time,\n",
    "                'total-seconds': round(time_diff,5)\n",
    "            }\n",
    "            changed = True\n",
    "\n",
    "    if changed:\n",
    "        time_metadata['version'] = time_metadata['version'] + 1\n",
    "        set_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = storage_name,\n",
    "            object_name = 'time',\n",
    "            path_replacers = {\n",
    "                'name': time_group\n",
    "            },\n",
    "            path_names = [],\n",
    "            overwrite = True,\n",
    "            object_data = time_data,\n",
    "            object_metadata = time_metadata \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef768ae-8158-4d00-8334-52e3a32f712f",
   "metadata": {},
   "source": [
    "## Compose functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b1e88fe-31b2-42b5-bac3-60b6be6e396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def start_compose(\n",
    "    file_path: str\n",
    ") -> bool:\n",
    "    compose_up_command = 'docker compose -f (file) up -d'\n",
    "    modified_up_command = compose_up_command.replace('(file)', file_path)\n",
    "    \n",
    "    resulted_print = subprocess.run(\n",
    "        modified_up_command,\n",
    "        shell = True,\n",
    "        stdout = subprocess.PIPE,\n",
    "        stderr = subprocess.PIPE\n",
    "    )\n",
    "    \n",
    "    print_split = resulted_print.stderr.decode('utf-8').split('\\n')\n",
    "\n",
    "    deployed = False\n",
    "    for row in print_split:\n",
    "        empty_split = row.split(' ')\n",
    "        for word in empty_split:\n",
    "            if 0 == len(word):\n",
    "                continue\n",
    "            if word.lower() == 'started':\n",
    "                deployed = True\n",
    "    return deployed\n",
    "\n",
    "def stop_compose(\n",
    "    file_path: str\n",
    ") -> bool:\n",
    "    compose_down_command = 'docker compose -f (file) down'\n",
    "    modified_down_command = compose_down_command.replace('(file)', file_path)\n",
    "    \n",
    "    resulted_print = subprocess.run(\n",
    "        modified_down_command,\n",
    "        shell = True,\n",
    "        stdout = subprocess.PIPE,\n",
    "        stderr = subprocess.PIPE\n",
    "    )\n",
    "\n",
    "    print_split = resulted_print.stderr.decode('utf-8').split('\\n')\n",
    "\n",
    "    removed = False\n",
    "    for row in print_split:\n",
    "        empty_split = row.split(' ')\n",
    "        for word in empty_split:\n",
    "            if 0 == len(word):\n",
    "                continue\n",
    "            if word.lower() == 'removed':\n",
    "                removed = True\n",
    "    return removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c204f7-0937-48e7-8423-81aec7e8eec6",
   "metadata": {},
   "source": [
    "## Access Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d06ed1b-f036-41c6-ad10-2d8e62becd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_storage_parameters(\n",
    "    env_path: str,\n",
    "    auth_url: str,\n",
    "    pre_auth_url: str,\n",
    "    auth_version: str,\n",
    "    bucket_prefix: str,\n",
    "    ice_id: str,\n",
    "    user: str\n",
    "):\n",
    "    env_config = Config(RepositoryEnv(env_path))\n",
    "    swift_auth_url = auth_url\n",
    "    swift_user = env_config.get('CSC_USERNAME')\n",
    "    swift_key = env_config.get('CSC_PASSWORD')\n",
    "    swift_project_name = env_config.get('CSC_PROJECT_NAME')\n",
    "    swift_user_domain_name = env_config.get('CSC_USER_DOMAIN_NAME')\n",
    "    swift_project_domain_name = env_config.get('CSC_USER_DOMAIN_NAME')\n",
    "\n",
    "    loader = loading.get_plugin_loader('password')\n",
    "    auth = loader.load_from_options(\n",
    "        auth_url = swift_auth_url,\n",
    "        username = swift_user,\n",
    "        password = swift_key,\n",
    "        project_name = swift_project_name,\n",
    "        user_domain_name = swift_user_domain_name,\n",
    "        project_domain_name = swift_project_domain_name\n",
    "    )\n",
    "\n",
    "    keystone_session = session.Session(\n",
    "        auth = auth\n",
    "    )\n",
    "    swift_token = keystone_session.get_token()\n",
    "\n",
    "    swift_pre_auth_url = pre_auth_url\n",
    "    swift_auth_version = auth_version\n",
    "\n",
    "    storage_parameters = {\n",
    "        'bucket-prefix': bucket_prefix,\n",
    "        'ice-id': ice_id,\n",
    "        'user': user,\n",
    "        'used-client': 'swift',\n",
    "        'pre-auth-url': str(swift_pre_auth_url),\n",
    "        'pre-auth-token': str(swift_token),\n",
    "        'user-domain-name': str(swift_user_domain_name),\n",
    "        'project-domain-name': str(swift_project_domain_name),\n",
    "        'project-name': str(swift_project_name),\n",
    "        'auth-version': str(swift_auth_version)\n",
    "    }\n",
    "\n",
    "    return storage_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac884bb-e8bf-49da-a589-c43d5cac2996",
   "metadata": {},
   "source": [
    "## Code Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b0a418-47ac-45c5-9e3a-fb6c390a9e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_code(\n",
    "    storage_client: any,\n",
    "    storage_name: str,\n",
    "    file_path: str,\n",
    "    overwrite: bool\n",
    "):\n",
    "    file_data = None\n",
    "    print('User code storage:' + str(storage_name))\n",
    "    print('Used code path:' + str(file_path))\n",
    "    with open(file_path, 'r') as f:\n",
    "        file_data = f.read()\n",
    "\n",
    "    path_split = file_path.split('/')\n",
    "    directory_name = path_split[-2]\n",
    "    file_name = path_split[-1]\n",
    "    \n",
    "    set_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = storage_name,\n",
    "        object_name = directory_name,\n",
    "        path_replacers = {\n",
    "            'name': file_name\n",
    "        },\n",
    "        path_names = [],\n",
    "        overwrite = overwrite,\n",
    "        object_data = file_data,\n",
    "        object_metadata = general_object_metadata()\n",
    "    )\n",
    "\n",
    "def get_code(\n",
    "    storage_client: any,\n",
    "    storage_name: str,\n",
    "    code_type: str,\n",
    "    code_file: str\n",
    ") -> any:\n",
    "    print('User code storage:' + str(storage_name))\n",
    "    fetched_object = get_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = storage_name,\n",
    "        object_name = code_type,\n",
    "        path_replacers = {\n",
    "            'name': code_file\n",
    "        },\n",
    "        path_names = []\n",
    "    )\n",
    "    code_object = {\n",
    "        'data': fetched_object['data'],\n",
    "        'metadata': fetched_object['custom-meta']\n",
    "    }\n",
    "    return code_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fb0b52-25fd-4e64-9a3d-a62a1289e0be",
   "metadata": {},
   "source": [
    "## Gaining Storage Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db89cc-6599-43de-a2c5-9ccfc339b31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_absolute_path = '/home/(your_local_username)/.ssh/.env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "392b9779-8485-4f44-8ae1-ee7ba00b81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_parameters = get_storage_parameters(\n",
    "    env_path = env_absolute_path,\n",
    "    auth_url = 'https://pouta.csc.fi:5001/v3',\n",
    "    pre_auth_url = 'https://a3s.fi:443/swift/v1/AUTH_6698ff90e6704a74930c33d6b66f1b5b',\n",
    "    auth_version = '3',\n",
    "    bucket_prefix = 'integration',\n",
    "    ice_id = 's0-c0-u1',\n",
    "    user = 'user@example.com'\n",
    ")\n",
    "\n",
    "storage_client, storage_names = setup_storage(\n",
    "    storage_parameters = storage_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "639111db-e5e6-4698-b277-f668abdc1ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['integration-forwarder-s0-c0-u1',\n",
       " 'integration-submitter-s0-c0-u1-user-example-com',\n",
       " 'integration-pipeline-s0-c0-u1-user-example-com',\n",
       " 'integration-experiment-s0-c0-u1-user-example-com']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a00f001-e0f9-4688-a015-3e2d6cd49920",
   "metadata": {},
   "source": [
    "## KFP Access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6f7c7c-0e36-4b30-a3a7-45a81906bfaf",
   "metadata": {},
   "source": [
    "## SLURM Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9028cb73-fb19-4fca-9452-afc0575c6b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/slurm/ray-cluster.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/slurm/ray-cluster.sh\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=ray-cluster\n",
    "#SBATCH --account=project_(your_csc_project_number)\n",
    "#SBATCH --partition=medium\n",
    "#SBATCH --time=00:20:00\n",
    "#SBATCH --nodes=2\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=10GB\n",
    "\n",
    "module load pytorch\n",
    "\n",
    "echo \"Loaded modules:\"\n",
    "\n",
    "module list\n",
    "\n",
    "echo \"Activating venv\"\n",
    "\n",
    "source /users/(your_csc_username)/exp-venv/bin/activate\n",
    "\n",
    "echo \"Venv active\"\n",
    "\n",
    "echo \"Installed packages\"\n",
    "\n",
    "pip list\n",
    "\n",
    "echo \"Packages listed\"\n",
    "\n",
    "echo \"Setting connection variables\"\n",
    "\n",
    "key_path=\"/users/(your_csc_username)/cpouta-mahti.pem\"\n",
    "cloud_ip=\"(your_cpouta_vm_internal_net_ip)\"\n",
    "cloud_port=8280\n",
    "cloud_user=\"(your_cpouta_vm_username)\"\n",
    "cloud_fip=\"(your_cpouta_vm_floating_ip)\"\n",
    "\n",
    "echo \"Setting Ray variables\"\n",
    "\n",
    "hpc_head_port=8265\n",
    "hpc_dashboard_port=8280 \n",
    "nodes=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\")\n",
    "nodes_array=($nodes)\n",
    "head_node=${nodes_array[0]}\n",
    "head_node_ip=$(srun --nodes=1 --ntasks=1 -w \"$head_node\" hostname --ip-address)\n",
    "\n",
    "echo \"Setting up Ray head\"\n",
    "\n",
    "ip_head=$head_node_ip:$hpc_head_port\n",
    "export ip_head\n",
    "echo \"IP Head: $ip_head\"\n",
    "\n",
    "echo \"Starting HEAD at $head_node\"\n",
    "srun --nodes=1 --ntasks=1 -w \"$head_node\" \\\n",
    "    singularity_wrapper exec ray start --head --node-ip-address=\"$head_node_ip\" --port=$hpc_head_port --dashboard-host=\"$head_node_ip\" --dashboard-port=$hpc_dashboard_port \\\n",
    "    --num-cpus \"${SLURM_CPUS_PER_TASK}\" --num-gpus 3 --block &\n",
    "\n",
    "echo \"Setting up SSH tunnel\"\n",
    "\n",
    "ssh -f -o StrictHostKeyChecking=no -i $key_path -N -R $cloud_ip:$cloud_port:$head_node_ip:$hpc_dashboard_port $cloud_user@$cloud_fip\n",
    "\n",
    "echo \"Reverse port forward running\"\n",
    "\n",
    "sleep 5\n",
    "\n",
    "echo \"Setting up Ray workers\"\n",
    "\n",
    "worker_num=$((SLURM_JOB_NUM_NODES - 1))\n",
    "\n",
    "for ((i = 1; i <= worker_num; i++)); do\n",
    "    node_i=${nodes_array[$i]}\n",
    "    echo \"Starting WORKER $i at $node_i\"\n",
    "    srun --nodes=1 --ntasks=1 -w \"$node_i\" \\\n",
    "         singularity_wrapper exec ray start --address \"$ip_head\" \\\n",
    "\t --num-cpus \"${SLURM_CPUS_PER_TASK}\" --num-gpus 3 --block &\n",
    "    sleep 1140\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a890a60c-47e7-4627-b69c-fa060574a502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'integration-pipeline-s0-c0-u1-user-example-com'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_names[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40b15c9b-9d20-4e6e-97d9-0268d247227b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User code storage:integration-pipeline-s0-c0-u1-user-example-com\n",
      "Used code path:scripts/slurm/ray-cluster.sh\n",
      "Used object path:CODE/SLURM/ray-cluster.sh\n"
     ]
    }
   ],
   "source": [
    "set_code(\n",
    "    storage_client = storage_client,\n",
    "    storage_name = storage_names[-2],\n",
    "    file_path = 'scripts/slurm/ray-cluster.sh',\n",
    "    overwrite = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30931ab-5131-4f93-9861-304a5a7a7ca8",
   "metadata": {},
   "source": [
    "## Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8d468e1-a14f-41dc-9712-1ca1e5453a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/ray/train-fmnist-cnn.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/ray/train-fmnist-cnn.py\n",
    "import sys\n",
    "import ray\n",
    "import json\n",
    "\n",
    "import re\n",
    "import swiftclient as sc\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics as TM\n",
    "\n",
    "import time as t\n",
    "\n",
    "def set_formatted_user(\n",
    "    user: str   \n",
    ") -> any:\n",
    "    return re.sub(r'[^a-z0-9]+', '-', user)\n",
    "def general_object_metadata():\n",
    "    general_object_metadata = {\n",
    "        'version': 1\n",
    "    }\n",
    "    return general_object_metadata\n",
    "\n",
    "def is_swift_client(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    return isinstance(storage_client, sc.Connection)\n",
    "\n",
    "def swift_setup_client(\n",
    "    pre_auth_url: str,\n",
    "    pre_auth_token: str,\n",
    "    user_domain_name: str,\n",
    "    project_domain_name: str,\n",
    "    project_name: str,\n",
    "    auth_version: str\n",
    ") -> any:\n",
    "    swift_client = sc.Connection(\n",
    "        preauthurl = pre_auth_url,\n",
    "        preauthtoken = pre_auth_token,\n",
    "        os_options = {\n",
    "            'user_domain_name': user_domain_name,\n",
    "            'project_domain_name': project_domain_name,\n",
    "            'project_name': project_name\n",
    "        },\n",
    "        auth_version = auth_version\n",
    "    )\n",
    "    return swift_client\n",
    "\n",
    "def swift_create_bucket(\n",
    "    swift_client: any,\n",
    "    bucket_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        swift_client.put_container(\n",
    "            container = bucket_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def swift_check_bucket(\n",
    "    swift_client: any,\n",
    "    bucket_name:str\n",
    ") -> any:\n",
    "    try:\n",
    "        bucket_info = swift_client.get_container(\n",
    "            container = bucket_name\n",
    "        )\n",
    "        bucket_metadata = bucket_info[0]\n",
    "        list_of_objects = bucket_info[1]\n",
    "        return {'metadata': bucket_metadata, 'objects': list_of_objects}\n",
    "    except Exception as e:\n",
    "        return {} \n",
    "\n",
    "def swift_delete_bucket(\n",
    "    swift_client: any,\n",
    "    bucket_name: str\n",
    ") -> bool:\n",
    "    try:\n",
    "        swift_client.delete_container(\n",
    "            container = bucket_name\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def swift_list_buckets(\n",
    "    swift_client: any\n",
    ") -> any:\n",
    "    try:\n",
    "        account_buckets = swift_client.get_account()[1]\n",
    "        return account_buckets\n",
    "    except Exception as e:\n",
    "        return {}\n",
    "\n",
    "def swift_create_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    ") -> bool: \n",
    "    try:\n",
    "        swift_client.put_object(\n",
    "            container = bucket_name,\n",
    "            obj = object_path,\n",
    "            contents = object_data,\n",
    "            headers = object_metadata\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def swift_check_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> any: \n",
    "    try:\n",
    "        object_metadata = swift_client.head_object(\n",
    "            container = bucket_name,\n",
    "            obj = object_path\n",
    "        )       \n",
    "        return object_metadata\n",
    "    except Exception as e:\n",
    "        return {} \n",
    "\n",
    "def swift_get_object(\n",
    "    swift_client:any,\n",
    "    bucket_name: str,\n",
    "    object_path: str\n",
    ") -> any:\n",
    "    try:\n",
    "        response = swift_client.get_object(\n",
    "            container = bucket_name,\n",
    "            obj = object_path \n",
    "        )\n",
    "        object_info = response[0]\n",
    "        object_data = response[1]\n",
    "        return {'data': object_data, 'info': object_info}\n",
    "    except Exception as e:\n",
    "        return {}     \n",
    "  \n",
    "def swift_remove_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> bool: \n",
    "    try:\n",
    "        swift_client.delete_object(\n",
    "            container = bucket_name, \n",
    "            obj = object_path\n",
    "        )\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "def swift_update_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    ") -> bool:  \n",
    "    remove = swift_remove_object(\n",
    "        swift_client = swift_client, \n",
    "        bucket_name = bucket_name, \n",
    "        object_path = object_path\n",
    "    )\n",
    "    if not remove:\n",
    "        return False\n",
    "    create = swift_create_object(\n",
    "        swift_client = swift_client, \n",
    "        bucket_name = bucket_name, \n",
    "        object_path = object_path, \n",
    "        object_data = object_data,\n",
    "        object_metadata = object_metadata\n",
    "    )\n",
    "    return create\n",
    "\n",
    "def swift_create_or_update_object(\n",
    "    swift_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    ") -> any:\n",
    "    bucket_info = swift_check_bucket(\n",
    "        swift_client = swift_client, \n",
    "        bucket_name = bucket_name\n",
    "    )\n",
    "    \n",
    "    if len(bucket_info) == 0:\n",
    "        creation_status = swift_create_bucket(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        if not creation_status:\n",
    "            return False\n",
    "    \n",
    "    object_info = swift_check_object(\n",
    "        swift_client = swift_client, \n",
    "        bucket_name = bucket_name, \n",
    "        object_path = object_path\n",
    "    )\n",
    "    \n",
    "    if len(object_info) == 0:\n",
    "        return swift_create_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            object_data = object_data,\n",
    "            object_metadata = object_metadata\n",
    "        )\n",
    "    else:\n",
    "        return swift_update_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            object_data = object_data,\n",
    "            object_metadata = object_metadata\n",
    "        )\n",
    "\n",
    "def set_encoded_metadata(\n",
    "    used_client: str,\n",
    "    object_metadata: any\n",
    ") -> any:\n",
    "    encoded_metadata = {}\n",
    "    if used_client == 'swift':\n",
    "        key_initial = 'x-object-meta'\n",
    "        for key, value in object_metadata.items():\n",
    "            encoded_key = key_initial + '-' + key\n",
    "            if isinstance(value, list):\n",
    "                encoded_metadata[encoded_key] = 'list=' + ','.join(map(str, value))\n",
    "                continue\n",
    "            encoded_metadata[encoded_key] = str(value)\n",
    "    return encoded_metadata\n",
    "\n",
    "def get_general_metadata(\n",
    "    used_client: str,\n",
    "    object_metadata: any\n",
    ") -> any:\n",
    "    general_metadata = {}\n",
    "    if used_client == 'swift':\n",
    "        key_initial = 'x-object-meta'\n",
    "        for key, value in object_metadata.items():\n",
    "            if not key_initial == key[:len(key_initial)]:\n",
    "                general_metadata[key] = value\n",
    "    return general_metadata\n",
    "\n",
    "def get_decoded_metadata(\n",
    "    used_client: str,\n",
    "    object_metadata: any\n",
    ") -> any: \n",
    "    decoded_metadata = {}\n",
    "    if used_client == 'swift':\n",
    "        key_initial = 'x-object-meta'\n",
    "        for key, value in object_metadata.items():\n",
    "            if key_initial == key[:len(key_initial)]:\n",
    "                decoded_key = key[len(key_initial) + 1:]\n",
    "                if 'list=' in value:\n",
    "                    string_integers = value.split('=')[1]\n",
    "                    values = string_integers.split(',')\n",
    "                    if len(values) == 1 and values[0] == '':\n",
    "                        decoded_metadata[decoded_key] = []\n",
    "                    else:\n",
    "                        try:\n",
    "                            decoded_metadata[decoded_key] = list(map(int, values))\n",
    "                        except:\n",
    "                            decoded_metadata[decoded_key] = list(map(str, values))\n",
    "                    continue\n",
    "                if value.isnumeric():\n",
    "                    decoded_metadata[decoded_key] = int(value)\n",
    "                    continue\n",
    "                decoded_metadata[decoded_key] = value\n",
    "    return decoded_metadata\n",
    "\n",
    "def set_bucket_names(\n",
    "    storage_parameters: any\n",
    ") -> any:\n",
    "    storage_names = []\n",
    "    bucket_prefix = storage_parameters['bucket-prefix']\n",
    "    ice_id = storage_parameters['ice-id']\n",
    "    user = storage_parameters['user']\n",
    "    storage_names.append(bucket_prefix + '-forwarder-' + ice_id)\n",
    "    storage_names.append(bucket_prefix + '-submitter-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "    storage_names.append(bucket_prefix + '-pipeline-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "    storage_names.append(bucket_prefix + '-experiment-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "    return storage_names\n",
    "\n",
    "def setup_storage(\n",
    "    storage_parameters: any\n",
    ") -> any:\n",
    "    storage_client = setup_storage_client(\n",
    "        storage_parameters = storage_parameters\n",
    "    ) \n",
    "    \n",
    "    storage_name = set_bucket_names(\n",
    "    storage_parameters = storage_parameters\n",
    "    )\n",
    "    \n",
    "    return storage_client, storage_name\n",
    "\n",
    "def setup_storage_client(\n",
    "    storage_parameters: any\n",
    ") -> any:\n",
    "    storage_client = None\n",
    "    if storage_parameters['used-client'] == 'swift':\n",
    "        storage_client = swift_setup_client(\n",
    "            pre_auth_url = storage_parameters['pre-auth-url'],\n",
    "            pre_auth_token = storage_parameters['pre-auth-token'],\n",
    "            user_domain_name = storage_parameters['user-domain-name'],\n",
    "            project_domain_name = storage_parameters['project-domain-name'],\n",
    "            project_name = storage_parameters['project-name'],\n",
    "            auth_version = storage_parameters['auth-version']\n",
    "        )\n",
    "    return storage_client\n",
    "\n",
    "def check_object_metadata(\n",
    "    storage_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> any: \n",
    "    object_metadata = {\n",
    "        'general-meta': {},\n",
    "        'custom-meta': {}\n",
    "    }\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        all_metadata = swift_check_object(\n",
    "        swift_client = storage_client,\n",
    "        bucket_name = bucket_name,\n",
    "        object_path = object_path\n",
    "        ) \n",
    "\n",
    "        general_metadata = {}\n",
    "        custom_metadata = {}\n",
    "        if not len(all_metadata) == 0:\n",
    "            general_metadata = get_general_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = all_metadata\n",
    "            )\n",
    "            custom_metadata = get_decoded_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = all_metadata\n",
    "            )\n",
    "\n",
    "        object_metadata['general-meta'] = general_metadata\n",
    "        object_metadata['custom-meta'] = custom_metadata\n",
    "\n",
    "    return object_metadata\n",
    "\n",
    "def get_object_content(\n",
    "    storage_client: any,\n",
    "    bucket_name: str,\n",
    "    object_path: str\n",
    ") -> any:\n",
    "    object_content = {}\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        fetched_object = swift_get_object(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path\n",
    "        )\n",
    "        object_content['data'] = pickle.loads(fetched_object['data'])\n",
    "        object_content['general-meta'] = get_general_metadata(\n",
    "            used_client = 'swift',\n",
    "            object_metadata = fetched_object['info']\n",
    "        )\n",
    "        object_content['custom-meta'] = get_decoded_metadata(\n",
    "            used_client = 'swift',\n",
    "            object_metadata = fetched_object['info']\n",
    "        )\n",
    "    return object_content\n",
    "    \n",
    "def remove_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str\n",
    ") -> bool: \n",
    "    removed = False\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        removed = swift_remove_object(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path\n",
    "        )\n",
    "    return removed\n",
    "\n",
    "def create_or_update_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str, \n",
    "    object_path: str, \n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    ") -> any:\n",
    "    success = False\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        formatted_data = pickle.dumps(object_data)\n",
    "        formatted_metadata = set_encoded_metadata(\n",
    "            used_client = 'swift',\n",
    "            object_metadata = object_metadata\n",
    "        )\n",
    "\n",
    "        success = swift_create_or_update_object(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path,\n",
    "            object_data = formatted_data,\n",
    "            object_metadata = formatted_metadata\n",
    "        )\n",
    "    return success\n",
    "\n",
    "def format_bucket_metadata(\n",
    "    used_client: str,\n",
    "    bucket_metadata: any\n",
    ") -> any:\n",
    "    formatted_metadata = {}\n",
    "    if used_client == 'swift':\n",
    "        relevant_values = {\n",
    "            'x-container-object-count': 'object-count',\n",
    "            'x-container-bytes-used-actual': 'used-bytes',\n",
    "            'last-modified': 'date',\n",
    "            'content-type': 'type'\n",
    "        }\n",
    "        formatted_metadata = {}\n",
    "        for key,value in bucket_metadata.items():\n",
    "            if key in relevant_values:\n",
    "                formatted_key = relevant_values[key]\n",
    "                formatted_metadata[formatted_key] = value\n",
    "    return formatted_metadata\n",
    "\n",
    "def format_bucket_objects(\n",
    "    used_client: str,\n",
    "    bucket_objects: any\n",
    ") -> any:\n",
    "    formatted_objects = {}\n",
    "    if used_client == 'swift':\n",
    "        for bucket_object in bucket_objects:\n",
    "            formatted_object_metadata = {\n",
    "                'hash': 'id',\n",
    "                'bytes': 'used-bytes',\n",
    "                'last_modified': 'date'\n",
    "            }\n",
    "            object_key = None\n",
    "            object_metadata = {}\n",
    "            for key, value in bucket_object.items():\n",
    "                if key == 'name':\n",
    "                    object_key = value\n",
    "                if key in formatted_object_metadata:\n",
    "                    formatted_key = formatted_object_metadata[key]\n",
    "                    object_metadata[formatted_key] = value\n",
    "            formatted_objects[object_key] = object_metadata\n",
    "    return formatted_objects\n",
    "\n",
    "def format_bucket_info(\n",
    "    used_client: str,\n",
    "    bucket_info: any\n",
    ") -> any:\n",
    "    bucket_metadata = {}\n",
    "    bucket_objects = {}\n",
    "    if used_client == 'swift':\n",
    "        bucket_metadata = format_bucket_metadata(\n",
    "            used_client = used_client,\n",
    "            bucket_metadata = bucket_info['metadata']\n",
    "        )\n",
    "        bucket_objects = format_bucket_objects(\n",
    "            used_client = used_client,\n",
    "            bucket_objects = bucket_info['objects']\n",
    "        )\n",
    "    return {'metadata': bucket_metadata, 'objects': bucket_objects} \n",
    "\n",
    "def get_bucket_info(\n",
    "    storage_client: any,\n",
    "    bucket_name: str\n",
    ") -> any:\n",
    "    bucket_info = {}\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        unformatted_bucket_info = swift_check_bucket(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        bucket_info = format_bucket_info(\n",
    "            used_client = 'swift',\n",
    "            bucket_info = unformatted_bucket_info\n",
    "        )\n",
    "    return bucket_info\n",
    "\n",
    "def format_container_info(\n",
    "    used_client: str,\n",
    "    container_info: any\n",
    ") -> any:\n",
    "    formatted_container_info = {}\n",
    "    if used_client == 'swift':\n",
    "        for bucket in container_info:\n",
    "            bucket_name = bucket['name']\n",
    "            bucket_count = bucket['count']\n",
    "            bucket_size = bucket['bytes']\n",
    "            formatted_container_info[bucket_name] = {\n",
    "                'amount': bucket_count,\n",
    "                'size': bucket_size\n",
    "            }\n",
    "    return formatted_container_info\n",
    "\n",
    "def get_container_info( \n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    container_info = {}\n",
    "    if is_swift_client(storage_client = storage_client):\n",
    "        unformatted_container_info = swift_list_buckets(\n",
    "            swift_client = storage_client \n",
    "        )\n",
    "        container_info = format_container_info(\n",
    "            used_client = 'swift',\n",
    "            container_info = unformatted_container_info\n",
    "        )\n",
    "    return container_info\n",
    "\n",
    "def set_object_path(\n",
    "    object_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any\n",
    "):\n",
    "    object_paths = {\n",
    "        'root': 'name',\n",
    "        'code': 'CODE/name',\n",
    "        'slurm': 'CODE/SLURM/name',\n",
    "        'ray': 'CODE/RAY/name',\n",
    "        'data': 'DATA/name',\n",
    "        'artifacts': 'ARTIFACTS/name',\n",
    "        'time': 'TIMES/name'\n",
    "    }\n",
    "\n",
    "    i = 0\n",
    "    path_split = object_paths[object_name].split('/')\n",
    "    for name in path_split:\n",
    "        if name in path_replacers:\n",
    "            replacer = path_replacers[name]\n",
    "            if 0 < len(replacer):\n",
    "                path_split[i] = replacer\n",
    "        i = i + 1\n",
    "    \n",
    "    if not len(path_names) == 0:\n",
    "        path_split.extend(path_names)\n",
    "\n",
    "    object_path = '/'.join(path_split)\n",
    "    return object_path\n",
    "\n",
    "def setup_storage(\n",
    "    storage_parameters: any\n",
    ") -> any:\n",
    "    storage_client = setup_storage_client(\n",
    "        storage_parameters = storage_parameters\n",
    "    ) \n",
    "    \n",
    "    storage_name = set_bucket_names(\n",
    "    storage_parameters = storage_parameters\n",
    "    )\n",
    "    \n",
    "    return storage_client, storage_name\n",
    "\n",
    "def check_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str,\n",
    "    object_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any\n",
    ") -> bool:\n",
    "    object_path = set_object_path(\n",
    "        object_name = object_name,\n",
    "        path_replacers = path_replacers,\n",
    "        path_names = path_names\n",
    "    )\n",
    "    object_metadata = check_object_metadata(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = bucket_name,\n",
    "        object_path = object_path\n",
    "    )\n",
    "    object_metadata['path'] = object_path\n",
    "    return object_metadata\n",
    "\n",
    "def get_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str,\n",
    "    object_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any\n",
    ") -> any:\n",
    "    checked_object = check_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = bucket_name,\n",
    "        object_name = object_name,\n",
    "        path_replacers = path_replacers,\n",
    "        path_names = path_names\n",
    "    )\n",
    "\n",
    "    object_data = None\n",
    "    if not len(checked_object['general-meta']) == 0:\n",
    "        object_data = get_object_content(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = checked_object['path']\n",
    "        )\n",
    "\n",
    "    return object_data\n",
    "\n",
    "def set_object(\n",
    "    storage_client: any,\n",
    "    bucket_name: str,\n",
    "    object_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any,\n",
    "    overwrite: bool,\n",
    "    object_data: any,\n",
    "    object_metadata: any\n",
    "):\n",
    "    checked_object = check_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = bucket_name,\n",
    "        object_name = object_name,\n",
    "        path_replacers = path_replacers,\n",
    "        path_names = path_names\n",
    "    )\n",
    "    \n",
    "    perform = True\n",
    "    if not len(checked_object['general-meta']) == 0 and not overwrite:\n",
    "        perform = False\n",
    "    \n",
    "    if perform:\n",
    "        create_or_update_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = checked_object['path'],\n",
    "            object_data = object_data,\n",
    "            object_metadata = object_metadata\n",
    "        )\n",
    "\n",
    "def check_bucket(\n",
    "    storage_client: any,\n",
    "    bucket_name: str\n",
    ") -> any:\n",
    "    return get_bucket_info(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = bucket_name\n",
    "    )\n",
    "\n",
    "def check_buckets(\n",
    "    storage_client: any\n",
    ") -> any:\n",
    "    return get_container_info( \n",
    "        storage_client = storage_client\n",
    "    )\n",
    "\n",
    "def gather_time(\n",
    "    storage_client: any,\n",
    "    storage_name: any,\n",
    "    time_group: any,\n",
    "    time_name: any,\n",
    "    start_time: int,\n",
    "    end_time: int\n",
    "):\n",
    "    time_object = get_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = storage_name,\n",
    "        object_name = 'time',\n",
    "        path_replacers = {\n",
    "            'name': time_group\n",
    "        },\n",
    "        path_names = []\n",
    "    )\n",
    "\n",
    "    time_data = {}\n",
    "    time_metadata = {} \n",
    "    if time_object is None:\n",
    "        time_data = {}\n",
    "        time_metadata = general_object_metadata()\n",
    "    else:\n",
    "        time_data = time_object['data']\n",
    "        time_metadata = time_object['custom-meta']\n",
    "    \n",
    "    current_key_amount = len(time_data)\n",
    "    current_key_full = False\n",
    "    current_key = str(current_key_amount)\n",
    "    if 0 < current_key_amount:\n",
    "        time_object = time_data[current_key]\n",
    "        if 0 < time_object['total-seconds']:\n",
    "            current_key_full = True\n",
    "    \n",
    "    changed = False\n",
    "    if 0 < end_time and 0 < current_key_amount and not current_key_full:\n",
    "        stored_start_time = time_data[current_key]['start-time']\n",
    "        time_diff = (end_time-stored_start_time)\n",
    "        time_data[current_key]['end-time'] = end_time\n",
    "        time_data[current_key]['total-seconds'] = round(time_diff,5)\n",
    "        changed = True\n",
    "    else:\n",
    "        next_key_amount = len(time_data) + 1\n",
    "        new_key = str(next_key_amount)\n",
    "    \n",
    "        if 0 < start_time and 0 == end_time:\n",
    "            time_data[new_key] = {\n",
    "                'name': time_name,\n",
    "                'start-time': start_time,\n",
    "                'end-time': 0,\n",
    "                'total-seconds': 0\n",
    "            }\n",
    "            changed = True\n",
    "\n",
    "        if 0 < start_time and 0 < end_time:\n",
    "            time_diff = (end_time-start_time)\n",
    "            time_data[new_key] = {\n",
    "                'name': time_name,\n",
    "                'start-time': start_time,\n",
    "                'end-time': end_time,\n",
    "                'total-seconds': round(time_diff,5)\n",
    "            }\n",
    "            changed = True\n",
    "\n",
    "    if changed:\n",
    "        time_metadata['version'] = time_metadata['version'] + 1\n",
    "        set_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = storage_name,\n",
    "            object_name = 'time',\n",
    "            path_replacers = {\n",
    "                'name': time_group\n",
    "            },\n",
    "            path_names = [],\n",
    "            overwrite = True,\n",
    "            object_data = time_data,\n",
    "            object_metadata = time_metadata \n",
    "        )\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def get_general_metrics():\n",
    "    general_metrics = TM.MetricCollection([\n",
    "        TM.classification.MulticlassAccuracy(\n",
    "            num_classes = 10,\n",
    "            average = 'macro'\n",
    "        ),\n",
    "        TM.classification.MulticlassPrecision(\n",
    "            num_classes = 10,\n",
    "            average = 'macro'\n",
    "        ),\n",
    "        TM.classification.MulticlassRecall(\n",
    "            num_classes = 10,\n",
    "            average = 'macro'\n",
    "        )\n",
    "    ])\n",
    "    return general_metrics\n",
    "    \n",
    "def get_class_metrics():\n",
    "    class_metrics = TM.MetricCollection([\n",
    "        TM.classification.MulticlassAccuracy(\n",
    "            num_classes = 10,\n",
    "            average = None\n",
    "        ),\n",
    "        TM.classification.MulticlassPrecision(\n",
    "            num_classes = 10,\n",
    "            average = None\n",
    "        ),\n",
    "        TM.classification.MulticlassRecall(\n",
    "            num_classes = 10,\n",
    "            average = None\n",
    "        )\n",
    "    ])\n",
    "    return class_metrics\n",
    "\n",
    "@ray.remote\n",
    "def remote_model_training(\n",
    "    storage_client: any,\n",
    "    storage_name: any,\n",
    "    folder_name: str,\n",
    "    seed: int,\n",
    "    train_print_rate: int,\n",
    "    epochs: int,\n",
    "    learning_rate: float,\n",
    "    momentum: float,\n",
    "    train_loader: any, \n",
    "    test_loader: any\n",
    "):\n",
    "    try:\n",
    "        time_start = t.time()\n",
    "    \n",
    "        print('Defining model')\n",
    "        model = CNNClassifier()\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(), \n",
    "            lr = learning_rate, \n",
    "            momentum = momentum\n",
    "        )\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "        print('Defining metrics')\n",
    "        general_metrics = get_general_metrics()\n",
    "        class_metrics = get_class_metrics()\n",
    "        \n",
    "        print('Starting model training')\n",
    "        current_epoch = 0\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            model.train()\n",
    "            for i, data in enumerate(train_loader):\n",
    "                inputs, labels = data\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "    \n",
    "                preds = torch.max(outputs, 1)[1]\n",
    "        \n",
    "                general_metrics(preds, labels)\n",
    "                \n",
    "                if (i + 1) % train_print_rate == 0:\n",
    "                    avg_loss = running_loss / train_print_rate\n",
    "                    train_general_metrics = general_metrics.compute()\n",
    "                    acc = round(train_general_metrics['MulticlassAccuracy'].item(),3)\n",
    "                    pre = round(train_general_metrics['MulticlassPrecision'].item(),3)\n",
    "                    rec = round(train_general_metrics['MulticlassRecall'].item(),3)\n",
    "                    general_metrics.reset()\n",
    "                    print(f'Epoch: {epoch + 1}/{epochs}, Batch {i + 1}, Loss: {avg_loss}, Accuracy: {acc}, Precision: {pre}, Recall: {rec}')\n",
    "                    running_loss = 0.0 \n",
    "            current_epoch += 1\n",
    "        print('Training complete')\n",
    "        \n",
    "        general_metrics.reset()\n",
    "        \n",
    "        print('Starting model testing')\n",
    "        running_loss = 0.0\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for i, data in enumerate(test_loader):\n",
    "                inputs, labels = data\n",
    "                outputs = model(inputs)\n",
    "                preds = torch.max(outputs, 1)[1]\n",
    "                loss = criterion(outputs, labels)\n",
    "                general_metrics(preds, labels)\n",
    "                class_metrics(preds, labels)\n",
    "                predictions.extend(preds.tolist())\n",
    "                running_loss += loss.item()\n",
    "        print('Testing complete')\n",
    "    \n",
    "        print('Storing created artifacts')\n",
    "        \n",
    "        test_general_metrics = general_metrics.compute()\n",
    "        test_class_metrics = class_metrics.compute()\n",
    "    \n",
    "        general_metrics.reset()\n",
    "        class_metrics.reset()\n",
    "        \n",
    "        print('Storing predictions')\n",
    "        \n",
    "        set_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = storage_name,\n",
    "            object_name = 'artifacts',\n",
    "            path_replacers = {\n",
    "                'name': folder_name\n",
    "            },\n",
    "            path_names = [\n",
    "                'predictions'\n",
    "            ],\n",
    "            overwrite = True,\n",
    "            object_data = predictions,\n",
    "            object_metadata = general_object_metadata()\n",
    "        )\n",
    "    \n",
    "        print('Formatting model parameters')\n",
    "        model_parameters = model.state_dict()\n",
    "        optimizer_parameters = optimizer.state_dict()\n",
    "    \n",
    "        parameters = {\n",
    "            'epoch': current_epoch,\n",
    "            'model': model_parameters,\n",
    "            'optimizer': optimizer_parameters\n",
    "        }\n",
    "\n",
    "        print('Storing parameters')\n",
    "        \n",
    "        set_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = storage_name,\n",
    "            object_name = 'artifacts',\n",
    "            path_replacers = {\n",
    "                'name': folder_name\n",
    "            },\n",
    "            path_names = [\n",
    "                'parameters'\n",
    "            ],\n",
    "            overwrite = True,\n",
    "            object_data = parameters,\n",
    "            object_metadata = general_object_metadata()\n",
    "        )\n",
    "    \n",
    "        print('Formatting model metrics')\n",
    "        accuracy = test_general_metrics['MulticlassAccuracy'].item()\n",
    "        precision = test_general_metrics['MulticlassPrecision'].item()\n",
    "        recall = test_general_metrics['MulticlassRecall'].item()\n",
    "    \n",
    "        class_accuracy = test_class_metrics['MulticlassAccuracy'].tolist()\n",
    "        class_precision = test_class_metrics['MulticlassPrecision'].tolist()\n",
    "        class_recall = test_class_metrics['MulticlassRecall'].tolist()\n",
    "    \n",
    "        metrics = {\n",
    "            'name': 'Convolutional-neural-network-classifier',\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'class-accuracy': class_accuracy,\n",
    "            'class-precision': class_precision,\n",
    "            'class-recall': class_recall\n",
    "        }\n",
    "\n",
    "        print('Storing metrics')\n",
    "        \n",
    "        set_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = storage_name,\n",
    "            object_name = 'artifacts',\n",
    "            path_replacers = {\n",
    "                'name': folder_name\n",
    "            },\n",
    "            path_names = [\n",
    "                'metrics'\n",
    "            ],\n",
    "            overwrite = True,\n",
    "            object_data = metrics,\n",
    "            object_metadata = general_object_metadata()\n",
    "        )\n",
    "    \n",
    "        time_end = t.time()\n",
    "        \n",
    "        gather_time(\n",
    "            storage_client = storage_client,\n",
    "            storage_name = storage_name,\n",
    "            time_group = 'ray-jobs',\n",
    "            time_name = 'remote-model-training',\n",
    "            start_time = time_start,\n",
    "            end_time = time_end\n",
    "        )\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    time_start = t.time()\n",
    "    print('Starting ray job')\n",
    "    print('Ray version is:' + str(ray.__version__))\n",
    "    print('Swiftclient version is:' + str(sc.__version__))\n",
    "    print('Torch version is:' + str(torch.__version__))\n",
    "    print('Torchmetrics version is:' + str(TM.__version__))\n",
    "    \n",
    "    input = json.loads(sys.argv[1])\n",
    "\n",
    "    storage_parameters = input['storage-parameters']\n",
    "\n",
    "    print('Setting storage client')\n",
    "    storage_client, storage_names = setup_storage(\n",
    "        storage_parameters = storage_parameters\n",
    "    )\n",
    "    print('Storage client setup')\n",
    "    \n",
    "    pipeline_storage = storage_names[-2]\n",
    "\n",
    "    print('Used bucket:' + str(pipeline_storage))\n",
    "\n",
    "    job_parameters = input['job-parameters']\n",
    "\n",
    "    folder_name = job_parameters['folder-name']\n",
    "    train_print_rate = job_parameters['train-print-rate']\n",
    "    seed = job_parameters['hp-seed']\n",
    "    epochs = job_parameters['hp-epochs']\n",
    "    learning_rate = job_parameters['hp-learning-rate']\n",
    "    momentum = job_parameters['hp-momentum']\n",
    "\n",
    "    print('Getting training data')\n",
    "\n",
    "    train_loader_object = get_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = pipeline_storage,\n",
    "        object_name = 'data',\n",
    "        path_replacers = {\n",
    "            'name': folder_name\n",
    "        },\n",
    "        path_names = [\n",
    "            'train'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_loader = train_loader_object['data']\n",
    "    \n",
    "    print('Getting testing data')\n",
    "\n",
    "    test_loader_object = get_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = pipeline_storage,\n",
    "        object_name = 'data',\n",
    "        path_replacers = {\n",
    "            'name': folder_name\n",
    "        },\n",
    "        path_names = [\n",
    "            'test'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    test_loader = test_loader_object['data']\n",
    "\n",
    "    print('Data loaded')\n",
    "\n",
    "    print('Starting training')\n",
    "    \n",
    "    training_status = ray.get(remote_model_training.remote(\n",
    "        storage_client = storage_client,\n",
    "        storage_name = pipeline_storage,\n",
    "        folder_name = folder_name,\n",
    "        seed = seed,\n",
    "        train_print_rate = train_print_rate,\n",
    "        epochs = epochs,\n",
    "        learning_rate = learning_rate,\n",
    "        momentum = momentum,\n",
    "        train_loader = train_loader,\n",
    "        test_loader = test_loader\n",
    "    ))\n",
    "\n",
    "    print('Training success:' + str(training_status))\n",
    "\n",
    "    time_end = t.time()\n",
    "\n",
    "    gather_time(\n",
    "        storage_client = storage_client,\n",
    "        storage_name = pipeline_storage,\n",
    "        time_group = 'ray-jobs',\n",
    "        time_name = 'train-fmnist-cnn',\n",
    "        start_time = time_start,\n",
    "        end_time = time_end\n",
    "    )\n",
    "\n",
    "    print('Ray job Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fbc8090-d68c-45f1-9772-f9f8e531d3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User code storage:integration-pipeline-s0-c0-u1-user-example-com\n",
      "Used code path:scripts/ray/train-fmnist-cnn.py\n",
      "Used object path:CODE/RAY/train-fmnist-cnn.py\n"
     ]
    }
   ],
   "source": [
    "set_code(\n",
    "    storage_client = storage_client,\n",
    "    storage_name = storage_names[-2],\n",
    "    file_path = 'scripts/ray/train-fmnist-cnn.py',\n",
    "    overwrite = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180d0cd-0683-443b-8d64-3b982c00d613",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e5ddd87-db0e-44f1-965a-1588a208b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp.aws import use_aws_secret\n",
    "from kfp.v2.dsl import (\n",
    "    component,\n",
    "    Input,\n",
    "    Output,\n",
    "    Dataset,\n",
    "    Metrics,\n",
    "    Artifact,\n",
    "    Model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7525e677-4338-4636-85ef-63b20bf39be8",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Please create components folder before running this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1386510d-7437-4e68-8338-bec5c8a6af91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component( \n",
    "    base_image = \"python:3.10\",\n",
    "    packages_to_install = [\n",
    "        \"python-swiftclient\",\n",
    "        \"torch==2.4.0+cpu\", \n",
    "        \"torchvision==0.19.0+cpu\"\n",
    "    ],\n",
    "    pip_index_urls=[\n",
    "        \"https://pypi.org/simple\",\n",
    "        \"https://download.pytorch.org/whl/cpu\",\n",
    "        \"https://download.pytorch.org/whl/cpu\"\n",
    "    ],\n",
    "    output_component_file = 'components/preprocess_component.yaml',\n",
    ")\n",
    "def preprocess( \n",
    "    storage_parameters: dict,\n",
    "    integration_parameters: dict,\n",
    ") -> bool:\n",
    "    import time as t \n",
    "    \n",
    "    import logging\n",
    "    import swiftclient as sc\n",
    "    import pickle\n",
    "    \n",
    "    import torch\n",
    "    from torchvision import datasets\n",
    "    import torchvision.transforms as T\n",
    "\n",
    "    import re\n",
    "\n",
    "    def set_formatted_user(\n",
    "        user: str   \n",
    "    ) -> any:\n",
    "        return re.sub(r'[^a-z0-9]+', '-', user)\n",
    "    def general_object_metadata():\n",
    "        general_object_metadata = {\n",
    "            'version': 1\n",
    "        }\n",
    "        return general_object_metadata\n",
    "    \n",
    "    def is_swift_client(\n",
    "        storage_client: any\n",
    "    ) -> any:\n",
    "        return isinstance(storage_client, sc.Connection)\n",
    "    \n",
    "    def swift_setup_client(\n",
    "        pre_auth_url: str,\n",
    "        pre_auth_token: str,\n",
    "        user_domain_name: str,\n",
    "        project_domain_name: str,\n",
    "        project_name: str,\n",
    "        auth_version: str\n",
    "    ) -> any:\n",
    "        swift_client = sc.Connection(\n",
    "            preauthurl = pre_auth_url,\n",
    "            preauthtoken = pre_auth_token,\n",
    "            os_options = {\n",
    "                'user_domain_name': user_domain_name,\n",
    "                'project_domain_name': project_domain_name,\n",
    "                'project_name': project_name\n",
    "            },\n",
    "            auth_version = auth_version\n",
    "        )\n",
    "        return swift_client\n",
    "    \n",
    "    def swift_create_bucket(\n",
    "        swift_client: any,\n",
    "        bucket_name: str\n",
    "    ) -> bool:\n",
    "        try:\n",
    "            swift_client.put_container(\n",
    "                container = bucket_name\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def swift_check_bucket(\n",
    "        swift_client: any,\n",
    "        bucket_name:str\n",
    "    ) -> any:\n",
    "        try:\n",
    "            bucket_info = swift_client.get_container(\n",
    "                container = bucket_name\n",
    "            )\n",
    "            bucket_metadata = bucket_info[0]\n",
    "            list_of_objects = bucket_info[1]\n",
    "            return {'metadata': bucket_metadata, 'objects': list_of_objects}\n",
    "        except Exception as e:\n",
    "            return {} \n",
    "    \n",
    "    def swift_delete_bucket(\n",
    "        swift_client: any,\n",
    "        bucket_name: str\n",
    "    ) -> bool:\n",
    "        try:\n",
    "            swift_client.delete_container(\n",
    "                container = bucket_name\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def swift_list_buckets(\n",
    "        swift_client: any\n",
    "    ) -> any:\n",
    "        try:\n",
    "            account_buckets = swift_client.get_account()[1]\n",
    "            return account_buckets\n",
    "        except Exception as e:\n",
    "            return {}\n",
    "    \n",
    "    def swift_create_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str, \n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ) -> bool: \n",
    "        try:\n",
    "            swift_client.put_object(\n",
    "                container = bucket_name,\n",
    "                obj = object_path,\n",
    "                contents = object_data,\n",
    "                headers = object_metadata\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def swift_check_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str\n",
    "    ) -> any: \n",
    "        try:\n",
    "            object_metadata = swift_client.head_object(\n",
    "                container = bucket_name,\n",
    "                obj = object_path\n",
    "            )       \n",
    "            return object_metadata\n",
    "        except Exception as e:\n",
    "            return {} \n",
    "    \n",
    "    def swift_get_object(\n",
    "        swift_client:any,\n",
    "        bucket_name: str,\n",
    "        object_path: str\n",
    "    ) -> any:\n",
    "        try:\n",
    "            response = swift_client.get_object(\n",
    "                container = bucket_name,\n",
    "                obj = object_path \n",
    "            )\n",
    "            object_info = response[0]\n",
    "            object_data = response[1]\n",
    "            return {'data': object_data, 'info': object_info}\n",
    "        except Exception as e:\n",
    "            return {}     \n",
    "     \n",
    "    def swift_remove_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str\n",
    "    ) -> bool: \n",
    "        try:\n",
    "            swift_client.delete_object(\n",
    "                container = bucket_name, \n",
    "                obj = object_path\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    def swift_update_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str, \n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ) -> bool:  \n",
    "        remove = swift_remove_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path\n",
    "        )\n",
    "        if not remove:\n",
    "            return False\n",
    "        create = swift_create_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            object_data = object_data,\n",
    "            object_metadata = object_metadata\n",
    "        )\n",
    "        return create\n",
    "    \n",
    "    def swift_create_or_update_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str, \n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ) -> any:\n",
    "        bucket_info = swift_check_bucket(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        \n",
    "        if len(bucket_info) == 0:\n",
    "            creation_status = swift_create_bucket(\n",
    "                swift_client = swift_client, \n",
    "                bucket_name = bucket_name\n",
    "            )\n",
    "            if not creation_status:\n",
    "                return False\n",
    "        \n",
    "        object_info = swift_check_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path\n",
    "        )\n",
    "        \n",
    "        if len(object_info) == 0:\n",
    "            return swift_create_object(\n",
    "                swift_client = swift_client, \n",
    "                bucket_name = bucket_name, \n",
    "                object_path = object_path, \n",
    "                object_data = object_data,\n",
    "                object_metadata = object_metadata\n",
    "            )\n",
    "        else:\n",
    "            return swift_update_object(\n",
    "                swift_client = swift_client, \n",
    "                bucket_name = bucket_name, \n",
    "                object_path = object_path, \n",
    "                object_data = object_data,\n",
    "                object_metadata = object_metadata\n",
    "            )\n",
    "    \n",
    "    def set_encoded_metadata(\n",
    "        used_client: str,\n",
    "        object_metadata: any\n",
    "    ) -> any:\n",
    "        encoded_metadata = {}\n",
    "        if used_client == 'swift':\n",
    "            key_initial = 'x-object-meta'\n",
    "            for key, value in object_metadata.items():\n",
    "                encoded_key = key_initial + '-' + key\n",
    "                if isinstance(value, list):\n",
    "                    encoded_metadata[encoded_key] = 'list=' + ','.join(map(str, value))\n",
    "                    continue\n",
    "                encoded_metadata[encoded_key] = str(value)\n",
    "        return encoded_metadata\n",
    "    \n",
    "    def get_general_metadata(\n",
    "        used_client: str,\n",
    "        object_metadata: any\n",
    "    ) -> any:\n",
    "        general_metadata = {}\n",
    "        if used_client == 'swift':\n",
    "            key_initial = 'x-object-meta'\n",
    "            for key, value in object_metadata.items():\n",
    "                if not key_initial == key[:len(key_initial)]:\n",
    "                    general_metadata[key] = value\n",
    "        return general_metadata\n",
    "    \n",
    "    def get_decoded_metadata(\n",
    "        used_client: str,\n",
    "        object_metadata: any\n",
    "    ) -> any: \n",
    "        decoded_metadata = {}\n",
    "        if used_client == 'swift':\n",
    "            key_initial = 'x-object-meta'\n",
    "            for key, value in object_metadata.items():\n",
    "                if key_initial == key[:len(key_initial)]:\n",
    "                    decoded_key = key[len(key_initial) + 1:]\n",
    "                    if 'list=' in value:\n",
    "                        string_integers = value.split('=')[1]\n",
    "                        values = string_integers.split(',')\n",
    "                        if len(values) == 1 and values[0] == '':\n",
    "                            decoded_metadata[decoded_key] = []\n",
    "                        else:\n",
    "                            try:\n",
    "                                decoded_metadata[decoded_key] = list(map(int, values))\n",
    "                            except:\n",
    "                                decoded_metadata[decoded_key] = list(map(str, values))\n",
    "                        continue\n",
    "                    if value.isnumeric():\n",
    "                        decoded_metadata[decoded_key] = int(value)\n",
    "                        continue\n",
    "                    decoded_metadata[decoded_key] = value\n",
    "        return decoded_metadata\n",
    "    \n",
    "    def set_bucket_names(\n",
    "        storage_parameters: any\n",
    "    ) -> any:\n",
    "        storage_names = []\n",
    "        bucket_prefix = storage_parameters['bucket-prefix']\n",
    "        ice_id = storage_parameters['ice-id']\n",
    "        user = storage_parameters['user']\n",
    "        storage_names.append(bucket_prefix + '-forwarder-' + ice_id)\n",
    "        storage_names.append(bucket_prefix + '-submitter-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "        storage_names.append(bucket_prefix + '-pipeline-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "        storage_names.append(bucket_prefix + '-experiment-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "        return storage_names\n",
    "    \n",
    "    def setup_storage(\n",
    "        storage_parameters: any\n",
    "    ) -> any:\n",
    "        storage_client = setup_storage_client(\n",
    "            storage_parameters = storage_parameters\n",
    "        ) \n",
    "        \n",
    "        storage_name = set_bucket_names(\n",
    "        storage_parameters = storage_parameters\n",
    "        )\n",
    "        \n",
    "        return storage_client, storage_name\n",
    "    \n",
    "    def setup_storage_client(\n",
    "        storage_parameters: any\n",
    "    ) -> any:\n",
    "        storage_client = None\n",
    "        if storage_parameters['used-client'] == 'swift':\n",
    "            storage_client = swift_setup_client(\n",
    "                pre_auth_url = storage_parameters['pre-auth-url'],\n",
    "                pre_auth_token = storage_parameters['pre-auth-token'],\n",
    "                user_domain_name = storage_parameters['user-domain-name'],\n",
    "                project_domain_name = storage_parameters['project-domain-name'],\n",
    "                project_name = storage_parameters['project-name'],\n",
    "                auth_version = storage_parameters['auth-version']\n",
    "            )\n",
    "        return storage_client\n",
    "    \n",
    "    def check_object_metadata(\n",
    "        storage_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str\n",
    "    ) -> any: \n",
    "        object_metadata = {\n",
    "            'general-meta': {},\n",
    "            'custom-meta': {}\n",
    "        }\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            all_metadata = swift_check_object(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path\n",
    "            ) \n",
    "\n",
    "            general_metadata = {}\n",
    "            custom_metadata = {}\n",
    "            if not len(all_metadata) == 0:\n",
    "                general_metadata = get_general_metadata(\n",
    "                    used_client = 'swift',\n",
    "                    object_metadata = all_metadata\n",
    "                )\n",
    "                custom_metadata = get_decoded_metadata(\n",
    "                    used_client = 'swift',\n",
    "                    object_metadata = all_metadata\n",
    "                )\n",
    "\n",
    "            object_metadata['general-meta'] = general_metadata\n",
    "            object_metadata['custom-meta'] = custom_metadata\n",
    "\n",
    "        return object_metadata\n",
    "    \n",
    "    def get_object_content(\n",
    "        storage_client: any,\n",
    "        bucket_name: str,\n",
    "        object_path: str\n",
    "    ) -> any:\n",
    "        object_content = {}\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            fetched_object = swift_get_object(\n",
    "                swift_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = object_path\n",
    "            )\n",
    "            object_content['data'] = pickle.loads(fetched_object['data'])\n",
    "            object_content['general-meta'] = get_general_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = fetched_object['info']\n",
    "            )\n",
    "            object_content['custom-meta'] = get_decoded_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = fetched_object['info']\n",
    "            )\n",
    "        return object_content\n",
    "        \n",
    "    def remove_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str\n",
    "    ) -> bool: \n",
    "        removed = False\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            removed = swift_remove_object(\n",
    "                swift_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = object_path\n",
    "            )\n",
    "        return removed\n",
    "    \n",
    "    def create_or_update_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str, \n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ) -> any:\n",
    "        success = False\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            formatted_data = pickle.dumps(object_data)\n",
    "            formatted_metadata = set_encoded_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = object_metadata\n",
    "            )\n",
    "\n",
    "            success = swift_create_or_update_object(\n",
    "                swift_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = object_path,\n",
    "                object_data = formatted_data,\n",
    "                object_metadata = formatted_metadata\n",
    "            )\n",
    "        return success\n",
    "    \n",
    "    def format_bucket_metadata(\n",
    "        used_client: str,\n",
    "        bucket_metadata: any\n",
    "    ) -> any:\n",
    "        formatted_metadata = {}\n",
    "        if used_client == 'swift':\n",
    "            relevant_values = {\n",
    "                'x-container-object-count': 'object-count',\n",
    "                'x-container-bytes-used-actual': 'used-bytes',\n",
    "                'last-modified': 'date',\n",
    "                'content-type': 'type'\n",
    "            }\n",
    "            formatted_metadata = {}\n",
    "            for key,value in bucket_metadata.items():\n",
    "                if key in relevant_values:\n",
    "                    formatted_key = relevant_values[key]\n",
    "                    formatted_metadata[formatted_key] = value\n",
    "        return formatted_metadata\n",
    "    \n",
    "    def format_bucket_objects(\n",
    "        used_client: str,\n",
    "        bucket_objects: any\n",
    "    ) -> any:\n",
    "        formatted_objects = {}\n",
    "        if used_client == 'swift':\n",
    "            for bucket_object in bucket_objects:\n",
    "                formatted_object_metadata = {\n",
    "                    'hash': 'id',\n",
    "                    'bytes': 'used-bytes',\n",
    "                    'last_modified': 'date'\n",
    "                }\n",
    "                object_key = None\n",
    "                object_metadata = {}\n",
    "                for key, value in bucket_object.items():\n",
    "                    if key == 'name':\n",
    "                        object_key = value\n",
    "                    if key in formatted_object_metadata:\n",
    "                        formatted_key = formatted_object_metadata[key]\n",
    "                        object_metadata[formatted_key] = value\n",
    "                formatted_objects[object_key] = object_metadata\n",
    "        return formatted_objects\n",
    "    \n",
    "    def format_bucket_info(\n",
    "        used_client: str,\n",
    "        bucket_info: any\n",
    "    ) -> any:\n",
    "        bucket_metadata = {}\n",
    "        bucket_objects = {}\n",
    "        if used_client == 'swift':\n",
    "            bucket_metadata = format_bucket_metadata(\n",
    "                used_client = used_client,\n",
    "                bucket_metadata = bucket_info['metadata']\n",
    "            )\n",
    "            bucket_objects = format_bucket_objects(\n",
    "                used_client = used_client,\n",
    "                bucket_objects = bucket_info['objects']\n",
    "            )\n",
    "        return {'metadata': bucket_metadata, 'objects': bucket_objects} \n",
    "    \n",
    "    def get_bucket_info(\n",
    "        storage_client: any,\n",
    "        bucket_name: str\n",
    "    ) -> any:\n",
    "        bucket_info = {}\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            unformatted_bucket_info = swift_check_bucket(\n",
    "                swift_client = storage_client,\n",
    "                bucket_name = bucket_name\n",
    "            )\n",
    "            bucket_info = format_bucket_info(\n",
    "                used_client = 'swift',\n",
    "                bucket_info = unformatted_bucket_info\n",
    "            )\n",
    "        return bucket_info\n",
    "    \n",
    "    def format_container_info(\n",
    "        used_client: str,\n",
    "        container_info: any\n",
    "    ) -> any:\n",
    "        formatted_container_info = {}\n",
    "        if used_client == 'swift':\n",
    "            for bucket in container_info:\n",
    "                bucket_name = bucket['name']\n",
    "                bucket_count = bucket['count']\n",
    "                bucket_size = bucket['bytes']\n",
    "                formatted_container_info[bucket_name] = {\n",
    "                    'amount': bucket_count,\n",
    "                    'size': bucket_size\n",
    "                }\n",
    "        return formatted_container_info\n",
    "    \n",
    "    def get_container_info( \n",
    "        storage_client: any\n",
    "    ) -> any:\n",
    "        container_info = {}\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            unformatted_container_info = swift_list_buckets(\n",
    "                swift_client = storage_client \n",
    "            )\n",
    "            container_info = format_container_info(\n",
    "                used_client = 'swift',\n",
    "                container_info = unformatted_container_info\n",
    "            )\n",
    "        return container_info\n",
    "    \n",
    "    def set_object_path(\n",
    "        object_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any\n",
    "    ):\n",
    "        object_paths = {\n",
    "            'root': 'name',\n",
    "            'code': 'CODE/name',\n",
    "            'slurm': 'CODE/SLURM/name',\n",
    "            'ray': 'CODE/RAY/name',\n",
    "            'data': 'DATA/name',\n",
    "            'artifacts': 'ARTIFACTS/name',\n",
    "            'time': 'TIMES/name'\n",
    "        }\n",
    "\n",
    "        i = 0\n",
    "        path_split = object_paths[object_name].split('/')\n",
    "        for name in path_split:\n",
    "            if name in path_replacers:\n",
    "                replacer = path_replacers[name]\n",
    "                if 0 < len(replacer):\n",
    "                    path_split[i] = replacer\n",
    "            i = i + 1\n",
    "        \n",
    "        if not len(path_names) == 0:\n",
    "            path_split.extend(path_names)\n",
    "\n",
    "        object_path = '/'.join(path_split)\n",
    "        return object_path\n",
    "    \n",
    "    def setup_storage(\n",
    "        storage_parameters: any\n",
    "    ) -> any:\n",
    "        storage_client = setup_storage_client(\n",
    "            storage_parameters = storage_parameters\n",
    "        ) \n",
    "        \n",
    "        storage_name = set_bucket_names(\n",
    "        storage_parameters = storage_parameters\n",
    "        )\n",
    "        \n",
    "        return storage_client, storage_name\n",
    "    \n",
    "    def check_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str,\n",
    "        object_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any\n",
    "    ) -> bool:\n",
    "        object_path = set_object_path(\n",
    "            object_name = object_name,\n",
    "            path_replacers = path_replacers,\n",
    "            path_names = path_names\n",
    "        )\n",
    "        object_metadata = check_object_metadata(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path\n",
    "        )\n",
    "        object_metadata['path'] = object_path\n",
    "        return object_metadata\n",
    "    \n",
    "    def get_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str,\n",
    "        object_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any\n",
    "    ) -> any:\n",
    "        checked_object = check_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_name = object_name,\n",
    "            path_replacers = path_replacers,\n",
    "            path_names = path_names\n",
    "        )\n",
    "\n",
    "        object_data = None\n",
    "        if not len(checked_object['general-meta']) == 0:\n",
    "            object_data = get_object_content(\n",
    "                storage_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = checked_object['path']\n",
    "            )\n",
    "\n",
    "        return object_data\n",
    "    \n",
    "    def set_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str,\n",
    "        object_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any,\n",
    "        overwrite: bool,\n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ):\n",
    "        checked_object = check_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_name = object_name,\n",
    "            path_replacers = path_replacers,\n",
    "            path_names = path_names\n",
    "        )\n",
    "        \n",
    "        perform = True\n",
    "        if not len(checked_object['general-meta']) == 0 and not overwrite:\n",
    "            perform = False\n",
    "        \n",
    "        if perform:\n",
    "            create_or_update_object(\n",
    "                storage_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = checked_object['path'],\n",
    "                object_data = object_data,\n",
    "                object_metadata = object_metadata\n",
    "            )\n",
    "    \n",
    "    def check_bucket(\n",
    "        storage_client: any,\n",
    "        bucket_name: str\n",
    "    ) -> any:\n",
    "        return get_bucket_info(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "    \n",
    "    def check_buckets(\n",
    "        storage_client: any\n",
    "    ) -> any:\n",
    "        return get_container_info( \n",
    "            storage_client = storage_client\n",
    "        )\n",
    "\n",
    "    def gather_time(\n",
    "        storage_client: any,\n",
    "        storage_name: any,\n",
    "        time_group: any,\n",
    "        time_name: any,\n",
    "        start_time: int,\n",
    "        end_time: int\n",
    "    ):\n",
    "        time_object = get_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = storage_name,\n",
    "            object_name = 'time',\n",
    "            path_replacers = {\n",
    "                'name': time_group\n",
    "            },\n",
    "            path_names = []\n",
    "        )\n",
    "\n",
    "        time_data = {}\n",
    "        time_metadata = {} \n",
    "        if time_object is None:\n",
    "            time_data = {}\n",
    "            time_metadata = general_object_metadata()\n",
    "        else:\n",
    "            time_data = time_object['data']\n",
    "            time_metadata = time_object['custom-meta']\n",
    "        \n",
    "        current_key_amount = len(time_data)\n",
    "        current_key_full = False\n",
    "        current_key = str(current_key_amount)\n",
    "        if 0 < current_key_amount:\n",
    "            time_object = time_data[current_key]\n",
    "            if 0 < time_object['total-seconds']:\n",
    "                current_key_full = True\n",
    "        \n",
    "        changed = False\n",
    "        if 0 < end_time and 0 < current_key_amount and not current_key_full:\n",
    "            stored_start_time = time_data[current_key]['start-time']\n",
    "            time_diff = (end_time-stored_start_time)\n",
    "            time_data[current_key]['end-time'] = end_time\n",
    "            time_data[current_key]['total-seconds'] = round(time_diff,5)\n",
    "            changed = True\n",
    "        else:\n",
    "            next_key_amount = len(time_data) + 1\n",
    "            new_key = str(next_key_amount)\n",
    "        \n",
    "            if 0 < start_time and 0 == end_time:\n",
    "                time_data[new_key] = {\n",
    "                    'name': time_name,\n",
    "                    'start-time': start_time,\n",
    "                    'end-time': 0,\n",
    "                    'total-seconds': 0\n",
    "                }\n",
    "                changed = True\n",
    "\n",
    "            if 0 < start_time and 0 < end_time:\n",
    "                time_diff = (end_time-start_time)\n",
    "                time_data[new_key] = {\n",
    "                    'name': time_name,\n",
    "                    'start-time': start_time,\n",
    "                    'end-time': end_time,\n",
    "                    'total-seconds': round(time_diff,5)\n",
    "                }\n",
    "                changed = True\n",
    "\n",
    "        if changed:\n",
    "            time_metadata['version'] = time_metadata['version'] + 1\n",
    "            set_object(\n",
    "                storage_client = storage_client,\n",
    "                bucket_name = storage_name,\n",
    "                object_name = 'time',\n",
    "                path_replacers = {\n",
    "                    'name': time_group\n",
    "                },\n",
    "                path_names = [],\n",
    "                overwrite = True,\n",
    "                object_data = time_data,\n",
    "                object_metadata = time_metadata \n",
    "            )\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    component_time_start = t.time()\n",
    "\n",
    "    storage_client, storage_names = setup_storage( \n",
    "        storage_parameters = storage_parameters\n",
    "    )\n",
    "\n",
    "    logger.info('Storage setup')\n",
    "\n",
    "    logger.info('Variable setup')\n",
    "    \n",
    "    pipeline_bucket = storage_names[-2]\n",
    "\n",
    "    logger.info('Utilized bucket: ' + str(pipeline_bucket))\n",
    "\n",
    "    folder_name = integration_parameters['folder-name']\n",
    "    train_batch_size = integration_parameters['ray-parameters']['job-parameters']['hp-train-batch-size']\n",
    "    test_batch_size = integration_parameters['ray-parameters']['job-parameters']['hp-test-batch-size']\n",
    "\n",
    "    logger.info('Checking train loader')\n",
    "\n",
    "    train_loader_metadata = check_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = pipeline_bucket,\n",
    "        object_name = 'data',\n",
    "        path_replacers = {\n",
    "            'name': folder_name\n",
    "        },\n",
    "        path_names = [\n",
    "            'train'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if len(train_loader_metadata['general-meta']) == 0:\n",
    "        logger.info('Preprocessing train')\n",
    "        \n",
    "        train_transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "        train_data = datasets.FashionMNIST(\n",
    "            root = './data', \n",
    "            train = True, \n",
    "            download = True, \n",
    "            transform = train_transform\n",
    "        )\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            train_data, \n",
    "            batch_size = train_batch_size, \n",
    "            shuffle = True\n",
    "        )\n",
    "\n",
    "        set_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = pipeline_bucket,\n",
    "            object_name = 'data',\n",
    "            path_replacers = {\n",
    "                'name': folder_name\n",
    "            },\n",
    "            path_names = [\n",
    "                'train'\n",
    "            ],\n",
    "            overwrite = True,\n",
    "            object_data = train_loader,\n",
    "            object_metadata = general_object_metadata()\n",
    "        )\n",
    "        logger.info('Train loader stored')\n",
    "\n",
    "    logger.info('Checking test loader')\n",
    "\n",
    "    test_loader_metadata = check_object(\n",
    "        storage_client = storage_client,\n",
    "        bucket_name = pipeline_bucket,\n",
    "        object_name = 'data',\n",
    "        path_replacers = {\n",
    "            'name': folder_name\n",
    "        },\n",
    "        path_names = [\n",
    "            'test'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if len(test_loader_metadata['general-meta']) == 0:\n",
    "        logger.info('Preprocessing test')\n",
    "\n",
    "        test_transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            T.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "        test_data = datasets.FashionMNIST(\n",
    "            root = './data', \n",
    "            train = False, \n",
    "            download = True, \n",
    "            transform = test_transform\n",
    "        )\n",
    "\n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            test_data, \n",
    "            batch_size = test_batch_size, \n",
    "            shuffle = False\n",
    "        )\n",
    "\n",
    "        set_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = pipeline_bucket,\n",
    "            object_name = 'data',\n",
    "            path_replacers = {\n",
    "                'name': folder_name\n",
    "            },\n",
    "            path_names = [ \n",
    "                'test'\n",
    "            ],\n",
    "            overwrite = True,\n",
    "            object_data = test_loader,\n",
    "            object_metadata = general_object_metadata()\n",
    "        )\n",
    "        logger.info('Test loader stored')\n",
    "        \n",
    "    component_time_end = t.time()\n",
    "    \n",
    "    gather_time(\n",
    "        storage_client = storage_client,\n",
    "        storage_name = pipeline_bucket,\n",
    "        time_group = 'components',\n",
    "        time_name = 'cloud-hpc-preprocess',\n",
    "        start_time = component_time_start,\n",
    "        end_time = component_time_end\n",
    "    )\n",
    "\n",
    "    logger.info('Preprocess complete')\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336c8bdd-cfbc-41ed-8b0c-d4b1ff1e0f58",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13eb7f58-3c98-45d2-a1ed-c78ce1dc273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "@component(\n",
    "    base_image = \"python:3.10\",\n",
    "    packages_to_install = [\n",
    "        \"python-swiftclient\",\n",
    "        \"ray[default]\",\n",
    "        \"mlflow~=2.12.2\", \n",
    "        \"boto3~=1.21.0\",\n",
    "        \"numpy\",\n",
    "        \"torch==2.4.0+cpu\" \n",
    "    ],\n",
    "    pip_index_urls=[\n",
    "        \"https://pypi.org/simple\",\n",
    "        \"https://pypi.org/simple\",\n",
    "        \"https://pypi.org/simple\",\n",
    "        \"https://pypi.org/simple\",\n",
    "        \"https://pypi.org/simple\",\n",
    "        \"https://download.pytorch.org/whl/cpu\"\n",
    "    ],\n",
    "    output_component_file = 'components/train_component.yaml',\n",
    ") \n",
    "def train(   \n",
    "    storage_parameters: dict,\n",
    "    integration_parameters: dict,\n",
    "    mlflow_parameters: dict\n",
    ") -> NamedTuple(\"Output\", [('storage_uri', str), ('run_id', str),]):\n",
    "    import logging\n",
    "    from collections import namedtuple\n",
    "    \n",
    "    import swiftclient as sc\n",
    "    import pickle\n",
    "    import requests\n",
    "    import json\n",
    "    \n",
    "    from datetime import datetime\n",
    "    import time as t\n",
    "        \n",
    "    import os\n",
    "    import mlflow\n",
    "    import mlflow.pytorch\n",
    "    \n",
    "    from ray.job_submission import JobSubmissionClient\n",
    "    from ray.job_submission import JobStatus\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    import numpy as np\n",
    "    import re\n",
    "\n",
    "    def set_formatted_user(\n",
    "        user: str   \n",
    "    ) -> any:\n",
    "        return re.sub(r'[^a-z0-9]+', '-', user)\n",
    "    def general_object_metadata():\n",
    "        general_object_metadata = {\n",
    "            'version': 1\n",
    "        }\n",
    "        return general_object_metadata\n",
    "   \n",
    "    def is_swift_client(\n",
    "        storage_client: any\n",
    "    ) -> any:\n",
    "        return isinstance(storage_client, sc.Connection)\n",
    "    \n",
    "    def swift_setup_client(\n",
    "        pre_auth_url: str,\n",
    "        pre_auth_token: str,\n",
    "        user_domain_name: str,\n",
    "        project_domain_name: str,\n",
    "        project_name: str,\n",
    "        auth_version: str\n",
    "    ) -> any:\n",
    "        swift_client = sc.Connection(\n",
    "            preauthurl = pre_auth_url,\n",
    "            preauthtoken = pre_auth_token,\n",
    "            os_options = {\n",
    "                'user_domain_name': user_domain_name,\n",
    "                'project_domain_name': project_domain_name,\n",
    "                'project_name': project_name\n",
    "            },\n",
    "            auth_version = auth_version\n",
    "        )\n",
    "        return swift_client\n",
    "    \n",
    "    def swift_create_bucket(\n",
    "        swift_client: any,\n",
    "        bucket_name: str\n",
    "    ) -> bool:\n",
    "        try:\n",
    "            swift_client.put_container(\n",
    "                container = bucket_name\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def swift_check_bucket(\n",
    "        swift_client: any,\n",
    "        bucket_name:str\n",
    "    ) -> any:\n",
    "        try:\n",
    "            bucket_info = swift_client.get_container(\n",
    "                container = bucket_name\n",
    "            )\n",
    "            bucket_metadata = bucket_info[0]\n",
    "            list_of_objects = bucket_info[1]\n",
    "            return {'metadata': bucket_metadata, 'objects': list_of_objects}\n",
    "        except Exception as e:\n",
    "            return {} \n",
    "    \n",
    "    def swift_delete_bucket(\n",
    "        swift_client: any,\n",
    "        bucket_name: str\n",
    "    ) -> bool:\n",
    "        try:\n",
    "            swift_client.delete_container(\n",
    "                container = bucket_name\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def swift_list_buckets(\n",
    "        swift_client: any\n",
    "    ) -> any:\n",
    "        try:\n",
    "            account_buckets = swift_client.get_account()[1]\n",
    "            return account_buckets\n",
    "        except Exception as e:\n",
    "            return {}\n",
    "    \n",
    "    def swift_create_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str, \n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ) -> bool: \n",
    "        try:\n",
    "            swift_client.put_object(\n",
    "                container = bucket_name,\n",
    "                obj = object_path,\n",
    "                contents = object_data,\n",
    "                headers = object_metadata\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def swift_check_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str\n",
    "    ) -> any: \n",
    "        try:\n",
    "            object_metadata = swift_client.head_object(\n",
    "                container = bucket_name,\n",
    "                obj = object_path\n",
    "            )       \n",
    "            return object_metadata\n",
    "        except Exception as e:\n",
    "            return {} \n",
    "    \n",
    "    def swift_get_object(\n",
    "        swift_client:any,\n",
    "        bucket_name: str,\n",
    "        object_path: str\n",
    "    ) -> any:\n",
    "        try:\n",
    "            response = swift_client.get_object(\n",
    "                container = bucket_name,\n",
    "                obj = object_path \n",
    "            )\n",
    "            object_info = response[0]\n",
    "            object_data = response[1]\n",
    "            return {'data': object_data, 'info': object_info}\n",
    "        except Exception as e:\n",
    "            return {}     \n",
    "      \n",
    "    def swift_remove_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str\n",
    "    ) -> bool: \n",
    "        try:\n",
    "            swift_client.delete_object(\n",
    "                container = bucket_name, \n",
    "                obj = object_path\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def swift_update_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str, \n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ) -> bool:  \n",
    "        remove = swift_remove_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path\n",
    "        )\n",
    "        if not remove:\n",
    "            return False\n",
    "        create = swift_create_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            object_data = object_data,\n",
    "            object_metadata = object_metadata\n",
    "        )\n",
    "        return create\n",
    "    \n",
    "    def swift_create_or_update_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str, \n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ) -> any:\n",
    "        bucket_info = swift_check_bucket(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        \n",
    "        if len(bucket_info) == 0:\n",
    "            creation_status = swift_create_bucket(\n",
    "                swift_client = swift_client, \n",
    "                bucket_name = bucket_name\n",
    "            )\n",
    "            if not creation_status:\n",
    "                return False\n",
    "        \n",
    "        object_info = swift_check_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path\n",
    "        )\n",
    "        \n",
    "        if len(object_info) == 0:\n",
    "            return swift_create_object(\n",
    "                swift_client = swift_client, \n",
    "                bucket_name = bucket_name, \n",
    "                object_path = object_path, \n",
    "                object_data = object_data,\n",
    "                object_metadata = object_metadata\n",
    "            )\n",
    "        else:\n",
    "            return swift_update_object(\n",
    "                swift_client = swift_client, \n",
    "                bucket_name = bucket_name, \n",
    "                object_path = object_path, \n",
    "                object_data = object_data,\n",
    "                object_metadata = object_metadata\n",
    "            )\n",
    "\n",
    "    def set_encoded_metadata(\n",
    "        used_client: str,\n",
    "        object_metadata: any\n",
    "    ) -> any:\n",
    "        encoded_metadata = {}\n",
    "        if used_client == 'swift':\n",
    "            key_initial = 'x-object-meta'\n",
    "            for key, value in object_metadata.items():\n",
    "                encoded_key = key_initial + '-' + key\n",
    "                if isinstance(value, list):\n",
    "                    encoded_metadata[encoded_key] = 'list=' + ','.join(map(str, value))\n",
    "                    continue\n",
    "                encoded_metadata[encoded_key] = str(value)\n",
    "        return encoded_metadata\n",
    "    \n",
    "    def get_general_metadata(\n",
    "        used_client: str,\n",
    "        object_metadata: any\n",
    "    ) -> any:\n",
    "        general_metadata = {}\n",
    "        if used_client == 'swift':\n",
    "            key_initial = 'x-object-meta'\n",
    "            for key, value in object_metadata.items():\n",
    "                if not key_initial == key[:len(key_initial)]:\n",
    "                    general_metadata[key] = value\n",
    "        return general_metadata\n",
    "    \n",
    "    def get_decoded_metadata(\n",
    "        used_client: str,\n",
    "        object_metadata: any\n",
    "    ) -> any: \n",
    "        decoded_metadata = {}\n",
    "        if used_client == 'swift':\n",
    "            key_initial = 'x-object-meta'\n",
    "            for key, value in object_metadata.items():\n",
    "                if key_initial == key[:len(key_initial)]:\n",
    "                    decoded_key = key[len(key_initial) + 1:]\n",
    "                    if 'list=' in value:\n",
    "                        string_integers = value.split('=')[1]\n",
    "                        values = string_integers.split(',')\n",
    "                        if len(values) == 1 and values[0] == '':\n",
    "                            decoded_metadata[decoded_key] = []\n",
    "                        else:\n",
    "                            try:\n",
    "                                decoded_metadata[decoded_key] = list(map(int, values))\n",
    "                            except:\n",
    "                                decoded_metadata[decoded_key] = list(map(str, values))\n",
    "                        continue\n",
    "                    if value.isnumeric():\n",
    "                        decoded_metadata[decoded_key] = int(value)\n",
    "                        continue\n",
    "                    decoded_metadata[decoded_key] = value\n",
    "        return decoded_metadata\n",
    "    \n",
    "    def set_bucket_names(\n",
    "        storage_parameters: any\n",
    "    ) -> any:\n",
    "        storage_names = []\n",
    "        bucket_prefix = storage_parameters['bucket-prefix']\n",
    "        ice_id = storage_parameters['ice-id']\n",
    "        user = storage_parameters['user']\n",
    "        storage_names.append(bucket_prefix + '-forwarder-' + ice_id)\n",
    "        storage_names.append(bucket_prefix + '-submitter-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "        storage_names.append(bucket_prefix + '-pipeline-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "        storage_names.append(bucket_prefix + '-experiment-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "        return storage_names\n",
    "    \n",
    "    def setup_storage(\n",
    "        storage_parameters: any\n",
    "    ) -> any:\n",
    "        storage_client = setup_storage_client(\n",
    "            storage_parameters = storage_parameters\n",
    "        ) \n",
    "        \n",
    "        storage_name = set_bucket_names(\n",
    "        storage_parameters = storage_parameters\n",
    "        )\n",
    "        \n",
    "        return storage_client, storage_name\n",
    "    \n",
    "    def setup_storage_client(\n",
    "        storage_parameters: any\n",
    "    ) -> any:\n",
    "        storage_client = None\n",
    "        if storage_parameters['used-client'] == 'swift':\n",
    "            storage_client = swift_setup_client(\n",
    "                pre_auth_url = storage_parameters['pre-auth-url'],\n",
    "                pre_auth_token = storage_parameters['pre-auth-token'],\n",
    "                user_domain_name = storage_parameters['user-domain-name'],\n",
    "                project_domain_name = storage_parameters['project-domain-name'],\n",
    "                project_name = storage_parameters['project-name'],\n",
    "                auth_version = storage_parameters['auth-version']\n",
    "            )\n",
    "        return storage_client\n",
    "    \n",
    "    def check_object_metadata(\n",
    "        storage_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str\n",
    "    ) -> any: \n",
    "        object_metadata = {\n",
    "            'general-meta': {},\n",
    "            'custom-meta': {}\n",
    "        }\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            all_metadata = swift_check_object(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path\n",
    "            ) \n",
    "\n",
    "            general_metadata = {}\n",
    "            custom_metadata = {}\n",
    "            if not len(all_metadata) == 0:\n",
    "                general_metadata = get_general_metadata(\n",
    "                    used_client = 'swift',\n",
    "                    object_metadata = all_metadata\n",
    "                )\n",
    "                custom_metadata = get_decoded_metadata(\n",
    "                    used_client = 'swift',\n",
    "                    object_metadata = all_metadata\n",
    "                )\n",
    "\n",
    "            object_metadata['general-meta'] = general_metadata\n",
    "            object_metadata['custom-meta'] = custom_metadata\n",
    "\n",
    "        return object_metadata\n",
    "    \n",
    "    def get_object_content(\n",
    "        storage_client: any,\n",
    "        bucket_name: str,\n",
    "        object_path: str\n",
    "    ) -> any:\n",
    "        object_content = {}\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            fetched_object = swift_get_object(\n",
    "                swift_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = object_path\n",
    "            )\n",
    "            object_content['data'] = pickle.loads(fetched_object['data'])\n",
    "            object_content['general-meta'] = get_general_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = fetched_object['info']\n",
    "            )\n",
    "            object_content['custom-meta'] = get_decoded_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = fetched_object['info']\n",
    "            )\n",
    "        return object_content\n",
    "       \n",
    "    def remove_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str\n",
    "    ) -> bool: \n",
    "        removed = False\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            removed = swift_remove_object(\n",
    "                swift_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = object_path\n",
    "            )\n",
    "        return removed\n",
    "    \n",
    "    def create_or_update_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str, \n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ) -> any:\n",
    "        success = False\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            formatted_data = pickle.dumps(object_data)\n",
    "            formatted_metadata = set_encoded_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = object_metadata\n",
    "            )\n",
    "\n",
    "            success = swift_create_or_update_object(\n",
    "                swift_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = object_path,\n",
    "                object_data = formatted_data,\n",
    "                object_metadata = formatted_metadata\n",
    "            )\n",
    "        return success\n",
    "    \n",
    "    def format_bucket_metadata(\n",
    "        used_client: str,\n",
    "        bucket_metadata: any\n",
    "    ) -> any:\n",
    "        formatted_metadata = {}\n",
    "        if used_client == 'swift':\n",
    "            relevant_values = {\n",
    "                'x-container-object-count': 'object-count',\n",
    "                'x-container-bytes-used-actual': 'used-bytes',\n",
    "                'last-modified': 'date',\n",
    "                'content-type': 'type'\n",
    "            }\n",
    "            formatted_metadata = {}\n",
    "            for key,value in bucket_metadata.items():\n",
    "                if key in relevant_values:\n",
    "                    formatted_key = relevant_values[key]\n",
    "                    formatted_metadata[formatted_key] = value\n",
    "        return formatted_metadata\n",
    "    \n",
    "    def format_bucket_objects(\n",
    "        used_client: str,\n",
    "        bucket_objects: any\n",
    "    ) -> any:\n",
    "        formatted_objects = {}\n",
    "        if used_client == 'swift':\n",
    "            for bucket_object in bucket_objects:\n",
    "                formatted_object_metadata = {\n",
    "                    'hash': 'id',\n",
    "                    'bytes': 'used-bytes',\n",
    "                    'last_modified': 'date'\n",
    "                }\n",
    "                object_key = None\n",
    "                object_metadata = {}\n",
    "                for key, value in bucket_object.items():\n",
    "                    if key == 'name':\n",
    "                        object_key = value\n",
    "                    if key in formatted_object_metadata:\n",
    "                        formatted_key = formatted_object_metadata[key]\n",
    "                        object_metadata[formatted_key] = value\n",
    "                formatted_objects[object_key] = object_metadata\n",
    "        return formatted_objects\n",
    "    \n",
    "    def format_bucket_info(\n",
    "        used_client: str,\n",
    "        bucket_info: any\n",
    "    ) -> any:\n",
    "        bucket_metadata = {}\n",
    "        bucket_objects = {}\n",
    "        if used_client == 'swift':\n",
    "            bucket_metadata = format_bucket_metadata(\n",
    "                used_client = used_client,\n",
    "                bucket_metadata = bucket_info['metadata']\n",
    "            )\n",
    "            bucket_objects = format_bucket_objects(\n",
    "                used_client = used_client,\n",
    "                bucket_objects = bucket_info['objects']\n",
    "            )\n",
    "        return {'metadata': bucket_metadata, 'objects': bucket_objects} \n",
    "   \n",
    "    def get_bucket_info(\n",
    "        storage_client: any,\n",
    "        bucket_name: str\n",
    "    ) -> any:\n",
    "        bucket_info = {}\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            unformatted_bucket_info = swift_check_bucket(\n",
    "                swift_client = storage_client,\n",
    "                bucket_name = bucket_name\n",
    "            )\n",
    "            bucket_info = format_bucket_info(\n",
    "                used_client = 'swift',\n",
    "                bucket_info = unformatted_bucket_info\n",
    "            )\n",
    "        return bucket_info\n",
    "    \n",
    "    def format_container_info(\n",
    "        used_client: str,\n",
    "        container_info: any\n",
    "    ) -> any:\n",
    "        formatted_container_info = {}\n",
    "        if used_client == 'swift':\n",
    "            for bucket in container_info:\n",
    "                bucket_name = bucket['name']\n",
    "                bucket_count = bucket['count']\n",
    "                bucket_size = bucket['bytes']\n",
    "                formatted_container_info[bucket_name] = {\n",
    "                    'amount': bucket_count,\n",
    "                    'size': bucket_size\n",
    "                }\n",
    "        return formatted_container_info\n",
    "    \n",
    "    def get_container_info( \n",
    "        storage_client: any\n",
    "    ) -> any:\n",
    "        container_info = {}\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            unformatted_container_info = swift_list_buckets(\n",
    "                swift_client = storage_client \n",
    "            )\n",
    "            container_info = format_container_info(\n",
    "                used_client = 'swift',\n",
    "                container_info = unformatted_container_info\n",
    "            )\n",
    "        return container_info\n",
    "    \n",
    "    def set_object_path(\n",
    "        object_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any\n",
    "    ):\n",
    "        object_paths = {\n",
    "            'root': 'name',\n",
    "            'code': 'CODE/name',\n",
    "            'slurm': 'CODE/SLURM/name',\n",
    "            'ray': 'CODE/RAY/name',\n",
    "            'data': 'DATA/name',\n",
    "            'artifacts': 'ARTIFACTS/name',\n",
    "            'time': 'TIMES/name'\n",
    "        }\n",
    "\n",
    "        i = 0\n",
    "        path_split = object_paths[object_name].split('/')\n",
    "        for name in path_split:\n",
    "            if name in path_replacers:\n",
    "                replacer = path_replacers[name]\n",
    "                if 0 < len(replacer):\n",
    "                    path_split[i] = replacer\n",
    "            i = i + 1\n",
    "        \n",
    "        if not len(path_names) == 0:\n",
    "            path_split.extend(path_names)\n",
    "\n",
    "        object_path = '/'.join(path_split)\n",
    "        return object_path\n",
    "   \n",
    "    def setup_storage(\n",
    "        storage_parameters: any\n",
    "    ) -> any:\n",
    "        storage_client = setup_storage_client(\n",
    "            storage_parameters = storage_parameters\n",
    "        ) \n",
    "        \n",
    "        storage_name = set_bucket_names(\n",
    "        storage_parameters = storage_parameters\n",
    "        )\n",
    "        \n",
    "        return storage_client, storage_name\n",
    "    \n",
    "    def check_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str,\n",
    "        object_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any\n",
    "    ) -> bool:\n",
    "        object_path = set_object_path(\n",
    "            object_name = object_name,\n",
    "            path_replacers = path_replacers,\n",
    "            path_names = path_names\n",
    "        )\n",
    "        object_metadata = check_object_metadata(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path\n",
    "        )\n",
    "        object_metadata['path'] = object_path\n",
    "        return object_metadata\n",
    "    \n",
    "    def get_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str,\n",
    "        object_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any\n",
    "    ) -> any:\n",
    "        checked_object = check_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_name = object_name,\n",
    "            path_replacers = path_replacers,\n",
    "            path_names = path_names\n",
    "        )\n",
    "\n",
    "        object_data = None\n",
    "        if not len(checked_object['general-meta']) == 0:\n",
    "            object_data = get_object_content(\n",
    "                storage_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = checked_object['path']\n",
    "            )\n",
    "\n",
    "        return object_data\n",
    "    \n",
    "    def set_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str,\n",
    "        object_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any,\n",
    "        overwrite: bool,\n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ):\n",
    "        checked_object = check_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_name = object_name,\n",
    "            path_replacers = path_replacers,\n",
    "            path_names = path_names\n",
    "        )\n",
    "        \n",
    "        perform = True\n",
    "        if not len(checked_object['general-meta']) == 0 and not overwrite:\n",
    "            perform = False\n",
    "        \n",
    "        if perform:\n",
    "            create_or_update_object(\n",
    "                storage_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = checked_object['path'],\n",
    "                object_data = object_data,\n",
    "                object_metadata = object_metadata\n",
    "            )\n",
    "    \n",
    "    def check_bucket(\n",
    "        storage_client: any,\n",
    "        bucket_name: str\n",
    "    ) -> any:\n",
    "        return get_bucket_info(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "    \n",
    "    def check_buckets(\n",
    "        storage_client: any\n",
    "    ) -> any:\n",
    "        return get_container_info( \n",
    "            storage_client = storage_client\n",
    "        )\n",
    "\n",
    "    def gather_time(\n",
    "        storage_client: any,\n",
    "        storage_name: any,\n",
    "        time_group: any,\n",
    "        time_name: any,\n",
    "        start_time: int,\n",
    "        end_time: int\n",
    "    ):\n",
    "        time_object = get_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = storage_name,\n",
    "            object_name = 'time',\n",
    "            path_replacers = {\n",
    "                'name': time_group\n",
    "            },\n",
    "            path_names = []\n",
    "        )\n",
    "\n",
    "        time_data = {}\n",
    "        time_metadata = {} \n",
    "        if time_object is None:\n",
    "            time_data = {}\n",
    "            time_metadata = general_object_metadata()\n",
    "        else:\n",
    "            time_data = time_object['data']\n",
    "            time_metadata = time_object['custom-meta']\n",
    "        \n",
    "        current_key_amount = len(time_data)\n",
    "        current_key_full = False\n",
    "        current_key = str(current_key_amount)\n",
    "        if 0 < current_key_amount:\n",
    "            time_object = time_data[current_key]\n",
    "            if 0 < time_object['total-seconds']:\n",
    "                current_key_full = True\n",
    "        \n",
    "        changed = False\n",
    "        if 0 < end_time and 0 < current_key_amount and not current_key_full:\n",
    "            stored_start_time = time_data[current_key]['start-time']\n",
    "            time_diff = (end_time-stored_start_time)\n",
    "            time_data[current_key]['end-time'] = end_time\n",
    "            time_data[current_key]['total-seconds'] = round(time_diff,5)\n",
    "            changed = True\n",
    "        else:\n",
    "            next_key_amount = len(time_data) + 1\n",
    "            new_key = str(next_key_amount)\n",
    "        \n",
    "            if 0 < start_time and 0 == end_time:\n",
    "                time_data[new_key] = {\n",
    "                    'name': time_name,\n",
    "                    'start-time': start_time,\n",
    "                    'end-time': 0,\n",
    "                    'total-seconds': 0\n",
    "                }\n",
    "                changed = True\n",
    "\n",
    "            if 0 < start_time and 0 < end_time:\n",
    "                time_diff = (end_time-start_time)\n",
    "                time_data[new_key] = {\n",
    "                    'name': time_name,\n",
    "                    'start-time': start_time,\n",
    "                    'end-time': end_time,\n",
    "                    'total-seconds': round(time_diff,5)\n",
    "                }\n",
    "                changed = True\n",
    "\n",
    "        if changed:\n",
    "            time_metadata['version'] = time_metadata['version'] + 1\n",
    "            set_object(\n",
    "                storage_client = storage_client,\n",
    "                bucket_name = storage_name,\n",
    "                object_name = 'time',\n",
    "                path_replacers = {\n",
    "                    'name': time_group\n",
    "                },\n",
    "                path_names = [],\n",
    "                overwrite = True,\n",
    "                object_data = time_data,\n",
    "                object_metadata = time_metadata \n",
    "            )\n",
    "\n",
    "    class CNNClassifier(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "            self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "            self.fc2 = nn.Linear(120, 84)\n",
    "            self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = x.view(-1, 16 * 4 * 4)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    def parse_torchmetrics(\n",
    "        metrics: any,\n",
    "        labels: any\n",
    "    ):\n",
    "        collected_metrics = {}\n",
    "        for key,value in metrics.items():\n",
    "            if key == 'name':\n",
    "                continue\n",
    "            if 'class-' in key:\n",
    "                i = 0\n",
    "                for class_value in value:\n",
    "                    formatted_key = key.replace('class', labels[i])\n",
    "                    rounded_value = round(class_value,5)\n",
    "                    collected_metrics[formatted_key] = rounded_value\n",
    "                    i += 1\n",
    "                continue\n",
    "            rounded_value = round(value,5)\n",
    "            collected_metrics[key] = rounded_value\n",
    "        return collected_metrics\n",
    "    \n",
    "    def setup_mlflow(\n",
    "        logger: any,\n",
    "        mlflow_parameters: any\n",
    "    ):\n",
    "        mlflow_s3_endpoint_url = mlflow_parameters['s3-endpoint-url']\n",
    "        mlflow_tracking_uri = mlflow_parameters['tracking-uri']\n",
    "        mlflow_experiment_name = mlflow_parameters['experiment-name']\n",
    "        \n",
    "        os.environ['MLFLOW_S3_ENDPOINT_URL'] = mlflow_s3_endpoint_url\n",
    "\n",
    "        logger.info(f\"Using MLflow tracking URI: {mlflow_tracking_uri}\")\n",
    "        mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "        logger.info(f\"Using MLflow experiment: {mlflow_experiment_name}\")\n",
    "        mlflow.set_experiment(mlflow_experiment_name)\n",
    "\n",
    "    def set_route(\n",
    "        route_type: str,\n",
    "        route_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any\n",
    "    ): \n",
    "        routes = {\n",
    "            'root': 'TYPE:/name',\n",
    "            'logs': 'GET:/general/logs/name',\n",
    "            'structure': 'GET:/general/structure',\n",
    "            'setup': 'POST:/setup/config',\n",
    "            'start': 'POST:/setup/start',\n",
    "            'stop': 'POST:/setup/stop',\n",
    "            'job-submit': 'POST:/requests/submit/job',\n",
    "            'job-run': 'PUT:/requests/run/job/name',\n",
    "            'job-cancel': 'PUT:/requests/cancel/job/name',\n",
    "            'forwarding-submit': 'POST:/requests/submit/forwarding',\n",
    "            'forwarding-cancel': 'PUT:/requests/cancel/type/user/key',\n",
    "            'task-request': 'PUT:/tasks/request/signature',\n",
    "            'task-result': 'GET:/tasks/result/id',\n",
    "            'job-artifact': 'GET:/artifacts/job/type/name',\n",
    "            'forwarding-artifact': 'GET:/artifacts/forwarding/type/user/key'\n",
    "        }\n",
    "\n",
    "        route = None\n",
    "        if route_name in routes:\n",
    "            i = 0\n",
    "            route = routes[route_name].split('/')\n",
    "            for name in route:\n",
    "                if name in path_replacers:\n",
    "                    replacer = path_replacers[name]\n",
    "                    if 0 < len(replacer):\n",
    "                        route[i] = replacer\n",
    "                i = i + 1\n",
    "\n",
    "            if not len(path_names) == 0:\n",
    "                route.extend(path_names)\n",
    "\n",
    "            if not len(route_type) == 0:\n",
    "                route[0] = route_type + ':'\n",
    "            \n",
    "            route = '/'.join(route)\n",
    "        return route\n",
    "    \n",
    "    def get_response(\n",
    "        route_type: str,\n",
    "        route_url: str,\n",
    "        route_input: any\n",
    "    ) -> any:\n",
    "        route_response = None\n",
    "        if route_type == 'POST':\n",
    "            route_response = requests.post(\n",
    "                url = route_url,\n",
    "                json = route_input\n",
    "            )\n",
    "        if route_type == 'PUT':\n",
    "            route_response = requests.put(\n",
    "                url = route_url\n",
    "            )\n",
    "        if route_type == 'GET':\n",
    "            route_response = requests.get(\n",
    "                url = route_url\n",
    "            )\n",
    "        return route_response\n",
    "    \n",
    "    def set_full_url(\n",
    "        address: str,\n",
    "        port: str,\n",
    "        used_route: str\n",
    "    ) -> str:\n",
    "        url_prefix = 'http://' + address + ':' + port\n",
    "        route_split = used_route.split(':')\n",
    "        url_type = route_split[0]\n",
    "        used_path = route_split[1]\n",
    "        full_url = url_prefix + used_path\n",
    "        return url_type, full_url\n",
    "    \n",
    "    def request_route(\n",
    "        address: str,\n",
    "        port: str,\n",
    "        route_type: str,\n",
    "        route_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any,\n",
    "        route_input: any,\n",
    "        timeout: any\n",
    "    ) -> any:\n",
    "        used_route = set_route(\n",
    "            route_type = route_type,\n",
    "            route_name = route_name,\n",
    "            path_replacers = path_replacers,\n",
    "            path_names = path_names\n",
    "        )\n",
    "\n",
    "        url_type, full_url = set_full_url(\n",
    "            address = address,\n",
    "            port = port,\n",
    "            used_route = used_route\n",
    "        )\n",
    "        \n",
    "        route_response = get_response(\n",
    "            route_type = url_type,\n",
    "            route_url = full_url,\n",
    "            route_input = route_input\n",
    "        )\n",
    "\n",
    "        route_status_code = None\n",
    "        route_returned_text = {}\n",
    "        if not route_response is None:\n",
    "            route_status_code = route_response.status_code\n",
    "            if route_status_code == 200:\n",
    "                route_text = json.loads(route_response.text)\n",
    "\n",
    "                if 'id' in route_text: \n",
    "                    task_result_route = set_route(\n",
    "                        route_type = '',\n",
    "                        route_name = 'task-result',\n",
    "                        path_replacers = {\n",
    "                            'id': route_text['id']\n",
    "                        },\n",
    "                        path_names = []\n",
    "                    )\n",
    "\n",
    "                    task_url_type, task_full_url = set_full_url(\n",
    "                        address = address,\n",
    "                        port = port,\n",
    "                        used_route = task_result_route\n",
    "                    )\n",
    "\n",
    "                    start = t.time()\n",
    "                    while t.time() - start <= timeout:\n",
    "                        task_route_response = get_response(\n",
    "                            route_type = task_url_type,\n",
    "                            route_url = task_full_url,\n",
    "                            route_input = {}\n",
    "                        )\n",
    "                        \n",
    "                        task_status_code = route_response.status_code\n",
    "                            \n",
    "                        if task_status_code == 200:\n",
    "                            task_text = json.loads(task_route_response.text)\n",
    "                            if task_text['status'] == 'FAILED':\n",
    "                                break\n",
    "                            \n",
    "                            if task_text['status'] == 'SUCCESS':\n",
    "                                route_returned_text = task_text['result']\n",
    "                                break\n",
    "                        else:\n",
    "                            break\n",
    "                else:\n",
    "                    route_returned_text = route_text\n",
    "        return route_status_code, route_returned_text\n",
    "    \n",
    "    def start_forwarder_scheduler(\n",
    "        address: str,\n",
    "        port: str,\n",
    "        scheduler_request: any\n",
    "    ) -> bool:\n",
    "        scheduler_route_code, scheduler_route_text = request_route(\n",
    "            address = address,\n",
    "            port = port,\n",
    "            route_type = '',\n",
    "            route_name = 'start',\n",
    "            path_replacers = {},\n",
    "            path_names = [],\n",
    "            route_input = scheduler_request,\n",
    "            timeout = 120\n",
    "        )\n",
    "        configured = False\n",
    "        if scheduler_route_code == 200 and scheduler_route_text:\n",
    "            configured = True\n",
    "        return configured\n",
    "    \n",
    "    def start_forwarder(\n",
    "        address: str,\n",
    "        port: str,\n",
    "        configuration: any,\n",
    "        scheduler_request: any\n",
    "    ) -> bool:\n",
    "        forwarder_route_code, forwarder_route_text  = request_route(\n",
    "            address = address,\n",
    "            port = port,\n",
    "            route_type = '',\n",
    "            route_name = 'setup',\n",
    "            path_replacers = {},\n",
    "            path_names = [],\n",
    "            route_input = configuration,\n",
    "            timeout = 120\n",
    "        )\n",
    "        configured = start_forwarder_scheduler(\n",
    "            address = address,\n",
    "            port = port,\n",
    "            scheduler_request = scheduler_request\n",
    "        )\n",
    "        return configured\n",
    "    \n",
    "    def test_url(\n",
    "        target_url: str,\n",
    "        timeout: int\n",
    "    ) -> bool:\n",
    "        try:\n",
    "            response = requests.head(\n",
    "                url = target_url, \n",
    "                timeout = timeout\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                return True\n",
    "            return False\n",
    "        except requests.ConnectionError:\n",
    "            return False\n",
    "        \n",
    "    def setup_ray(\n",
    "        logger: any,\n",
    "        services: any,\n",
    "        timeout: int\n",
    "    ):\n",
    "        logger.info('Setting up ray client')\n",
    "        start = t.time()\n",
    "        ray_client = None\n",
    "        if 0 < len(services):\n",
    "            ray_dashboard_url = 'http://' + services['ray-dashboard']\n",
    "            ray_exists = None\n",
    "            while t.time() - start <= timeout:\n",
    "                logger.info('Testing ray client url: ' + str(ray_dashboard_url))\n",
    "                ray_exists = test_url(\n",
    "                    target_url = ray_dashboard_url,\n",
    "                    timeout = 5\n",
    "                )\n",
    "                logger.info('Ray client exists: ' + str(ray_exists))\n",
    "                if ray_exists:\n",
    "                    break\n",
    "                t.sleep(5)\n",
    "            if ray_exists:\n",
    "                ray_client = JobSubmissionClient(\n",
    "                    address = ray_dashboard_url\n",
    "                )\n",
    "                logger.info(\"Ray setup\")\n",
    "        return ray_client\n",
    "\n",
    "    def get_ray_job(\n",
    "        logger: any,\n",
    "        storage_client: any,\n",
    "        storage_name: str,\n",
    "        ray_job_file: str\n",
    "    ) -> any:\n",
    "        ray_job_object = get_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = storage_name,\n",
    "            object_name = 'ray',\n",
    "            path_replacers = {\n",
    "                'name': ray_job_file\n",
    "            },\n",
    "            path_names = []\n",
    "        )\n",
    "\n",
    "        ray_job_object_data = ray_job_object['data']\n",
    "\n",
    "        current_directory = os.getcwd()\n",
    "        ray_job_directory = os.path.join(current_directory, 'jobs')\n",
    "\n",
    "        if not os.path.exists(ray_job_directory):\n",
    "            logger.info('Make directory')\n",
    "            os.makedirs(ray_job_directory)\n",
    "        \n",
    "        used_ray_job_path = os.path.join(ray_job_directory, ray_job_file)\n",
    "        \n",
    "        logger.info('Job writing path:' + str(used_ray_job_path))\n",
    "        with open(used_ray_job_path, 'w') as file:\n",
    "            file.write(ray_job_object_data)\n",
    "\n",
    "        return ray_job_directory\n",
    "\n",
    "    def submit_ray_job(\n",
    "        logger: any,\n",
    "        ray_client: any,\n",
    "        ray_parameters: any,\n",
    "        ray_job_file: any,\n",
    "        working_directory: str,\n",
    "        ray_job_envs: any\n",
    "    ) -> any:\n",
    "        logger.info('Submitting ray job ' + str(ray_job_file) + ' using directory ' + str(working_directory))\n",
    "        command = \"python \" + str(ray_job_file)\n",
    "        if 0 < len(ray_parameters):\n",
    "            command = command + \" '\" + json.dumps(ray_parameters) + \"'\"\n",
    "        job_id = ray_client.submit_job(\n",
    "            entrypoint = command,\n",
    "            runtime_env = {\n",
    "                'working_dir': str(working_directory),\n",
    "                'env_vars': ray_job_envs\n",
    "            }\n",
    "        )\n",
    "        return job_id\n",
    "\n",
    "    def wait_ray_job(\n",
    "        logger: any,\n",
    "        ray_client: any,\n",
    "        ray_job_id: int, \n",
    "        waited_status: any,\n",
    "        timeout: int\n",
    "    ) -> any:\n",
    "        logger.info('Waiting ray job ' + str(ray_job_id))\n",
    "        start = t.time()\n",
    "        job_status = None\n",
    "        while t.time() - start <= timeout:\n",
    "            status = ray_client.get_job_status(ray_job_id)\n",
    "            logger.info(f\"status: {status}\")\n",
    "            if status in waited_status:\n",
    "                job_status = status\n",
    "                break\n",
    "            t.sleep(5)\n",
    "        job_logs = ray_client.get_job_logs(ray_job_id)\n",
    "        return job_status, job_logs\n",
    "\n",
    "    def ray_job_handler(\n",
    "        logger: any,\n",
    "        storage_client: any,\n",
    "        storage_name: str,\n",
    "        ray_client: any,\n",
    "        ray_parameters: any,\n",
    "        ray_job_file: str,\n",
    "        ray_job_envs: any,\n",
    "        timeout: int\n",
    "    ) -> bool:\n",
    "        logger.info('Setting up ray job')\n",
    "\n",
    "        ray_job_directory = get_ray_job(\n",
    "            logger = logger,\n",
    "            storage_client = storage_client,\n",
    "            storage_name = storage_name,\n",
    "            ray_job_file = ray_job_file\n",
    "        )\n",
    "\n",
    "        logger.info('Submitting a ray job')\n",
    "        ray_job_id = submit_ray_job(\n",
    "            logger = logger,\n",
    "            ray_client = ray_client,\n",
    "            ray_parameters = ray_parameters,\n",
    "            ray_job_file = ray_job_file,\n",
    "            working_directory = ray_job_directory,\n",
    "            ray_job_envs = ray_job_envs\n",
    "        )\n",
    "\n",
    "        logger.info('Ray batch job id: ' + str(ray_job_id))\n",
    "        \n",
    "        ray_job_status, ray_job_logs = wait_ray_job(\n",
    "            logger = logger,\n",
    "            ray_client = ray_client,\n",
    "            ray_job_id = ray_job_id,\n",
    "            waited_status = {\n",
    "                JobStatus.SUCCEEDED, \n",
    "                JobStatus.STOPPED, \n",
    "                JobStatus.FAILED\n",
    "            }, \n",
    "            timeout = timeout\n",
    "        )\n",
    "        logger.info('Ray batch job ended:')\n",
    "        success = True\n",
    "        if not ray_job_status == JobStatus.SUCCEEDED:\n",
    "            logger.info('RAY batch job failed')\n",
    "            success = False\n",
    "        else:\n",
    "            logger.info('RAY batch job succeeded')\n",
    "        logger.info(ray_job_logs)\n",
    "        return success\n",
    "\n",
    "    def parse_job_sacct(\n",
    "        logger: any,\n",
    "        sacct: any\n",
    "    ) -> any:\n",
    "        collected_parameters = {}\n",
    "        collected_metrics = {}\n",
    "        logger.info('')\n",
    "        logger.info('Sacct:')\n",
    "        for row in sacct.keys():\n",
    "            logger.info('Row ' + str(row))\n",
    "            row_metadata = sacct[row]['metadata']\n",
    "            row_metrics = sacct[row]['metrics']\n",
    "        \n",
    "            relevant_metadata = [\n",
    "                'job-name',\n",
    "                'state'\n",
    "            ]\n",
    "            \n",
    "            for key, value in row_metadata.items():\n",
    "                if key in relevant_metadata:\n",
    "                    logger.info(str(key) + '=' + str(value))\n",
    "                    collected_parameters[str(row) + '-' + key] = value\n",
    "        \n",
    "            relevant_metrics = [\n",
    "                'ave-cpu-seconds',\n",
    "                'cpu-time-seconds',\n",
    "                'elapsed-seconds',\n",
    "                'total-cpu-seconds',\n",
    "            ]\n",
    "            \n",
    "            for key, value in row_metrics.items():\n",
    "                if key in relevant_metrics:\n",
    "                    logger.info(str(key) + '=' + str(value))\n",
    "                    collected_metrics[str(row) + '-' + key] = value\n",
    "        \n",
    "            start_time = row_metrics['start-time']\n",
    "            submit_time = row_metrics['submit-time']\n",
    "            end_time = row_metrics['end-time']\n",
    "        \n",
    "            submit_date = datetime.fromtimestamp(start_time).strftime('%Y-%m-%d-%H:%M:%S')\n",
    "            total_start_seconds = (submit_time-start_time)\n",
    "            total_end_seconds = (end_time-submit_time)\n",
    "        \n",
    "            logger.info('submit-date=' + str(submit_date))\n",
    "            collected_parameters[str(row) + '-submit-date'] = submit_date\n",
    "            \n",
    "            logger.info('total-submit-start-seconds=' + str(total_start_seconds))\n",
    "            collected_metrics[str(row) + '-total-submit-start-seconds'] = total_start_seconds\n",
    "            \n",
    "            logger.info('total-start-end-seconds=' + str(total_end_seconds))\n",
    "            collected_metrics[str(row) + '-total-start-end-seconds'] = total_end_seconds\n",
    "            \n",
    "            logger.info('')\n",
    "        return collected_parameters, collected_metrics\n",
    "\n",
    "    def parse_job_seff(\n",
    "        logger: any,\n",
    "        seff: any\n",
    "    ) -> any:\n",
    "        collected_parameters = {}\n",
    "        collected_metrics = {}\n",
    "        relevant_metadata = [\n",
    "            'billed-project',\n",
    "            'cluster',\n",
    "            'status'\n",
    "        ]\n",
    "\n",
    "        logger.info('')\n",
    "        logger.info('Seff:')\n",
    "        seff_metadata = seff['metadata']\n",
    "        for key,value in seff_metadata.items():\n",
    "            if key in relevant_metadata:\n",
    "                logger.info(str(key) + '=' + str(value))\n",
    "                collected_parameters[key] = value\n",
    "        \n",
    "        relevant_metrics = [\n",
    "            'billing-units',\n",
    "            'cpu-efficiency-percentage',\n",
    "            'cpu-efficiency-seconds',\n",
    "            'cpu-utilized-seconds',\n",
    "            'job-wall-clock-time-seconds',\n",
    "            'memory-efficiency-percentage'\n",
    "        ]\n",
    "\n",
    "\n",
    "        seff_metrics = seff['metrics']\n",
    "        for key,value in seff_metrics.items():\n",
    "            if key in relevant_metrics:\n",
    "                logger.info(str(key) + '=' + str(value))\n",
    "                collected_metrics[key] = value\n",
    "\n",
    "        return collected_parameters, collected_metrics\n",
    "    \n",
    "    logging.basicConfig(level = logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    component_time_start = t.time()\n",
    "\n",
    "    storage_client, storage_names = setup_storage(\n",
    "        storage_parameters = storage_parameters\n",
    "    )\n",
    "\n",
    "    logger.info('Storage setup')\n",
    "\n",
    "    output = namedtuple('Output', ['storage_uri', 'run_id'])\n",
    "\n",
    "    pipeline_bucket = storage_names[-2]\n",
    "\n",
    "    logger.info('Used bucket:' + str(pipeline_bucket))\n",
    "    \n",
    "    logger.info(\"Variable setup\")\n",
    "\n",
    "    configuration = integration_parameters['configuration']\n",
    "    scheduler_request = integration_parameters['scheduler-request']\n",
    "    forwarder_address = integration_parameters['forwarder-address']\n",
    "    forwarder_port = integration_parameters['forwarder-port']\n",
    "    forwarding_request = integration_parameters['forwarding-request']\n",
    "    user = integration_parameters['user']\n",
    "    job_request = integration_parameters['job-request']\n",
    "    ray_parameters = integration_parameters['ray-parameters']\n",
    "    ray_job_file = integration_parameters['ray-job-file']\n",
    "    ray_job_envs = integration_parameters['ray-job-envs']\n",
    "    ray_job_timeout = integration_parameters['ray-job-timeout']\n",
    "    folder_name = integration_parameters['folder-name']\n",
    "    \n",
    "    logger.info(forwarder_address)\n",
    "\n",
    "    logger.info(\"Starting forwarder\")\n",
    "\n",
    "    forwarder_started = start_forwarder(\n",
    "        address = forwarder_address, \n",
    "        port = forwarder_port,\n",
    "        configuration = configuration,\n",
    "        scheduler_request = scheduler_request\n",
    "    )\n",
    "\n",
    "    if not forwarder_started:\n",
    "        return output('none', 'none')\n",
    "\n",
    "    logger.info(\"Forwarder started\")\n",
    "\n",
    "    logger.info(\"Submitting forwarding request\")\n",
    "    logger.info(forwarder_address)\n",
    "\n",
    "    status_code, forwarding = request_route(\n",
    "        address = forwarder_address,\n",
    "        port = forwarder_port,\n",
    "        route_type = '',\n",
    "        route_name = 'forwarding-submit',\n",
    "        path_replacers = {},\n",
    "        path_names = [],\n",
    "        route_input = forwarding_request,\n",
    "        timeout = 300\n",
    "    )\n",
    "    \n",
    "    if not status_code == 200:\n",
    "        return output('none', 'none')\n",
    "\n",
    "    logger.info(\"Request success\")\n",
    "\n",
    "    forwarder_keys = forwarding['keys']\n",
    "    forwarding_split = forwarder_keys.split(',')\n",
    "    import_key = forwarding_split[0]\n",
    "\n",
    "    logger.info(\"Import key: \" + str(import_key))\n",
    "\n",
    "    if import_key == '0':\n",
    "        return output('none', 'none')\n",
    "    \n",
    "    logger.info(\"Waiting forwarding services\")\n",
    "\n",
    "    forwarding_timeout = 5000\n",
    "    start = t.time()\n",
    "    current_services = None\n",
    "    while t.time() - start <= forwarding_timeout:\n",
    "        status_code, forwarding_data = request_route(\n",
    "            address = forwarder_address,\n",
    "            port = forwarder_port,\n",
    "            route_type = '',\n",
    "            route_name = 'forwarding-artifact',\n",
    "            path_replacers = {\n",
    "                'type': 'status-imports',\n",
    "                'user': user,\n",
    "                'key': import_key\n",
    "            },\n",
    "            path_names = [],\n",
    "            route_input = {},\n",
    "            timeout = 500\n",
    "        )\n",
    "\n",
    "        if not status_code == 200:\n",
    "            return output('none', 'none')\n",
    "\n",
    "        if not 'forwarding-status' in forwarding_data:\n",
    "            return output('none', 'none')\n",
    "        \n",
    "        forwarding_status = forwarding_data['forwarding-status']    \n",
    "\n",
    "        if 'cancel' in forwarding_status or 'deleted' in forwarding_status:\n",
    "            if forwarding_status['cancel'] or forwarding_status['deleted']:\n",
    "                break\n",
    "\n",
    "        if 'created' in forwarding_status:\n",
    "            if forwarding_status['created']:\n",
    "                current_services = forwarding_status['services']\n",
    "                break\n",
    "        t.sleep(5)\n",
    "    \n",
    "    if current_services is None:\n",
    "        return output('none', 'none')\n",
    "        \n",
    "    logger.info(\"Services up\")\n",
    "\n",
    "    logger.info(\"Submitting job request\")\n",
    "\n",
    "    status_code, job_key = request_route(\n",
    "        address = forwarder_address,\n",
    "        port = forwarder_port,\n",
    "        route_type = '',\n",
    "        route_name = 'job-submit',\n",
    "        path_replacers = {},\n",
    "        path_names = [],\n",
    "        route_input = job_request,\n",
    "        timeout = 300\n",
    "    )\n",
    "\n",
    "    current_job_key = job_key['key']\n",
    "\n",
    "    logger.info(\"Current job key: \" + str(current_job_key))\n",
    "\n",
    "    if not status_code == 200:\n",
    "        return output('none', 'none')\n",
    "\n",
    "    if current_job_key == '0':\n",
    "        return output('none', 'none')\n",
    "\n",
    "    logger.info(\"Starting job\")\n",
    "    \n",
    "    status_code, job_start = request_route(\n",
    "        address = forwarder_address,\n",
    "        port = forwarder_port,\n",
    "        route_type = '',\n",
    "        route_name = 'job-run',\n",
    "        path_replacers = {\n",
    "            'name': user\n",
    "        },\n",
    "        path_names = [\n",
    "            current_job_key\n",
    "        ],\n",
    "        route_input = {},\n",
    "        timeout = 300\n",
    "    )\n",
    "\n",
    "    job_start_status = job_start['status']\n",
    "\n",
    "    logger.info(\"Job started: \" + str(job_start_status))\n",
    "\n",
    "    if not job_start_status == 'success':\n",
    "        return output('none', 'none')\n",
    "\n",
    "    logger.info(\"Waiting job to run\")\n",
    "\n",
    "    current_jobid = None\n",
    "    job_timeout = 5000\n",
    "    start = t.time()\n",
    "    while t.time() - start <= job_timeout:\n",
    "        status_code, job_data = request_route(\n",
    "            address = forwarder_address,\n",
    "            port = forwarder_port,\n",
    "            route_type = '',\n",
    "            route_name = 'job-artifact',\n",
    "            path_replacers = {\n",
    "                'type': 'status',\n",
    "                'name': user\n",
    "            },\n",
    "            path_names = [\n",
    "                current_job_key\n",
    "            ],\n",
    "            route_input = {},\n",
    "            timeout = 500\n",
    "        )\n",
    "\n",
    "        if not status_code == 200:\n",
    "            return output('none', 'none')\n",
    "\n",
    "        if not 'job-status' in job_data:\n",
    "            return output('none', 'none')\n",
    "\n",
    "        job_status = job_data['job-status']\n",
    "\n",
    "        if 'cancel' in job_status or 'stopped' in job_status:\n",
    "            if job_status['cancel'] or job_status['stopped']:\n",
    "                break\n",
    "\n",
    "        if 'pending' in job_status or 'running' in job_status:\n",
    "            if job_status['pending'] or job_status['running']:\n",
    "                current_jobid = job_status['id']\n",
    "                break\n",
    "\n",
    "        t.sleep(5)\n",
    "\n",
    "    if current_jobid is None:\n",
    "        return output('none', 'none')\n",
    "    \n",
    "    logger.info('SLURM job id: ' + str(current_jobid))\n",
    "\n",
    "    logger.info('Setting up Ray')\n",
    "    logger.info(current_services)\n",
    "    ray_client = setup_ray(\n",
    "        logger = logger,\n",
    "        services = current_services,\n",
    "        timeout = ray_job_timeout\n",
    "    )\n",
    "    \n",
    "    if ray_client is None:\n",
    "        return output('none', 'none')\n",
    "\n",
    "    logger.info('Ray client setup')\n",
    "\n",
    "    logger.info('Setting up MLFlow')\n",
    "   \n",
    "    setup_mlflow(\n",
    "        logger = logger,\n",
    "        mlflow_parameters = mlflow_parameters\n",
    "    )\n",
    "\n",
    "    logger.info('MLflow setup')\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        run_id = run.info.run_id\n",
    "        logger.info(f\"Run ID: {run_id}\")\n",
    "\n",
    "        logger.info('Running ray job: ' + str(ray_job_file))\n",
    "\n",
    "        ray_job_success = ray_job_handler(\n",
    "            logger = logger,\n",
    "            storage_client = storage_client,\n",
    "            storage_name = pipeline_bucket,\n",
    "            ray_client = ray_client,\n",
    "            ray_parameters = ray_parameters,\n",
    "            ray_job_file = ray_job_file,\n",
    "            ray_job_envs = ray_job_envs,\n",
    "            timeout = ray_job_timeout\n",
    "        )\n",
    "\n",
    "        logger.info('Ray job ran: ' + str(ray_job_success))\n",
    "\n",
    "        status_code, cancel_data = request_route(\n",
    "            address = forwarder_address,\n",
    "            port = forwarder_port,\n",
    "            route_type = '',\n",
    "            route_name = 'job-cancel',\n",
    "            path_replacers = {\n",
    "                'name': user,\n",
    "            },\n",
    "            path_names = [\n",
    "                current_job_key\n",
    "            ],\n",
    "            route_input = {},\n",
    "            timeout = 300\n",
    "        )\n",
    "        \n",
    "        logger.info('SLURM job cancel: ' + str(cancel_data))\n",
    "        if not ray_job_success:\n",
    "            return output('none', 'none')\n",
    "\n",
    "        logger.info('Collecting Artifacts')\n",
    " \n",
    "        collected_parameters = {}\n",
    "        collected_metrics = {}\n",
    "\n",
    "        logger.info('Hyperarameters')\n",
    "\n",
    "        for key,value in ray_parameters.items():\n",
    "            if 'hp-' in key:\n",
    "                formatted_key = key.replace('hp-', '')\n",
    "                logger.info(str(key) + '=' + str(value))\n",
    "                collected_parameters[formatted_key] = value\n",
    "\n",
    "        logger.info('Getting model parameters')\n",
    "\n",
    "        parameters_object = get_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = pipeline_bucket,\n",
    "            object_name = 'artifacts',\n",
    "            path_replacers = {\n",
    "                'name': folder_name\n",
    "            },\n",
    "            path_names = [\n",
    "                'parameters'\n",
    "            ]\n",
    "        )\n",
    "        model_available = False\n",
    "        if not parameters_object is None:\n",
    "            parameters_object_data = parameters_object['data']\n",
    "\n",
    "            logger.info('Logging model')\n",
    "\n",
    "            trained_model = CNNClassifier()\n",
    "            trained_model.load_state_dict(parameters_object_data['model'])\n",
    "            trained_model.eval()\n",
    "            \n",
    "            model_name = mlflow_parameters['model-name']\n",
    "            registered_name = mlflow_parameters['registered-name']\n",
    "            mlflow.pytorch.log_model(\n",
    "                trained_model, \n",
    "                model_name,\n",
    "                registered_model_name = registered_name\n",
    "            )\n",
    "            model_available = True\n",
    "\n",
    "        logger.info('Getting model predictions')\n",
    "\n",
    "        predictions_object = get_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = pipeline_bucket,\n",
    "            object_name = 'artifacts',\n",
    "            path_replacers = {\n",
    "                'name': folder_name\n",
    "            },\n",
    "            path_names = [\n",
    "                'predictions'\n",
    "            ]\n",
    "        ) \n",
    "\n",
    "        if not predictions_object is None:\n",
    "            predictions_object_data = predictions_object['data']\n",
    "\n",
    "            logger.info(\"Logging predictions\")\n",
    "            np.save(\"predictions.npy\", predictions_object_data)\n",
    "            mlflow.log_artifact(\n",
    "                local_path = \"predictions.npy\",\n",
    "                artifact_path = \"predicted_qualities/\"\n",
    "            )\n",
    "        \n",
    "        logger.info(\"Logging metrics\")\n",
    "        metrics_object = get_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = pipeline_bucket,\n",
    "            object_name = 'artifacts',\n",
    "            path_replacers = {\n",
    "                'name': folder_name\n",
    "            },\n",
    "            path_names = [\n",
    "                'metrics'\n",
    "            ]\n",
    "        ) \n",
    "\n",
    "        if not metrics_object is None:\n",
    "            performance = metrics_object['data']\n",
    "\n",
    "            parsed_performance = parse_torchmetrics(\n",
    "                metrics = performance,\n",
    "                labels = {\n",
    "                    0: 'top',\n",
    "                    1: 'trouser',\n",
    "                    2: 'pullover',\n",
    "                    3: 'dress',\n",
    "                    4: 'coat',\n",
    "                    5: 'sandal',\n",
    "                    6: 'shirt',\n",
    "                    7: 'sneaker',\n",
    "                    8: 'bag',\n",
    "                    9: 'ankle-boot',\n",
    "                }\n",
    "            )\n",
    "\n",
    "            for key,value in parsed_performance.items():\n",
    "                collected_metrics[key] = value\n",
    "                    \n",
    "        logger.info(\"Waiting sacct and seff\")\n",
    "        store_timeout = 5000\n",
    "        start = t.time()\n",
    "        stored = False\n",
    "        while t.time() - start <= store_timeout:\n",
    "            status_code, job_data = request_route(\n",
    "                address = forwarder_address,\n",
    "                port = forwarder_port,\n",
    "                route_type = '',\n",
    "                route_name = 'job-artifact',\n",
    "                path_replacers = {\n",
    "                    'type': 'status',\n",
    "                    'name': user\n",
    "                },\n",
    "                path_names = [\n",
    "                    current_job_key\n",
    "                ],\n",
    "                route_input = {},\n",
    "                timeout = 500\n",
    "            )\n",
    "\n",
    "            if not status_code == 200:\n",
    "                break\n",
    "\n",
    "            if not 'job-status' in job_data:\n",
    "                break\n",
    "\n",
    "            job_status = job_data['job-status']\n",
    "\n",
    "            if 'stored' in job_status:\n",
    "                if job_status['stored']:\n",
    "                    stored = True\n",
    "                    break\n",
    "\n",
    "            t.sleep(5)\n",
    "\n",
    "        if stored:\n",
    "            logger.info(\"Fetching sacct\")\n",
    "            status_code, sacct_data = request_route(\n",
    "                address = forwarder_address,\n",
    "                port = forwarder_port,\n",
    "                route_type = '',\n",
    "                route_name = 'job-artifact',\n",
    "                path_replacers = {\n",
    "                    'type': 'sacct',\n",
    "                    'name': user\n",
    "                },\n",
    "                path_names = [\n",
    "                    current_job_key\n",
    "                ],\n",
    "                route_input = {},\n",
    "                timeout = 300\n",
    "            )\n",
    "\n",
    "            if status_code == 200:\n",
    "                if 'job-sacct' in sacct_data:\n",
    "                    logger.info(\"Logging sacct\")\n",
    "                    job_sacct = sacct_data['job-sacct']\n",
    "                    params, metrics = parse_job_sacct(\n",
    "                        logger = logger,\n",
    "                        sacct = job_sacct\n",
    "                    )\n",
    "\n",
    "                    for key,value in params.items():\n",
    "                        collected_parameters[key] = value\n",
    "\n",
    "                    for key,value in metrics.items():\n",
    "                        collected_metrics[key] = value\n",
    "\n",
    "            logger.info(\"Fetching seff\")\n",
    "            status_code, seff_data = request_route(\n",
    "                address = forwarder_address,\n",
    "                port = forwarder_port,\n",
    "                route_type = '',\n",
    "                route_name = 'job-artifact',\n",
    "                path_replacers = {\n",
    "                    'type': 'seff',\n",
    "                    'name': user\n",
    "                },\n",
    "                path_names = [\n",
    "                    current_job_key\n",
    "                ],\n",
    "                route_input = {},\n",
    "                timeout = 300\n",
    "            )\n",
    "            \n",
    "            if status_code == 200:\n",
    "                if 'job-seff' in seff_data:\n",
    "                    logger.info(\"Logging seff\")\n",
    "                    job_seff = seff_data['job-seff']\n",
    "                    params, metrics = parse_job_seff(\n",
    "                        logger = logger,\n",
    "                        seff = job_seff \n",
    "                    )\n",
    "\n",
    "                    for key,value in params.items():\n",
    "                        collected_parameters[key] = value\n",
    "\n",
    "                    for key,value in metrics.items():\n",
    "                        collected_metrics[key] = value\n",
    "\n",
    "        logger.info(\"Logging parameters and metrics\")\n",
    "\n",
    "        for key,value in collected_parameters.items():\n",
    "            mlflow.log_param(key, value)\n",
    "        logger.info(\"Parameters logged\")\n",
    "\n",
    "        for key,value in collected_metrics.items():\n",
    "            mlflow.log_metric(key, value)\n",
    "        logger.info(\"Metrics logged\")\n",
    "        \n",
    "        logger.info(\"Canceling imports\")\n",
    "\n",
    "        status_code, cancel_data = request_route(\n",
    "            address = forwarder_address,\n",
    "            port = forwarder_port,\n",
    "            route_type = '',\n",
    "            route_name = 'forwarding-cancel',\n",
    "            path_replacers = {\n",
    "                'type': 'imports',\n",
    "                'user': user,\n",
    "                'key': import_key\n",
    "            },\n",
    "            path_names = [],\n",
    "            route_input = {},\n",
    "            timeout = 300\n",
    "        )\n",
    "\n",
    "        logger.info(\"Cancellation success\")\n",
    "        \n",
    "        component_time_end = t.time()\n",
    "        \n",
    "        logger.info(\"Storing time\")\n",
    "        gather_time( \n",
    "            storage_client = storage_client,\n",
    "            storage_name = pipeline_bucket,\n",
    "            time_group = 'components',\n",
    "            time_name = 'cloud-hpc-train',\n",
    "            start_time = component_time_start,\n",
    "            end_time = component_time_end\n",
    "        )\n",
    "\n",
    "        if not model_available:\n",
    "            return output('none', 'none')\n",
    "\n",
    "        return output(mlflow.get_artifact_uri(), run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021dfafc-b121-4749-ab77-cba52be68dcb",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "957f832b-ff90-4358-a733-b4a5ce162478",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image = \"python:3.10\",\n",
    "    packages_to_install = [\n",
    "        \"python-swiftclient\",\n",
    "        \"mlflow~=2.12.2\", \n",
    "    ],\n",
    "    output_component_file = 'components/evaluate_component.yaml',\n",
    ")\n",
    "def evaluate(   \n",
    "    storage_parameters: dict,\n",
    "    integration_parameters: dict,\n",
    "    mlflow_parameters: dict,\n",
    "    metric_parameters: dict,\n",
    "    run_id: str\n",
    ") -> bool:\n",
    "    from mlflow.tracking import MlflowClient\n",
    "    import logging\n",
    "\n",
    "    import time as t\n",
    "    \n",
    "    import swiftclient as sc\n",
    "    import pickle\n",
    "\n",
    "    import re\n",
    "    import json\n",
    "    import requests\n",
    "\n",
    "    def set_formatted_user(\n",
    "        user: str   \n",
    "    ) -> any:\n",
    "        return re.sub(r'[^a-z0-9]+', '-', user)\n",
    "    def general_object_metadata():\n",
    "        general_object_metadata = {\n",
    "            'version': 1\n",
    "        }\n",
    "        return general_object_metadata\n",
    "    \n",
    "    def is_swift_client(\n",
    "        storage_client: any\n",
    "    ) -> any:\n",
    "        return isinstance(storage_client, sc.Connection)\n",
    "    \n",
    "    def swift_setup_client(\n",
    "        pre_auth_url: str,\n",
    "        pre_auth_token: str,\n",
    "        user_domain_name: str,\n",
    "        project_domain_name: str,\n",
    "        project_name: str,\n",
    "        auth_version: str\n",
    "    ) -> any:\n",
    "        swift_client = sc.Connection(\n",
    "            preauthurl = pre_auth_url,\n",
    "            preauthtoken = pre_auth_token,\n",
    "            os_options = {\n",
    "                'user_domain_name': user_domain_name,\n",
    "                'project_domain_name': project_domain_name,\n",
    "                'project_name': project_name\n",
    "            },\n",
    "            auth_version = auth_version\n",
    "        )\n",
    "        return swift_client\n",
    "   \n",
    "    def swift_create_bucket(\n",
    "        swift_client: any,\n",
    "        bucket_name: str\n",
    "    ) -> bool:\n",
    "        try:\n",
    "            swift_client.put_container(\n",
    "                container = bucket_name\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def swift_check_bucket(\n",
    "        swift_client: any,\n",
    "        bucket_name:str\n",
    "    ) -> any:\n",
    "        try:\n",
    "            bucket_info = swift_client.get_container(\n",
    "                container = bucket_name\n",
    "            )\n",
    "            bucket_metadata = bucket_info[0]\n",
    "            list_of_objects = bucket_info[1]\n",
    "            return {'metadata': bucket_metadata, 'objects': list_of_objects}\n",
    "        except Exception as e:\n",
    "            return {} \n",
    "    \n",
    "    def swift_delete_bucket(\n",
    "        swift_client: any,\n",
    "        bucket_name: str\n",
    "    ) -> bool:\n",
    "        try:\n",
    "            swift_client.delete_container(\n",
    "                container = bucket_name\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def swift_list_buckets(\n",
    "        swift_client: any\n",
    "    ) -> any:\n",
    "        try:\n",
    "            account_buckets = swift_client.get_account()[1]\n",
    "            return account_buckets\n",
    "        except Exception as e:\n",
    "            return {}\n",
    "    \n",
    "    def swift_create_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str, \n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ) -> bool: \n",
    "        try:\n",
    "            swift_client.put_object(\n",
    "                container = bucket_name,\n",
    "                obj = object_path,\n",
    "                contents = object_data,\n",
    "                headers = object_metadata\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def swift_check_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str\n",
    "    ) -> any: \n",
    "        try:\n",
    "            object_metadata = swift_client.head_object(\n",
    "                container = bucket_name,\n",
    "                obj = object_path\n",
    "            )       \n",
    "            return object_metadata\n",
    "        except Exception as e:\n",
    "            return {} \n",
    "    \n",
    "    def swift_get_object(\n",
    "        swift_client:any,\n",
    "        bucket_name: str,\n",
    "        object_path: str\n",
    "    ) -> any:\n",
    "        try:\n",
    "            response = swift_client.get_object(\n",
    "                container = bucket_name,\n",
    "                obj = object_path \n",
    "            )\n",
    "            object_info = response[0]\n",
    "            object_data = response[1]\n",
    "            return {'data': object_data, 'info': object_info}\n",
    "        except Exception as e:\n",
    "            return {}     \n",
    "       \n",
    "    def swift_remove_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str\n",
    "    ) -> bool: \n",
    "        try:\n",
    "            swift_client.delete_object(\n",
    "                container = bucket_name, \n",
    "                obj = object_path\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def swift_update_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str, \n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ) -> bool:  \n",
    "        remove = swift_remove_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path\n",
    "        )\n",
    "        if not remove:\n",
    "            return False\n",
    "        create = swift_create_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path, \n",
    "            object_data = object_data,\n",
    "            object_metadata = object_metadata\n",
    "        )\n",
    "        return create\n",
    "    \n",
    "    def swift_create_or_update_object(\n",
    "        swift_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str, \n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ) -> any:\n",
    "        bucket_info = swift_check_bucket(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "        \n",
    "        if len(bucket_info) == 0:\n",
    "            creation_status = swift_create_bucket(\n",
    "                swift_client = swift_client, \n",
    "                bucket_name = bucket_name\n",
    "            )\n",
    "            if not creation_status:\n",
    "                return False\n",
    "        \n",
    "        object_info = swift_check_object(\n",
    "            swift_client = swift_client, \n",
    "            bucket_name = bucket_name, \n",
    "            object_path = object_path\n",
    "        )\n",
    "        \n",
    "        if len(object_info) == 0:\n",
    "            return swift_create_object(\n",
    "                swift_client = swift_client, \n",
    "                bucket_name = bucket_name, \n",
    "                object_path = object_path, \n",
    "                object_data = object_data,\n",
    "                object_metadata = object_metadata\n",
    "            )\n",
    "        else:\n",
    "            return swift_update_object(\n",
    "                swift_client = swift_client, \n",
    "                bucket_name = bucket_name, \n",
    "                object_path = object_path, \n",
    "                object_data = object_data,\n",
    "                object_metadata = object_metadata\n",
    "            )\n",
    "\n",
    "    def set_encoded_metadata(\n",
    "        used_client: str,\n",
    "        object_metadata: any\n",
    "    ) -> any:\n",
    "        encoded_metadata = {}\n",
    "        if used_client == 'swift':\n",
    "            key_initial = 'x-object-meta'\n",
    "            for key, value in object_metadata.items():\n",
    "                encoded_key = key_initial + '-' + key\n",
    "                if isinstance(value, list):\n",
    "                    encoded_metadata[encoded_key] = 'list=' + ','.join(map(str, value))\n",
    "                    continue\n",
    "                encoded_metadata[encoded_key] = str(value)\n",
    "        return encoded_metadata\n",
    "   \n",
    "    def get_general_metadata(\n",
    "        used_client: str,\n",
    "        object_metadata: any\n",
    "    ) -> any:\n",
    "        general_metadata = {}\n",
    "        if used_client == 'swift':\n",
    "            key_initial = 'x-object-meta'\n",
    "            for key, value in object_metadata.items():\n",
    "                if not key_initial == key[:len(key_initial)]:\n",
    "                    general_metadata[key] = value\n",
    "        return general_metadata\n",
    "    \n",
    "    def get_decoded_metadata(\n",
    "        used_client: str,\n",
    "        object_metadata: any\n",
    "    ) -> any: \n",
    "        decoded_metadata = {}\n",
    "        if used_client == 'swift':\n",
    "            key_initial = 'x-object-meta'\n",
    "            for key, value in object_metadata.items():\n",
    "                if key_initial == key[:len(key_initial)]:\n",
    "                    decoded_key = key[len(key_initial) + 1:]\n",
    "                    if 'list=' in value:\n",
    "                        string_integers = value.split('=')[1]\n",
    "                        values = string_integers.split(',')\n",
    "                        if len(values) == 1 and values[0] == '':\n",
    "                            decoded_metadata[decoded_key] = []\n",
    "                        else:\n",
    "                            try:\n",
    "                                decoded_metadata[decoded_key] = list(map(int, values))\n",
    "                            except:\n",
    "                                decoded_metadata[decoded_key] = list(map(str, values))\n",
    "                        continue\n",
    "                    if value.isnumeric():\n",
    "                        decoded_metadata[decoded_key] = int(value)\n",
    "                        continue\n",
    "                    decoded_metadata[decoded_key] = value\n",
    "        return decoded_metadata\n",
    "   \n",
    "    def set_bucket_names(\n",
    "        storage_parameters: any\n",
    "    ) -> any:\n",
    "        storage_names = []\n",
    "        bucket_prefix = storage_parameters['bucket-prefix']\n",
    "        ice_id = storage_parameters['ice-id']\n",
    "        user = storage_parameters['user']\n",
    "        storage_names.append(bucket_prefix + '-forwarder-' + ice_id)\n",
    "        storage_names.append(bucket_prefix + '-submitter-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "        storage_names.append(bucket_prefix + '-pipeline-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "        storage_names.append(bucket_prefix + '-experiment-' + ice_id + '-' + set_formatted_user(user = user))\n",
    "        return storage_names\n",
    "    \n",
    "    def setup_storage(\n",
    "        storage_parameters: any\n",
    "    ) -> any:\n",
    "        storage_client = setup_storage_client(\n",
    "            storage_parameters = storage_parameters\n",
    "        ) \n",
    "        \n",
    "        storage_name = set_bucket_names(\n",
    "        storage_parameters = storage_parameters\n",
    "        )\n",
    "        \n",
    "        return storage_client, storage_name\n",
    "    \n",
    "    def setup_storage_client(\n",
    "        storage_parameters: any\n",
    "    ) -> any:\n",
    "        storage_client = None\n",
    "        if storage_parameters['used-client'] == 'swift':\n",
    "            storage_client = swift_setup_client(\n",
    "                pre_auth_url = storage_parameters['pre-auth-url'],\n",
    "                pre_auth_token = storage_parameters['pre-auth-token'],\n",
    "                user_domain_name = storage_parameters['user-domain-name'],\n",
    "                project_domain_name = storage_parameters['project-domain-name'],\n",
    "                project_name = storage_parameters['project-name'],\n",
    "                auth_version = storage_parameters['auth-version']\n",
    "            )\n",
    "        return storage_client\n",
    "    \n",
    "    def check_object_metadata(\n",
    "        storage_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str\n",
    "    ) -> any: \n",
    "        object_metadata = {\n",
    "            'general-meta': {},\n",
    "            'custom-meta': {}\n",
    "        }\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            all_metadata = swift_check_object(\n",
    "            swift_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path\n",
    "            ) \n",
    "\n",
    "            general_metadata = {}\n",
    "            custom_metadata = {}\n",
    "            if not len(all_metadata) == 0:\n",
    "                general_metadata = get_general_metadata(\n",
    "                    used_client = 'swift',\n",
    "                    object_metadata = all_metadata\n",
    "                )\n",
    "                custom_metadata = get_decoded_metadata(\n",
    "                    used_client = 'swift',\n",
    "                    object_metadata = all_metadata\n",
    "                )\n",
    "\n",
    "            object_metadata['general-meta'] = general_metadata\n",
    "            object_metadata['custom-meta'] = custom_metadata\n",
    "\n",
    "        return object_metadata\n",
    "    \n",
    "    def get_object_content(\n",
    "        storage_client: any,\n",
    "        bucket_name: str,\n",
    "        object_path: str\n",
    "    ) -> any:\n",
    "        object_content = {}\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            fetched_object = swift_get_object(\n",
    "                swift_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = object_path\n",
    "            )\n",
    "            object_content['data'] = pickle.loads(fetched_object['data'])\n",
    "            object_content['general-meta'] = get_general_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = fetched_object['info']\n",
    "            )\n",
    "            object_content['custom-meta'] = get_decoded_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = fetched_object['info']\n",
    "            )\n",
    "        return object_content\n",
    "        \n",
    "    def remove_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str\n",
    "    ) -> bool: \n",
    "        removed = False\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            removed = swift_remove_object(\n",
    "                swift_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = object_path\n",
    "            )\n",
    "        return removed\n",
    "    \n",
    "    def create_or_update_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str, \n",
    "        object_path: str, \n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ) -> any:\n",
    "        success = False\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            formatted_data = pickle.dumps(object_data)\n",
    "            formatted_metadata = set_encoded_metadata(\n",
    "                used_client = 'swift',\n",
    "                object_metadata = object_metadata\n",
    "            )\n",
    "\n",
    "            success = swift_create_or_update_object(\n",
    "                swift_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = object_path,\n",
    "                object_data = formatted_data,\n",
    "                object_metadata = formatted_metadata\n",
    "            )\n",
    "        return success\n",
    "    \n",
    "    def format_bucket_metadata(\n",
    "        used_client: str,\n",
    "        bucket_metadata: any\n",
    "    ) -> any:\n",
    "        formatted_metadata = {}\n",
    "        if used_client == 'swift':\n",
    "            relevant_values = {\n",
    "                'x-container-object-count': 'object-count',\n",
    "                'x-container-bytes-used-actual': 'used-bytes',\n",
    "                'last-modified': 'date',\n",
    "                'content-type': 'type'\n",
    "            }\n",
    "            formatted_metadata = {}\n",
    "            for key,value in bucket_metadata.items():\n",
    "                if key in relevant_values:\n",
    "                    formatted_key = relevant_values[key]\n",
    "                    formatted_metadata[formatted_key] = value\n",
    "        return formatted_metadata\n",
    "    \n",
    "    def format_bucket_objects(\n",
    "        used_client: str,\n",
    "        bucket_objects: any\n",
    "    ) -> any:\n",
    "        formatted_objects = {}\n",
    "        if used_client == 'swift':\n",
    "            for bucket_object in bucket_objects:\n",
    "                formatted_object_metadata = {\n",
    "                    'hash': 'id',\n",
    "                    'bytes': 'used-bytes',\n",
    "                    'last_modified': 'date'\n",
    "                }\n",
    "                object_key = None\n",
    "                object_metadata = {}\n",
    "                for key, value in bucket_object.items():\n",
    "                    if key == 'name':\n",
    "                        object_key = value\n",
    "                    if key in formatted_object_metadata:\n",
    "                        formatted_key = formatted_object_metadata[key]\n",
    "                        object_metadata[formatted_key] = value\n",
    "                formatted_objects[object_key] = object_metadata\n",
    "        return formatted_objects\n",
    "    \n",
    "    def format_bucket_info(\n",
    "        used_client: str,\n",
    "        bucket_info: any\n",
    "    ) -> any:\n",
    "        bucket_metadata = {}\n",
    "        bucket_objects = {}\n",
    "        if used_client == 'swift':\n",
    "            bucket_metadata = format_bucket_metadata(\n",
    "                used_client = used_client,\n",
    "                bucket_metadata = bucket_info['metadata']\n",
    "            )\n",
    "            bucket_objects = format_bucket_objects(\n",
    "                used_client = used_client,\n",
    "                bucket_objects = bucket_info['objects']\n",
    "            )\n",
    "        return {'metadata': bucket_metadata, 'objects': bucket_objects} \n",
    "    \n",
    "    def get_bucket_info(\n",
    "        storage_client: any,\n",
    "        bucket_name: str\n",
    "    ) -> any:\n",
    "        bucket_info = {}\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            unformatted_bucket_info = swift_check_bucket(\n",
    "                swift_client = storage_client,\n",
    "                bucket_name = bucket_name\n",
    "            )\n",
    "            bucket_info = format_bucket_info(\n",
    "                used_client = 'swift',\n",
    "                bucket_info = unformatted_bucket_info\n",
    "            )\n",
    "        return bucket_info\n",
    "    \n",
    "    def format_container_info(\n",
    "        used_client: str,\n",
    "        container_info: any\n",
    "    ) -> any:\n",
    "        formatted_container_info = {}\n",
    "        if used_client == 'swift':\n",
    "            for bucket in container_info:\n",
    "                bucket_name = bucket['name']\n",
    "                bucket_count = bucket['count']\n",
    "                bucket_size = bucket['bytes']\n",
    "                formatted_container_info[bucket_name] = {\n",
    "                    'amount': bucket_count,\n",
    "                    'size': bucket_size\n",
    "                }\n",
    "        return formatted_container_info\n",
    "    \n",
    "    def get_container_info( \n",
    "        storage_client: any\n",
    "    ) -> any:\n",
    "        container_info = {}\n",
    "        if is_swift_client(storage_client = storage_client):\n",
    "            unformatted_container_info = swift_list_buckets(\n",
    "                swift_client = storage_client \n",
    "            )\n",
    "            container_info = format_container_info(\n",
    "                used_client = 'swift',\n",
    "                container_info = unformatted_container_info\n",
    "            )\n",
    "        return container_info\n",
    "    \n",
    "    def set_object_path(\n",
    "        object_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any\n",
    "    ):\n",
    "        object_paths = {\n",
    "            'root': 'name',\n",
    "            'code': 'CODE/name',\n",
    "            'slurm': 'CODE/SLURM/name',\n",
    "            'ray': 'CODE/RAY/name',\n",
    "            'data': 'DATA/name',\n",
    "            'artifacts': 'ARTIFACTS/name',\n",
    "            'time': 'TIMES/name'\n",
    "        }\n",
    "\n",
    "        i = 0\n",
    "        path_split = object_paths[object_name].split('/')\n",
    "        for name in path_split:\n",
    "            if name in path_replacers:\n",
    "                replacer = path_replacers[name]\n",
    "                if 0 < len(replacer):\n",
    "                    path_split[i] = replacer\n",
    "            i = i + 1\n",
    "        \n",
    "        if not len(path_names) == 0:\n",
    "            path_split.extend(path_names)\n",
    "\n",
    "        object_path = '/'.join(path_split)\n",
    "        return object_path\n",
    "    \n",
    "    def setup_storage(\n",
    "        storage_parameters: any\n",
    "    ) -> any:\n",
    "        storage_client = setup_storage_client(\n",
    "            storage_parameters = storage_parameters\n",
    "        ) \n",
    "        \n",
    "        storage_name = set_bucket_names(\n",
    "        storage_parameters = storage_parameters\n",
    "        )\n",
    "        \n",
    "        return storage_client, storage_name\n",
    "    \n",
    "    def check_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str,\n",
    "        object_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any\n",
    "    ) -> bool:\n",
    "        object_path = set_object_path(\n",
    "            object_name = object_name,\n",
    "            path_replacers = path_replacers,\n",
    "            path_names = path_names\n",
    "        )\n",
    "        object_metadata = check_object_metadata(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_path = object_path\n",
    "        )\n",
    "        object_metadata['path'] = object_path\n",
    "        return object_metadata\n",
    "    \n",
    "    def get_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str,\n",
    "        object_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any\n",
    "    ) -> any:\n",
    "        checked_object = check_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_name = object_name,\n",
    "            path_replacers = path_replacers,\n",
    "            path_names = path_names\n",
    "        )\n",
    "\n",
    "        object_data = None\n",
    "        if not len(checked_object['general-meta']) == 0:\n",
    "            object_data = get_object_content(\n",
    "                storage_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = checked_object['path']\n",
    "            )\n",
    "\n",
    "        return object_data\n",
    "    \n",
    "    def set_object(\n",
    "        storage_client: any,\n",
    "        bucket_name: str,\n",
    "        object_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any,\n",
    "        overwrite: bool,\n",
    "        object_data: any,\n",
    "        object_metadata: any\n",
    "    ):\n",
    "        checked_object = check_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name,\n",
    "            object_name = object_name,\n",
    "            path_replacers = path_replacers,\n",
    "            path_names = path_names\n",
    "        )\n",
    "        \n",
    "        perform = True\n",
    "        if not len(checked_object['general-meta']) == 0 and not overwrite:\n",
    "            perform = False\n",
    "        \n",
    "        if perform:\n",
    "            create_or_update_object(\n",
    "                storage_client = storage_client,\n",
    "                bucket_name = bucket_name,\n",
    "                object_path = checked_object['path'],\n",
    "                object_data = object_data,\n",
    "                object_metadata = object_metadata\n",
    "            )\n",
    "    \n",
    "    def check_bucket(\n",
    "        storage_client: any,\n",
    "        bucket_name: str\n",
    "    ) -> any:\n",
    "        return get_bucket_info(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = bucket_name\n",
    "        )\n",
    "    \n",
    "    def check_buckets(\n",
    "        storage_client: any\n",
    "    ) -> any:\n",
    "        return get_container_info( \n",
    "            storage_client = storage_client\n",
    "        )\n",
    "\n",
    "    def gather_time(\n",
    "        storage_client: any,\n",
    "        storage_name: any,\n",
    "        time_group: any,\n",
    "        time_name: any,\n",
    "        start_time: int,\n",
    "        end_time: int\n",
    "    ):\n",
    "        time_object = get_object(\n",
    "            storage_client = storage_client,\n",
    "            bucket_name = storage_name,\n",
    "            object_name = 'time',\n",
    "            path_replacers = {\n",
    "                'name': time_group\n",
    "            },\n",
    "            path_names = []\n",
    "        )\n",
    "\n",
    "        time_data = {}\n",
    "        time_metadata = {} \n",
    "        if time_object is None:\n",
    "            time_data = {}\n",
    "            time_metadata = general_object_metadata()\n",
    "        else:\n",
    "            time_data = time_object['data']\n",
    "            time_metadata = time_object['custom-meta']\n",
    "        \n",
    "        current_key_amount = len(time_data)\n",
    "        current_key_full = False\n",
    "        current_key = str(current_key_amount)\n",
    "        if 0 < current_key_amount:\n",
    "            time_object = time_data[current_key]\n",
    "            if 0 < time_object['total-seconds']:\n",
    "                current_key_full = True\n",
    "        \n",
    "        changed = False\n",
    "        if 0 < end_time and 0 < current_key_amount and not current_key_full:\n",
    "            stored_start_time = time_data[current_key]['start-time']\n",
    "            time_diff = (end_time-stored_start_time)\n",
    "            time_data[current_key]['end-time'] = end_time\n",
    "            time_data[current_key]['total-seconds'] = round(time_diff,5)\n",
    "            changed = True\n",
    "        else:\n",
    "            next_key_amount = len(time_data) + 1\n",
    "            new_key = str(next_key_amount)\n",
    "        \n",
    "            if 0 < start_time and 0 == end_time:\n",
    "                time_data[new_key] = {\n",
    "                    'name': time_name,\n",
    "                    'start-time': start_time,\n",
    "                    'end-time': 0,\n",
    "                    'total-seconds': 0\n",
    "                }\n",
    "                changed = True\n",
    "\n",
    "            if 0 < start_time and 0 < end_time:\n",
    "                time_diff = (end_time-start_time)\n",
    "                time_data[new_key] = {\n",
    "                    'name': time_name,\n",
    "                    'start-time': start_time,\n",
    "                    'end-time': end_time,\n",
    "                    'total-seconds': round(time_diff,5)\n",
    "                }\n",
    "                changed = True\n",
    "\n",
    "        if changed:\n",
    "            time_metadata['version'] = time_metadata['version'] + 1\n",
    "            set_object(\n",
    "                storage_client = storage_client,\n",
    "                bucket_name = storage_name,\n",
    "                object_name = 'time',\n",
    "                path_replacers = {\n",
    "                    'name': time_group\n",
    "                },\n",
    "                path_names = [],\n",
    "                overwrite = True,\n",
    "                object_data = time_data,\n",
    "                object_metadata = time_metadata \n",
    "            )\n",
    "    \n",
    "    def set_route(\n",
    "        route_type: str,\n",
    "        route_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any\n",
    "    ): \n",
    "        routes = {\n",
    "            'root': 'TYPE:/name',\n",
    "            'logs': 'GET:/general/logs/name',\n",
    "            'structure': 'GET:/general/structure',\n",
    "            'setup': 'POST:/setup/config',\n",
    "            'start': 'POST:/setup/start',\n",
    "            'stop': 'POST:/setup/stop',\n",
    "            'job-submit': 'POST:/requests/submit/job',\n",
    "            'job-run': 'PUT:/requests/run/job/name',\n",
    "            'job-cancel': 'PUT:/requests/cancel/job/name',\n",
    "            'forwarding-submit': 'POST:/requests/submit/forwarding',\n",
    "            'forwarding-cancel': 'PUT:/requests/cancel/type/user/key',\n",
    "            'task-request': 'PUT:/tasks/request/signature',\n",
    "            'task-result': 'GET:/tasks/result/id',\n",
    "            'job-artifact': 'GET:/artifacts/job/type/name',\n",
    "            'forwarding-artifact': 'GET:/artifacts/forwarding/type/user/key'\n",
    "        }\n",
    "\n",
    "        route = None\n",
    "        if route_name in routes:\n",
    "            i = 0\n",
    "            route = routes[route_name].split('/')\n",
    "            for name in route:\n",
    "                if name in path_replacers:\n",
    "                    replacer = path_replacers[name]\n",
    "                    if 0 < len(replacer):\n",
    "                        route[i] = replacer\n",
    "                i = i + 1\n",
    "\n",
    "            if not len(path_names) == 0:\n",
    "                route.extend(path_names)\n",
    "\n",
    "            if not len(route_type) == 0:\n",
    "                route[0] = route_type + ':'\n",
    "            \n",
    "            route = '/'.join(route)\n",
    "        return route\n",
    "    \n",
    "    def get_response(\n",
    "        route_type: str,\n",
    "        route_url: str,\n",
    "        route_input: any\n",
    "    ) -> any:\n",
    "        route_response = None\n",
    "        if route_type == 'POST':\n",
    "            route_response = requests.post(\n",
    "                url = route_url,\n",
    "                json = route_input\n",
    "            )\n",
    "        if route_type == 'PUT':\n",
    "            route_response = requests.put(\n",
    "                url = route_url\n",
    "            )\n",
    "        if route_type == 'GET':\n",
    "            route_response = requests.get(\n",
    "                url = route_url\n",
    "            )\n",
    "        return route_response\n",
    "    \n",
    "    def set_full_url(\n",
    "        address: str,\n",
    "        port: str,\n",
    "        used_route: str\n",
    "    ) -> str:\n",
    "        url_prefix = 'http://' + address + ':' + port\n",
    "        route_split = used_route.split(':')\n",
    "        url_type = route_split[0]\n",
    "        used_path = route_split[1]\n",
    "        full_url = url_prefix + used_path\n",
    "        return url_type, full_url\n",
    "    \n",
    "    def request_route(\n",
    "        address: str,\n",
    "        port: str,\n",
    "        route_type: str,\n",
    "        route_name: str,\n",
    "        path_replacers: any,\n",
    "        path_names: any,\n",
    "        route_input: any,\n",
    "        timeout: any\n",
    "    ) -> any:\n",
    "        used_route = set_route(\n",
    "            route_type = route_type,\n",
    "            route_name = route_name,\n",
    "            path_replacers = path_replacers,\n",
    "            path_names = path_names\n",
    "        )\n",
    "\n",
    "        url_type, full_url = set_full_url(\n",
    "            address = address,\n",
    "            port = port,\n",
    "            used_route = used_route\n",
    "        )\n",
    "\n",
    "        route_response = get_response(\n",
    "            route_type = url_type,\n",
    "            route_url = full_url,\n",
    "            route_input = route_input\n",
    "        )\n",
    "\n",
    "        route_status_code = None\n",
    "        route_returned_text = {}\n",
    "        if not route_response is None:\n",
    "            route_status_code = route_response.status_code\n",
    "            if route_status_code == 200:\n",
    "                route_text = json.loads(route_response.text)\n",
    "\n",
    "                if 'id' in route_text: \n",
    "                    task_result_route = set_route(\n",
    "                        route_type = '',\n",
    "                        route_name = 'task-result',\n",
    "                        path_replacers = {\n",
    "                            'id': route_text['id']\n",
    "                        },\n",
    "                        path_names = []\n",
    "                    )\n",
    "\n",
    "                    task_url_type, task_full_url = set_full_url(\n",
    "                        address = address,\n",
    "                        port = port,\n",
    "                        used_route = task_result_route\n",
    "                    )\n",
    "\n",
    "                    start = t.time()\n",
    "                    while t.time() - start <= timeout:\n",
    "                        task_route_response = get_response(\n",
    "                            route_type = task_url_type,\n",
    "                            route_url = task_full_url,\n",
    "                            route_input = {}\n",
    "                        )\n",
    "                        \n",
    "                        task_status_code = route_response.status_code\n",
    "                            \n",
    "                        if task_status_code == 200:\n",
    "                            task_text = json.loads(task_route_response.text)\n",
    "                            if task_text['status'] == 'FAILED':\n",
    "                                break\n",
    "                            \n",
    "                            if task_text['status'] == 'SUCCESS':\n",
    "                                route_returned_text = task_text['result']\n",
    "                                break\n",
    "                        else:\n",
    "                            break\n",
    "                else:\n",
    "                    route_returned_text = route_text\n",
    "        return route_status_code, route_returned_text\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    component_time_start = t.time()\n",
    "\n",
    "    storage_client, storage_names = setup_storage( \n",
    "        storage_parameters = storage_parameters\n",
    "    )\n",
    "\n",
    "    logger.info('Storage setup')\n",
    "\n",
    "    pipeline_bucket = storage_names[-2]\n",
    "\n",
    "    logger.info('Used bucket: ' + str(pipeline_bucket))\n",
    "\n",
    "    logger.info('Setting up MLflow')\n",
    "\n",
    "    mlflow_tracking_uri = mlflow_parameters['tracking-uri']\n",
    "    \n",
    "    client = MlflowClient(\n",
    "        tracking_uri = mlflow_tracking_uri\n",
    "    )\n",
    "    info = client.get_run(run_id)\n",
    "    training_metrics = info.data.metrics\n",
    "\n",
    "    logger.info(f\"Training metrics: {training_metrics}\")\n",
    "\n",
    "    # compare the evaluation metrics with the defined thresholds\n",
    "    success = True\n",
    "    for key, value in metric_parameters.items():\n",
    "        logger.info(f\"Checked metric {key} with threshold {value}\")\n",
    "        if key not in training_metrics:\n",
    "            continue\n",
    "        training_metric = training_metrics[key]\n",
    "        if training_metric < value:\n",
    "            logger.error(f\"Metric {key} failed with {training_metric}. Evaluation not passed!\")\n",
    "            success = False\n",
    "\n",
    "    logger.info('Stopping forwarder scheduler')\n",
    "\n",
    "    forwarder_address = integration_parameters['forwarder-address']\n",
    "    forwarder_port = integration_parameters['forwarder-port']\n",
    "    \n",
    "    forwarder_scheduler_stopped = request_route(\n",
    "        address = forwarder_address,\n",
    "        port = forwarder_port,\n",
    "        route_type = '',\n",
    "        route_name = 'stop',\n",
    "        path_replacers = {},\n",
    "        path_names = [],\n",
    "        route_input = {},\n",
    "        timeout = 120\n",
    "    ) \n",
    "\n",
    "    logger.info('Forwarder scheduler stopped: ' + str(forwarder_scheduler_stopped))\n",
    "    \n",
    "    component_time_end = t.time()\n",
    "\n",
    "    gather_time(\n",
    "        storage_client = storage_client,\n",
    "        storage_name = pipeline_bucket,\n",
    "        time_group = 'components',\n",
    "        time_name = 'cloud-hpc-evaluate',\n",
    "        start_time = component_time_start,\n",
    "        end_time = component_time_end\n",
    "    )\n",
    "\n",
    "    return success"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f1adcb-572c-48eb-a3f9-f62dd25c861a",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "626e03ab-f1f0-48ad-98b3-d41c68bf0dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name = 'cloud-hpc-pipeline',\n",
    "    description = 'Cloud-HPC integrated pipeline for Fashion MNIST CNN',\n",
    ")\n",
    "def pipeline(\n",
    "    storage_parameters: dict,\n",
    "    integration_parameters: dict,\n",
    "    mlflow_parameters: dict,\n",
    "    metric_parameters: dict\n",
    "):\n",
    "    preprocess_task = preprocess(\n",
    "        storage_parameters = storage_parameters,\n",
    "        integration_parameters = integration_parameters\n",
    "    )\n",
    "\n",
    "    preprocess_sucess = preprocess_task.output\n",
    "    \n",
    "    with dsl.Condition(preprocess_sucess == 'true'):\n",
    "        train_task = train(\n",
    "            storage_parameters = storage_parameters,\n",
    "            integration_parameters = integration_parameters,\n",
    "            mlflow_parameters = mlflow_parameters\n",
    "        )\n",
    "        train_task.after(preprocess_task)\n",
    "        train_task.apply(use_aws_secret(secret_name=\"aws-secret\"))\n",
    "\n",
    "        with dsl.Condition(train_task.outputs[\"run_id\"] != \"none\"):\n",
    "            evaluate_task = evaluate(\n",
    "                storage_parameters = storage_parameters,\n",
    "                integration_parameters = integration_parameters,\n",
    "                mlflow_parameters = mlflow_parameters,\n",
    "                metric_parameters = metric_parameters,\n",
    "                run_id = train_task.outputs[\"run_id\"]\n",
    "            )\n",
    "            evaluate_task.after(train_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85551c4-2864-453b-a956-cbf8f779f9e6",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a08b387-56d0-48e4-a294-480980edeb75",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "\n",
    "If you have not used Allas, please check the following CSC docs.\n",
    "\n",
    "- [Python with swift](https://docs.csc.fi/data/Allas/using_allas/python_swift/)\n",
    "- [Keystoneauth loader](https://docs.openstack.org/keystoneauth/latest/api/keystoneauth1.loading.html)\n",
    "- [Keystoneauth session](https://docs.openstack.org/keystoneauth/latest/api/keystoneauth1.session.html)\n",
    "- [Swiftclient](https://docs.openstack.org/python-swiftclient/stein/swiftclient.html)\n",
    "- [CPouta APIs](https://docs.csc.fi/cloud/pouta/api-access/)\n",
    "\n",
    "The short version is that you can get auth_url, auth_version, user, key, project name and user domain from the first document and the pre auth url from CPouta/Allas dashboard API access in object_store row. Use these docs to create a .env containing used credentials:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48e89f4-1c06-4800-b72f-4fff52b8a579",
   "metadata": {},
   "source": [
    "#### Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc302fa2-8416-4da2-ac46-59b8097500be",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_parameters = get_storage_parameters(\n",
    "    env_path = env_absolute_path,\n",
    "    auth_url = 'https://pouta.csc.fi:5001/v3',\n",
    "    pre_auth_url = 'https://a3s.fi:443/swift/v1/AUTH_6698ff90e6704a74930c33d6b66f1b5b',\n",
    "    auth_version = '3',\n",
    "    bucket_prefix = 'integration',\n",
    "    ice_id = 's0-c0-u1',\n",
    "    user = 'user@example.com'\n",
    ")\n",
    "\n",
    "storage_client, storage_names = setup_storage(\n",
    "    storage_parameters = storage_parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4f5b1c",
   "metadata": {},
   "source": [
    "The following JSON provides details to forwarder. You can leave it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be127dc-de4f-49f2-940c-ccffc3b6ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forwarder_configuration = {\n",
    "    'ice-id': 's0-c0-u1',\n",
    "    'enviroments': {\n",
    "        'secrets-path': '',\n",
    "        'cloud': {\n",
    "            'platforms': [\n",
    "                'cpouta'\n",
    "            ]\n",
    "        },\n",
    "        'storage': {\n",
    "            'platforms': [\n",
    "                'allas'\n",
    "            ],\n",
    "            'object-store': {\n",
    "                'used-client': storage_parameters['used-client'],\n",
    "                'pre-auth-url': storage_parameters['pre-auth-url'],\n",
    "                'pre-auth-token': storage_parameters['pre-auth-token'],\n",
    "                'user-domain-name': storage_parameters['user-domain-name'],\n",
    "                'project-domain-name': storage_parameters['project-domain-name'],\n",
    "                'project-name': storage_parameters['project-name'],\n",
    "                'auth-version': storage_parameters['auth-version'],\n",
    "                'bucket-prefix': storage_parameters['bucket-prefix']\n",
    "            }\n",
    "        },\n",
    "        'hpc': {\n",
    "            'platforms': [\n",
    "                'mahti'\n",
    "            ]\n",
    "        },\n",
    "        'integration': {\n",
    "            'platforms': [\n",
    "                'cpouta-mahti'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95234e8",
   "metadata": {},
   "source": [
    "This JSON specifies the restart interval of each scheduled task. You can leave it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc3b1bb-96b7-4d0c-ac08-06efc59d2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forwarder_scheduler_request = {\n",
    "    'task-times': [\n",
    "        '55',\n",
    "        '170',\n",
    "        '265'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6acc6b9",
   "metadata": {},
   "source": [
    "This JSON specifies services for IPs outside of KinD cluster, which are the VM network IPs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53f1eb-72c7-435c-9b38-5018de658d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forwarding_request = {\n",
    "    'user': 'user@example.com',\n",
    "    'imports': [\n",
    "        {\n",
    "            'name': 'ray-dashboard',\n",
    "            'address': '192.168.1.13',\n",
    "            'port': '8280'\n",
    "        }\n",
    "    ],\n",
    "    'exports': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd96d6c",
   "metadata": {},
   "source": [
    "This JSON specifies the necessary details for running Ray SLURM in HPC platform. Fill in details with keyword 'your'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb023354-fc5a-4234-9e9b-782a4795e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_request = {\n",
    "    'user': 'user@example.com',\n",
    "    'target': 'hpc/mahti',\n",
    "    'name': '/users/(your_csc_username)/ray-cluster.sh',\n",
    "    'enviroment': {\n",
    "        'submission-modules': [\n",
    "            'gcc',\n",
    "            'openmpi',\n",
    "            'openblas',\n",
    "            'csc-tools',\n",
    "            'StdEnv'\n",
    "        ],\n",
    "        'venv': {\n",
    "            'name': 'exp-venv',\n",
    "            'directory': 'users',\n",
    "            'configuration-modules': [\n",
    "                'pytorch'\n",
    "            ],\n",
    "            'packages': [\n",
    "                'ray',\n",
    "                'python-swiftclient',\n",
    "                'torch',\n",
    "                'torchmetrics'\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'files': {\n",
    "        'provide': [\n",
    "            {\n",
    "                'source': 'local/submitter/secrets|integration|cpouta-mahti|key',\n",
    "                'target': 'hpc/mahti/users/(your_csc_username)/cpouta-mahti.pem',\n",
    "                'overwrite': False\n",
    "            },\n",
    "            {\n",
    "                'source': 'storage/allas/pipeline/CODE/SLURM/ray-cluster.sh',\n",
    "                'target': 'hpc/mahti/users/(your_csc_username)/ray-cluster.sh',\n",
    "                'overwrite': True\n",
    "            }\n",
    "        ],\n",
    "        'store': [\n",
    "            {\n",
    "                'source': 'hpc/mahti/users/(your_csc_username)/slurm-(id).out',\n",
    "                'target': 'storage/allas/pipeline/LOGS/(key)',\n",
    "                'remove': False\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    'workflow': {\n",
    "        'requires': [],\n",
    "        'enables': []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fb8a17",
   "metadata": {},
   "source": [
    "This JSON provides details for Kubeflow and the sent Ray scripts. You can leave them as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6efcd8c-a89b-4723-a0b2-1cd74cb5f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_parameters = {\n",
    "    'forwarder-address': 'fastapi-service.forwarder.svc.cluster.local',\n",
    "    'forwarder-port': '6500',\n",
    "    'configuration': forwarder_configuration,\n",
    "    'scheduler-request': forwarder_scheduler_request,\n",
    "    'forwarding-request': forwarding_request,\n",
    "    'user': 'user@example.com',\n",
    "    'job-request': job_request,\n",
    "    'ray-job-file': 'train-fmnist-cnn.py',\n",
    "    'ray-job-envs': {},\n",
    "    'folder-name': 'FMNIST',\n",
    "    'ray-parameters': {\n",
    "        'storage-parameters': storage_parameters,\n",
    "        'job-parameters': {\n",
    "            'folder-name': 'FMNIST',\n",
    "            'train-print-rate': 2000,\n",
    "            'hp-train-batch-size': 4,\n",
    "            'hp-test-batch-size': 4,\n",
    "            'hp-seed': 42,\n",
    "            'hp-epochs': 5,\n",
    "            'hp-learning-rate': 0.001,\n",
    "            'hp-momentum': 0.9\n",
    "        }\n",
    "    },\n",
    "    'ray-job-timeout': 5000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd414a",
   "metadata": {},
   "source": [
    "This JSON provides details to MLflow. Leave as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea25942-af31-465a-97cc-e3c3a2500525",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_parameters = {\n",
    "    'tracking-uri': 'http://mlflow.mlflow.svc.cluster.local:5000',\n",
    "    's3-endpoint-url': 'http://mlflow-minio-service.mlflow.svc.cluster.local:9000',\n",
    "    'experiment-name': 'cloud-hpc-fmnist-pipeline',\n",
    "    'model-name': 'cloud-hpc-fmnist-cnn',\n",
    "    'registered-name': 'CLOUD-HPC-FMNIST-CNN'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb59aaab",
   "metadata": {},
   "source": [
    "This JSON specifies the metric thresholds used by kubeflow for tests. Leave as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a870097b-2409-4e33-8dad-c9b18107fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_parameters = {\n",
    "    'accuracy': 0.80,\n",
    "    'precision': 0.80,\n",
    "    'recall': 0.80\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab358227-6a92-42f2-bcd1-aa62a445f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_arguments = {\n",
    "    'storage_parameters': storage_parameters,\n",
    "    'integration_parameters': integration_parameters,\n",
    "    'mlflow_parameters': mlflow_parameters,\n",
    "    'metric_parameters': metric_parameters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec00e4-7a48-4420-a2dd-a25874d52b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_route(\n",
    "    route_type: str,\n",
    "    route_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any\n",
    "): \n",
    "    routes = {\n",
    "        'root': 'TYPE:/name',\n",
    "        'logs': 'GET:/general/logs/name',\n",
    "        'structure': 'GET:/general/structure',\n",
    "        'setup': 'POST:/setup/config',\n",
    "        'start': 'POST:/setup/start',\n",
    "        'stop': 'POST:/setup/stop',\n",
    "        'job-submit': 'POST:/requests/submit/job',\n",
    "        'job-run': 'PUT:/requests/run/job/key',\n",
    "        'job-cancel': 'PUT:/requests/cancel/job/key',\n",
    "        'forwarding-submit': 'POST:/requests/submit/forwarding',\n",
    "        'forwarding-cancel': 'PUT:/requests/cancel/type/user/key',\n",
    "        'task-request': 'PUT:/tasks/request/signature',\n",
    "        'task-result': 'GET:/tasks/result/id',\n",
    "        'job-artifact': 'GET:/artifacts/job/type/name',\n",
    "        'forwarding-artifact': 'GET:/artifacts/forwarding/type/user/key'\n",
    "    }\n",
    "\n",
    "    route = None\n",
    "    if route_name in routes:\n",
    "        i = 0\n",
    "        route = routes[route_name].split('/')\n",
    "        for name in route:\n",
    "            if name in path_replacers:\n",
    "                replacer = path_replacers[name]\n",
    "                if 0 < len(replacer):\n",
    "                    route[i] = replacer\n",
    "            i = i + 1\n",
    "\n",
    "        if not len(path_names) == 0:\n",
    "            route.extend(path_names)\n",
    "\n",
    "        if not len(route_type) == 0:\n",
    "            route[0] = route_type + ':'\n",
    "        \n",
    "        route = '/'.join(route)\n",
    "    print('Used route: ' + str(route))\n",
    "    return route\n",
    "\n",
    "def get_response(\n",
    "    route_type: str,\n",
    "    route_url: str,\n",
    "    route_input: any\n",
    ") -> any:\n",
    "    route_response = None\n",
    "    if route_type == 'POST':\n",
    "        route_response = requests.post(\n",
    "            url = route_url,\n",
    "            json = route_input\n",
    "        )\n",
    "    if route_type == 'PUT':\n",
    "        route_response = requests.put(\n",
    "            url = route_url\n",
    "        )\n",
    "    if route_type == 'GET':\n",
    "        route_response = requests.get(\n",
    "            url = route_url\n",
    "        )\n",
    "    return route_response\n",
    "\n",
    "def set_full_url(\n",
    "    address: str,\n",
    "    port: str,\n",
    "    used_route: str\n",
    ") -> str:\n",
    "    url_prefix = 'http://' + address + ':' + port\n",
    "    route_split = used_route.split(':')\n",
    "    url_type = route_split[0]\n",
    "    used_path = route_split[1]\n",
    "    full_url = url_prefix + used_path\n",
    "    return url_type, full_url\n",
    "\n",
    "def request_route(\n",
    "    address: str,\n",
    "    port: str,\n",
    "    route_type: str,\n",
    "    route_name: str,\n",
    "    path_replacers: any,\n",
    "    path_names: any,\n",
    "    route_input: any,\n",
    "    timeout: any\n",
    ") -> any:\n",
    "    used_route = set_route(\n",
    "        route_type = route_type,\n",
    "        route_name = route_name,\n",
    "        path_replacers = path_replacers,\n",
    "        path_names = path_names\n",
    "    )\n",
    "\n",
    "    url_type, full_url = set_full_url(\n",
    "        address = address,\n",
    "        port = port,\n",
    "        used_route = used_route\n",
    "    )\n",
    "\n",
    "    route_response = get_response(\n",
    "        route_type = url_type,\n",
    "        route_url = full_url,\n",
    "        route_input = route_input\n",
    "    )\n",
    "\n",
    "    route_status_code = None\n",
    "    route_returned_text = {}\n",
    "    if not route_response is None:\n",
    "        route_status_code = route_response.status_code\n",
    "        if route_status_code == 200:\n",
    "            route_text = json.loads(route_response.text)\n",
    "\n",
    "            if 'id' in route_text: \n",
    "                task_result_route = set_route(\n",
    "                    route_type = '',\n",
    "                    route_name = 'task-result',\n",
    "                    path_replacers = {\n",
    "                        'id': route_text['id']\n",
    "                    },\n",
    "                    path_names = []\n",
    "                )\n",
    "\n",
    "                task_url_type, task_full_url = set_full_url(\n",
    "                    address = address,\n",
    "                    port = port,\n",
    "                    used_route = task_result_route\n",
    "                )\n",
    "\n",
    "                start = time.time()\n",
    "                while time.time() - start <= timeout:\n",
    "                    task_route_response = get_response(\n",
    "                        route_type = task_url_type,\n",
    "                        route_url = task_full_url,\n",
    "                        route_input = {}\n",
    "                    )\n",
    "                    \n",
    "                    task_status_code = route_response.status_code\n",
    "                        \n",
    "                    if task_status_code == 200:\n",
    "                        task_text = json.loads(task_route_response.text)\n",
    "                        if task_text['status'] == 'FAILED':\n",
    "                            break\n",
    "                        if task_text['status'] == 'SUCCESS':\n",
    "                            route_returned_text = task_text['result']\n",
    "                            break\n",
    "                    else:\n",
    "                        break\n",
    "            else:\n",
    "                route_returned_text = route_text\n",
    "    return route_status_code, route_returned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c524508-5593-426b-b87d-2adc29dcc859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['integration-forwarder-s0-c0-u1',\n",
       " 'integration-submitter-s0-c0-u1-user-example-com',\n",
       " 'integration-pipeline-s0-c0-u1-user-example-com',\n",
       " 'integration-experiment-s0-c0-u1-user-example-com']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279714dd-5dd4-4ea2-adb5-1f6aa0148eff",
   "metadata": {},
   "source": [
    "## Start Submitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13b8a2b-9a4c-4f0a-a0c4-2e21f34f890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_folder = '/home/(your_local_username)/oss-mlops-platform/applications/integration/submitter/deployment/production'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "397c2d9e-193d-4eb4-b7e7-4f9dd7e93187",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_file = deployment_folder + '/' + 'stack.yaml'\n",
    "scheduler_file = deployment_folder + '/' + 'scheduler.yaml'\n",
    "submitter_file_paths = [\n",
    "    stack_file,\n",
    "    scheduler_file\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "957645fa-b8d5-4c2a-a67f-8f70c3607796",
   "metadata": {},
   "outputs": [],
   "source": [
    "submitter_address = '127.0.0.1'\n",
    "submitter_port = '6600'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c5976",
   "metadata": {},
   "source": [
    "This JSON provides setup details for submitter. Leave it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44ee5a3e-235f-4297-81e2-c16f6088c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets_path = '/run/secrets/secret-metadata'\n",
    "submitter_configuration = {\n",
    "    'ice-id': 's0-c0-u1',\n",
    "    'user': 'user@example.com',\n",
    "    'enviroments': {\n",
    "        'secrets-path': secrets_path,\n",
    "        'cloud': {\n",
    "            'platforms': [\n",
    "                'cpouta'\n",
    "            ]\n",
    "        },\n",
    "        'storage': {\n",
    "            'platforms': [\n",
    "                'allas'\n",
    "            ],\n",
    "            'object-store': {\n",
    "                'used-client': storage_parameters['used-client'],\n",
    "                'pre-auth-url': storage_parameters['pre-auth-url'],\n",
    "                'pre-auth-token': storage_parameters['pre-auth-token'],\n",
    "                'user-domain-name': storage_parameters['user-domain-name'],\n",
    "                'project-domain-name': storage_parameters['project-domain-name'],\n",
    "                'project-name': storage_parameters['project-name'],\n",
    "                'auth-version': storage_parameters['auth-version'],\n",
    "                'bucket-prefix': storage_parameters['bucket-prefix'],\n",
    "            }\n",
    "        },\n",
    "        'hpc': {\n",
    "            'platforms': [\n",
    "                'mahti'\n",
    "            ]\n",
    "        },\n",
    "        'integration': {\n",
    "            'platforms': [\n",
    "                'cpouta-mahti'\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66f8368",
   "metadata": {},
   "source": [
    "Run this to start up Submitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f03708f-e53a-4e11-aa9d-517049d9a62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_compose(\n",
    "    file_path = submitter_file_paths[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93603d4e-a774-4605-b7c4-679591bebf77",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "You can check the submitter frontend and monitor with:\n",
    "- http://localhost:6600\n",
    "- http://localhost:6601"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66fe42dc-0ebe-413b-b303-e28e7dee50b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used route: POST:/setup/config\n",
      "Used route: GET:/tasks/result/f34730b6-899c-4513-b7fe-4bac9e36a560\n",
      "200\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "route_code, route_text = request_route(\n",
    "    address = '127.0.0.1',\n",
    "    port = '6600',\n",
    "    route_type = '',\n",
    "    route_name = 'setup',\n",
    "    path_replacers = {},\n",
    "    path_names = [],\n",
    "    route_input = submitter_configuration,\n",
    "    timeout = 240\n",
    ")\n",
    "print(route_code)\n",
    "print(route_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "171887ec-59cd-495a-a440-59839e5d3fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_compose(\n",
    "    file_path = submitter_file_paths[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c0530-4ab5-4f0f-90e2-4123504439ae",
   "metadata": {},
   "source": [
    "## Local Forwards\n",
    "\n",
    "In order to use and monitor the pipeline progress, open following local forwards:\n",
    "\n",
    "```\n",
    "kubeflow\n",
    "ssh -L 8080:localhost:8080 cpouta\n",
    "kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80\n",
    "localhost:8080\n",
    "\n",
    "forwarder frontend\n",
    "\n",
    "ssh -L 6500:localhost:6500 cpouta\n",
    "kubectl port-forward svc/fastapi-service 6500:6500 -n forwarder\n",
    "localhost:6500\n",
    "\n",
    "forwarder monitor\n",
    "\n",
    "ssh -L 6501:localhost:6501 cpouta\n",
    "kubectl port-forward svc/flower-service 6501:6501 -n forwarder\n",
    "localhost:6501\n",
    "\n",
    "ray dashboard\n",
    "ssh -L 127.0.0.1:8280:192.168.1.13:8280 cpouta\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789b8468-37b9-4c40-9f4b-2926eb274e7b",
   "metadata": {},
   "source": [
    "#### Submit Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0213284d-47f9-4f68-a0bf-bb1861fbe2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as t\n",
    "\n",
    "def wait_kubeflow_run(\n",
    "    kfp_client: any,\n",
    "    timeout: int,\n",
    "    run_id: str\n",
    "):\n",
    "    start = t.time()\n",
    "    run_status = None\n",
    "    print('Checking kubeflow run: ' + str(run_id))\n",
    "    while t.time() - start <= timeout:\n",
    "        run_details = kfp_client.get_run(\n",
    "            run_id = run_id\n",
    "        )\n",
    "        run_status = run_details.run.status\n",
    "        print('Run status: ' + str(run_status))\n",
    "        if run_status == 'Failed':\n",
    "            run_status = False\n",
    "            break\n",
    "        if run_status == 'Succeeded':\n",
    "            run_status = True\n",
    "            break\n",
    "        if run_status == 'Error':\n",
    "            run_status = True\n",
    "            break\n",
    "        t.sleep(10)\n",
    "    return run_status\n",
    "\n",
    "def manage_kubeflow_run(\n",
    "    submitter_file_paths: any,\n",
    "    submitter_address: str,\n",
    "    submitter_port: str,\n",
    "    submitter_configuration: str,\n",
    "    storage_client: any,\n",
    "    storage_name: str,\n",
    "    kfp_client: any,\n",
    "    run_name: str,\n",
    "    experiment_name: str,\n",
    "    pipeline_arguments: any,\n",
    "    timeout: int\n",
    "):\n",
    "    time_start = t.time()\n",
    "    \n",
    "    print('Submitting pipeline')\n",
    "    run_details = kfp_client.create_run_from_pipeline_func(\n",
    "        pipeline_func = pipeline,\n",
    "        run_name = run_name,\n",
    "        experiment_name = experiment_name,\n",
    "        arguments = pipeline_arguments,\n",
    "        mode = kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE,\n",
    "        enable_caching = True,\n",
    "        namespace = \"kubeflow-user-example-com\"\n",
    "    )\n",
    "\n",
    "    run_status = wait_kubeflow_run(\n",
    "        kfp_client = kfp_client,\n",
    "        timeout = timeout,\n",
    "        run_id = run_details.run_id\n",
    "    )\n",
    "\n",
    "    print('Run status: ' + str(run_status))\n",
    "    \n",
    "    time_end = t.time()\n",
    "\n",
    "    gather_time(\n",
    "        storage_client = storage_client,\n",
    "        storage_name = storage_name,\n",
    "        time_group = 'components',\n",
    "        time_name = 'cloud-hpc-pipeline',\n",
    "        start_time = time_start,\n",
    "        end_time = time_end\n",
    "    )\n",
    "\n",
    "    print('Kubeflow pipeline complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf84f62a-fa2d-4a00-b407-1755a2b335be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp.aws import use_aws_secret\n",
    "from kfp.v2.dsl import (\n",
    "    component,\n",
    "    Input,\n",
    "    Output,\n",
    "    Dataset,\n",
    "    Metrics,\n",
    "    Artifact,\n",
    "    Model\n",
    ")\n",
    "\n",
    "KUBEFLOW_ENDPOINT = 'http://localhost:8080'\n",
    "KUBEFLOW_USERNAME = 'user@example.com'\n",
    "KUBEFLOW_PASSWORD = '12341234'\n",
    "\n",
    "auth_session = get_istio_auth_session(\n",
    "    url=KUBEFLOW_ENDPOINT,\n",
    "    username=KUBEFLOW_USERNAME,\n",
    "    password=KUBEFLOW_PASSWORD\n",
    ")\n",
    "\n",
    "kfp_client = kfp.Client(host=f\"{KUBEFLOW_ENDPOINT}/pipeline\", cookies=auth_session[\"session_cookie\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "606793f8-a6e9-4c60-8edc-9fb3c8089f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting pipeline\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:8080/pipeline/#/experiments/details/6fc2d164-5244-4e50-b38b-a085096b816e\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:8080/pipeline/#/runs/details/19c31f67-eed6-4ec3-8c52-de1e015fa929\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking kubeflow run: 19c31f67-eed6-4ec3-8c52-de1e015fa929\n",
      "Run status: None\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Running\n",
      "Run status: Succeeded\n",
      "Run status: True\n",
      "Used object path:TIMES/components\n",
      "Used object path:TIMES/components\n",
      "Kubeflow pipeline complete\n"
     ]
    }
   ],
   "source": [
    "manage_kubeflow_run(\n",
    "    submitter_file_paths = submitter_file_paths,\n",
    "    submitter_address = submitter_address,\n",
    "    submitter_port = submitter_port,\n",
    "    submitter_configuration = submitter_configuration,\n",
    "    storage_client = storage_client,\n",
    "    storage_name = storage_names[-2],\n",
    "    kfp_client = kfp_client,\n",
    "    run_name = \"cloud-hpc-fmnist-exp-run\",\n",
    "    experiment_name = \"cloud-hpc-fmnist-experiment\",\n",
    "    pipeline_arguments = pipeline_arguments,\n",
    "    timeout = 5000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b355faa-a443-4021-abac-68425703abed",
   "metadata": {},
   "source": [
    "## Stop Submitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d9408b",
   "metadata": {},
   "source": [
    "Run this to stop Submitter scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "295f6d42-157f-437d-ad9a-444ad9062592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_compose(\n",
    "    file_path = submitter_file_paths[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff6d71c",
   "metadata": {},
   "source": [
    "Run this to stop all Submitter containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "32dd2cd7-61d7-47a8-a03a-732ccfde68d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_compose(\n",
    "    file_path = submitter_file_paths[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7d9f3c-e085-4a8b-a647-efdceb0623b8",
   "metadata": {},
   "source": [
    "## Removing completed or error kubeflow pods\n",
    "\n",
    "If your kubeflow pipelines fail due to not having enough memory, then run these\n",
    "to remove kubeflow pods:\n",
    "\n",
    "```\n",
    "kubectl delete pod -n kubeflow-user-example-com --field-selector=status.phase=Failed\n",
    "kubectl delete pod -n kubeflow-user-example-com --field-selector=status.phase=Succeeded\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f22f4f-a3b8-42ad-857e-f050b3c6c840",
   "metadata": {},
   "source": [
    "## Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35593bd-b320-4907-941f-3e365cda4f9f",
   "metadata": {},
   "source": [
    "Packages:\n",
    "- Ray version is:2.9.3\n",
    "- Swiftclient version is:4.4.0\n",
    "- PyTorch version is:2.2.1+cu121\n",
    "- Torchmetrics version is:1.3.1\n",
    "\n",
    "Hardware:\n",
    "\n",
    "- OSS:\n",
    "    - Resource request:\n",
    "        ```\n",
    "        Allocated resources:\n",
    "          (Total limits may be over 100 percent, i.e., overcommitted.)\n",
    "          Resource           Requests           Limits\n",
    "          --------           --------           ------\n",
    "          cpu                6570m (82%)        61800m (772%)\n",
    "          memory             11732346112 (35%)  36710Mi (117%)\n",
    "          ephemeral-storage  0 (0%)             0 (0%)\n",
    "          hugepages-1Gi      0 (0%)             0 (0%)\n",
    "          hugepages-2Mi      0 (0%)             0 (0%)\n",
    "        ```\n",
    "- CPouta:\n",
    "    - Image = Ubuntu 22.04\n",
    "    - Flavor = standard.xxlarge\n",
    "        - CPU Cores = 8\n",
    "        - RAM = 31 GiB\n",
    "        - DISK = 80 GB\n",
    "        - Memory/core = 3.8 GiB\n",
    "        - Redundancy = P,R,N\n",
    "        - BU/h = 8\n",
    "    - Floating IP\n",
    "        - BU/h = 0.2\n",
    "    - Security groups:\n",
    "        - Laptop SSH\n",
    "        - Mahti-node-1 SSH\n",
    "        - Mahti-node-2 SSH \n",
    "- Allas (format is pickle):\n",
    "    - Integration-forwarder-s0-c0-u1 = 270.15 KB\n",
    "    - integration-pipeline-s0-c0-u1-user-example-com = 53.47 MB\n",
    "    - integration-submitter-s0-c0-u1-user-example-com = 362.32 KB\n",
    "- Mahti:\n",
    "    - Type = SLURM Cluster Node\n",
    "    - Partition = Medium\n",
    "    - Nodes = 2\n",
    "    - Node CPU = AMD Zen 2 Rome 7H12 x 64 core\n",
    "    - Node RAM = 10GB\n",
    "    - OS = Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283b36e8-92f0-4107-9062-cf48e5bfffe6",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f73027-96f5-479d-8386-f855da1d68e5",
   "metadata": {},
   "source": [
    "## MLflow\n",
    "\n",
    "To use the MLflow analysis tools, run the following\n",
    "```\n",
    "ssh -L 5000:localhost:5000 cpouta\n",
    "kubectl -n mlflow port-forward svc/mlflow 5000:5000\n",
    "```\n",
    "\n",
    "and go to localhost:5000\n",
    "\n",
    "## Grafana\n",
    "\n",
    "To use Grafana dashboards, run the following\n",
    "\n",
    "```\n",
    "ssh -L 5050:localhost:5050 cpouta\n",
    "kubectl port-forward svc/grafana 5050:3000 --namespace monitoring\n",
    "```\n",
    "\n",
    "login with admin-admin and import the provided dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04927a4a-80bb-42c3-813c-e895d766dd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used object path:ARTIFACTS/FMNIST/metrics\n"
     ]
    }
   ],
   "source": [
    "model_metrics = get_object(\n",
    "    storage_client = storage_client,\n",
    "    bucket_name = storage_names[-2],\n",
    "    object_name = 'root',\n",
    "    path_replacers = {\n",
    "        'name': 'ARTIFACTS'\n",
    "    },\n",
    "    path_names = [\n",
    "        'FMNIST',\n",
    "        'metrics'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed92ba6d-954d-44da-9ab1-2ca44a01487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics_data = model_metrics['data']\n",
    "with open('artifacts/cloud-hpc-metrics-1.json', 'w') as f:\n",
    "    json.dump(model_metrics_data, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bc0d0616-c01d-4be9-9a6c-6527aed14f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Convolutional-neural-network-classifier',\n",
       " 'accuracy': 0.8819999694824219,\n",
       " 'precision': 0.8865039348602295,\n",
       " 'recall': 0.8819999694824219,\n",
       " 'class-accuracy': [0.7680000066757202,\n",
       "  0.984000027179718,\n",
       "  0.8109999895095825,\n",
       "  0.8830000162124634,\n",
       "  0.8090000152587891,\n",
       "  0.9430000185966492,\n",
       "  0.7250000238418579,\n",
       "  0.9620000123977661,\n",
       "  0.9739999771118164,\n",
       "  0.9610000252723694],\n",
       " 'class-precision': [0.8757126331329346,\n",
       "  0.9685039520263672,\n",
       "  0.8430353403091431,\n",
       "  0.896446704864502,\n",
       "  0.8374741077423096,\n",
       "  0.9895068407058716,\n",
       "  0.6144067645072937,\n",
       "  0.9241114258766174,\n",
       "  0.9643564224243164,\n",
       "  0.9514851570129395],\n",
       " 'class-recall': [0.7680000066757202,\n",
       "  0.984000027179718,\n",
       "  0.8109999895095825,\n",
       "  0.8830000162124634,\n",
       "  0.8090000152587891,\n",
       "  0.9430000185966492,\n",
       "  0.7250000238418579,\n",
       "  0.9620000123977661,\n",
       "  0.9739999771118164,\n",
       "  0.9610000252723694]}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2cbdc74e-d4d0-496e-a711-565326fa5b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used object path:ARTIFACTS/FMNIST/parameters\n"
     ]
    }
   ],
   "source": [
    "model_parameters = get_object(\n",
    "    storage_client = storage_client,\n",
    "    bucket_name = storage_names[-2],\n",
    "    object_name = 'root',\n",
    "    path_replacers = {\n",
    "        'name': 'ARTIFACTS'\n",
    "    },\n",
    "    path_names = [\n",
    "        'FMNIST',\n",
    "        'parameters'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c300df-e8a8-4b5b-8189-674e9d131c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model_parameters_data = model_parameters['data']\n",
    "\n",
    "model = model_parameters_data['model']\n",
    "optimizer = model_parameters_data['optimizer']\n",
    "\n",
    "torch.save(model, 'artifacts/cloud-hpc-model-1.pth')\n",
    "torch.save(optimizer, 'artifacts/cloud-hpc-optimizer-1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "faa13188-2767-471e-9968-b88e98da7dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used object path:ARTIFACTS/FMNIST/predictions\n"
     ]
    }
   ],
   "source": [
    "model_predictions = get_object(\n",
    "    storage_client = storage_client,\n",
    "    bucket_name = storage_names[-2],\n",
    "    object_name = 'root',\n",
    "    path_replacers = {\n",
    "        'name': 'ARTIFACTS'\n",
    "    },\n",
    "    path_names = [\n",
    "        'FMNIST',\n",
    "        'predictions'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "457e44de-cf9f-4649-9ef2-28b40e7de87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "model_predictions_data = model_predictions['data']\n",
    "np.save('artifacts/cloud-hpc-predictions-1.npy', model_predictions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0710e18-475b-444b-8293-e2ab73ca64a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bfc7b357-cada-4f8a-a94f-bf8d5e06566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = './data', \n",
    "    train = False, \n",
    "    download = True, \n",
    "    transform = test_transform\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, \n",
    "    batch_size = 4, \n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "942955dd-4096-4e0c-9b95-bca26f65d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(iter(test_loader))\n",
    "inputs, labels = first_batch\n",
    "sample_inputs = inputs.numpy().tolist()\n",
    "sample_labels = labels.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b526f79-8067-4616-affd-3d21150ec841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def inference(\n",
    "    model_state_path: any,\n",
    "    inputs: any\n",
    ") -> any:\n",
    "    model = CNNClassifier()\n",
    "    model.load_state_dict(torch.load(model_state_path))\n",
    "    predictions = []\n",
    "    inputs = torch.tensor(np.array(inputs, dtype=np.float32))\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.max(outputs, 1)[1]\n",
    "        predictions.extend(preds.tolist())\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4bfe772c-709e-4101-a0eb-539be1445005",
   "metadata": {},
   "outputs": [],
   "source": [
    "created_preds = inference(\n",
    "    model_state_path = 'artifacts/cloud-hpc-model-1.pth',\n",
    "    inputs = sample_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3400457b-9576-4c46-9e8b-fb9396147170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 2, 1, 1]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "b7ba30c4-0e95-47d0-9a83-aa74da4b50a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 2, 1, 1]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408de8fe-f833-4d00-9245-2614ca3aaece",
   "metadata": {},
   "source": [
    "## TIMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0301e98f-4c93-4148-8420-0b1157e03840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used object path:TIMES/ray-jobs\n"
     ]
    }
   ],
   "source": [
    "training_time = get_object(\n",
    "    storage_client = storage_client,\n",
    "    bucket_name = storage_names[-2],\n",
    "    object_name = 'root',\n",
    "    path_replacers = {\n",
    "        'name': 'TIMES'\n",
    "    },\n",
    "    path_names = [\n",
    "        'ray-jobs'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2c1c3945-d4ac-4367-a489-5f1910ea0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_time_data = training_time['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6894889b-0839-4063-8af5-8818d7a29d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('times/training-1.json', 'w') as f:\n",
    "    json.dump(training_time_data, f, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "178474f3-7716-4267-a366-3e0c222c8075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used object path:TIMES/components\n"
     ]
    }
   ],
   "source": [
    "component_time = get_object(\n",
    "    storage_client = storage_client,\n",
    "    bucket_name = storage_names[-2],\n",
    "    object_name = 'root',\n",
    "    path_replacers = {\n",
    "        'name': 'TIMES'\n",
    "    },\n",
    "    path_names = [\n",
    "        'components'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f041b329-f951-434d-bef6-2e1f7ebf9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "component_time = component_time['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b6124b7a-ff77-4569-a9eb-a3304d7fdb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('times/components-1.json', 'w') as f:\n",
    "    json.dump(component_time, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5b9aec-3220-4187-82a8-514820f15100",
   "metadata": {},
   "source": [
    "## LOGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63adb170-1ae4-4b41-bc8f-5b67b58ac98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    url = 'http://127.0.0.1:6500/general/logs/frontend'\n",
    ")\n",
    "logs = json.loads(response.text)['logs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1782ba54-e295-47b9-9c70-7b2217e3ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logs/forwarder-frontend-1.txt', 'w') as f:\n",
    "    for line in logs:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9337459-dd32-414b-a112-7a90d086cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    url = 'http://127.0.0.1:6500/general/logs/backend'\n",
    ")\n",
    "logs = json.loads(response.text)['logs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aac288d0-a41b-4dde-ab54-de3c48ba2ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logs/forwarder-backend-1.txt', 'w') as f:\n",
    "    for line in logs:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c3b0a50c-6f5c-4879-ad76-8d187328bcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    url = 'http://127.0.0.1:6600/general/logs/frontend'\n",
    ")\n",
    "logs = json.loads(response.text)['logs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c7043d3-2ca7-4589-bd15-1955a22ad716",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logs/submitter-frontend-1.txt', 'w') as f:\n",
    "    for line in logs:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee2d6ed8-2227-44d6-8aaf-61c3e3a3e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    url = 'http://127.0.0.1:6600/general/logs/backend'\n",
    ")\n",
    "logs = json.loads(response.text)['logs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2e9ef348-76a9-4b58-bea2-ba78e07ff369",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logs/submitter-backend-1.txt', 'w') as f:\n",
    "    for line in logs:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f10b407-7350-4cda-abc5-c5d37cffa935",
   "metadata": {},
   "source": [
    "## SACCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f00aa-2900-49d8-bd9e-9c9de7657c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used object path:ARTIFACTS/SACCT/23\n"
     ]
    }
   ],
   "source": [
    "sacct_object = get_object(\n",
    "    storage_client = storage_client,\n",
    "    bucket_name = storage_names[1],\n",
    "    object_name = 'root',\n",
    "    path_replacers = {\n",
    "        'name': 'ARTIFACTS'\n",
    "    },\n",
    "    path_names = [\n",
    "        'SACCT',\n",
    "        '1'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ab14f3f1-37a2-4e8d-8e53-fd103409f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sacct_data = sacct_object['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b04089fc-9400-45c4-9f48-3d3e62ff510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('artifacts/sacct-1.json', 'w') as f:\n",
    "    json.dump(sacct_data, f, indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14298355-d25c-44f5-93cc-340d0e3c93a9",
   "metadata": {},
   "source": [
    "## SEFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d6325c-bbac-4215-a30b-59b694d7dfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used object path:ARTIFACTS/SEFF/23\n"
     ]
    }
   ],
   "source": [
    "seff_object = get_object(\n",
    "    storage_client = storage_client,\n",
    "    bucket_name = storage_names[1],\n",
    "    object_name = 'root',\n",
    "    path_replacers = {\n",
    "        'name': 'ARTIFACTS'\n",
    "    },\n",
    "    path_names = [\n",
    "        'SEFF',\n",
    "        '1'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd1eefa6-e6d8-45d0-95b2-42837695f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "seff_data = seff_object['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc8643e9-9773-41ff-8e4d-4fef777f8861",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('artifacts/seff-1.json', 'w') as f:\n",
    "    json.dump(seff_data , f, indent = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
